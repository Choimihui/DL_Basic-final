{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "from randaugment import RandAugment\n",
    "import Rand\n",
    "\n",
    "\n",
    "import PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from torchsummary import summary #!#\n",
    "from tensorboardX import SummaryWriter #!#\n",
    "\n",
    "\n",
    "writer = SummaryWriter('./runs/' + '/graph')  #!#\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'                # GPU Number \n",
    "\n",
    "start_time = time.time()\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "root_dir = 'drive/app/cifar10/'\n",
    "default_directory = 'drive/app/torch/save_models'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.RandomCrop(32, padding=4),               # Random Position Crop\n",
    "    RandAugment(),\n",
    "    transforms.RandomHorizontalFlip(),                  # right and left flip\n",
    "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
    "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
    "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
    "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
    "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# automatically download\n",
    "train_dataset = datasets.CIFAR10(root=root_dir,\n",
    "                                 train=True,\n",
    "                                 transform=transform_train,\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=root_dir,\n",
    "                                train=False,\n",
    "                                transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,            # at Training Procedure, Data Shuffle = True\n",
    "                                           num_workers=4)           # CPU loader number\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,            # at Test Procedure, Data Shuffle = False\n",
    "                                          num_workers=4)            # CPU loader number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE 1 GPUs!\n"
     ]
    }
   ],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = out + self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)        \n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "        \n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.device_count() > 0:\n",
    "    print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    print(\"USE ONLY CPU!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Batch_idx: 0 |  Loss: (2.5715) | Acc: (9.38%) (12/128)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 10 |  Loss: (2.4790) | Acc: (14.84%) (209/1408)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 20 |  Loss: (2.3228) | Acc: (17.93%) (482/2688)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 30 |  Loss: (2.2414) | Acc: (20.04%) (795/3968)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 40 |  Loss: (2.1900) | Acc: (21.38%) (1122/5248)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 50 |  Loss: (2.1464) | Acc: (22.81%) (1489/6528)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 60 |  Loss: (2.1091) | Acc: (23.71%) (1851/7808)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 70 |  Loss: (2.0821) | Acc: (24.58%) (2234/9088)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 80 |  Loss: (2.0538) | Acc: (25.43%) (2637/10368)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 90 |  Loss: (2.0360) | Acc: (26.00%) (3029/11648)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 100 |  Loss: (2.0176) | Acc: (26.65%) (3445/12928)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 110 |  Loss: (2.0020) | Acc: (27.08%) (3847/14208)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 120 |  Loss: (1.9890) | Acc: (27.47%) (4255/15488)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 130 |  Loss: (1.9729) | Acc: (27.90%) (4678/16768)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 140 |  Loss: (1.9554) | Acc: (28.60%) (5161/18048)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 150 |  Loss: (1.9438) | Acc: (29.04%) (5612/19328)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 160 |  Loss: (1.9300) | Acc: (29.48%) (6076/20608)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 170 |  Loss: (1.9205) | Acc: (29.81%) (6524/21888)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 180 |  Loss: (1.9081) | Acc: (30.29%) (7018/23168)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 190 |  Loss: (1.8991) | Acc: (30.66%) (7495/24448)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 200 |  Loss: (1.8892) | Acc: (31.04%) (7985/25728)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 210 |  Loss: (1.8775) | Acc: (31.43%) (8489/27008)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 220 |  Loss: (1.8700) | Acc: (31.69%) (8964/28288)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 230 |  Loss: (1.8608) | Acc: (32.04%) (9475/29568)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 240 |  Loss: (1.8517) | Acc: (32.45%) (10010/30848)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 250 |  Loss: (1.8427) | Acc: (32.79%) (10536/32128)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 260 |  Loss: (1.8323) | Acc: (33.23%) (11103/33408)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 270 |  Loss: (1.8240) | Acc: (33.60%) (11656/34688)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 280 |  Loss: (1.8174) | Acc: (33.85%) (12175/35968)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 290 |  Loss: (1.8102) | Acc: (34.13%) (12712/37248)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 300 |  Loss: (1.8012) | Acc: (34.42%) (13261/38528)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 310 |  Loss: (1.7919) | Acc: (34.77%) (13842/39808)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 320 |  Loss: (1.7836) | Acc: (35.12%) (14430/41088)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 330 |  Loss: (1.7754) | Acc: (35.44%) (15017/42368)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 340 |  Loss: (1.7676) | Acc: (35.74%) (15598/43648)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 350 |  Loss: (1.7601) | Acc: (36.02%) (16183/44928)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 360 |  Loss: (1.7551) | Acc: (36.22%) (16738/46208)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 370 |  Loss: (1.7481) | Acc: (36.48%) (17324/47488)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 380 |  Loss: (1.7416) | Acc: (36.74%) (17917/48768)\n",
      "lr: 0.001\n",
      "Epoch: 0 | Batch_idx: 390 |  Loss: (1.7351) | Acc: (36.94%) (18472/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (4.3478) | Acc: (13.57%) (1357/10000)\n",
      "Epoch: 1 | Batch_idx: 0 |  Loss: (1.4260) | Acc: (56.25%) (72/128)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 10 |  Loss: (1.4616) | Acc: (47.80%) (673/1408)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 20 |  Loss: (1.4403) | Acc: (49.33%) (1326/2688)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 30 |  Loss: (1.4405) | Acc: (49.09%) (1948/3968)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 40 |  Loss: (1.4357) | Acc: (49.03%) (2573/5248)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 50 |  Loss: (1.4397) | Acc: (48.67%) (3177/6528)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 60 |  Loss: (1.4317) | Acc: (48.90%) (3818/7808)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 70 |  Loss: (1.4242) | Acc: (49.16%) (4468/9088)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 80 |  Loss: (1.4091) | Acc: (49.80%) (5163/10368)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 90 |  Loss: (1.4052) | Acc: (49.88%) (5810/11648)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 100 |  Loss: (1.3978) | Acc: (50.18%) (6487/12928)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 110 |  Loss: (1.3974) | Acc: (50.10%) (7118/14208)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 120 |  Loss: (1.3944) | Acc: (50.19%) (7773/15488)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 130 |  Loss: (1.3916) | Acc: (50.27%) (8429/16768)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 140 |  Loss: (1.3905) | Acc: (50.31%) (9080/18048)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 150 |  Loss: (1.3833) | Acc: (50.56%) (9773/19328)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 160 |  Loss: (1.3793) | Acc: (50.72%) (10452/20608)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 170 |  Loss: (1.3771) | Acc: (50.89%) (11138/21888)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 180 |  Loss: (1.3708) | Acc: (51.11%) (11842/23168)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 190 |  Loss: (1.3677) | Acc: (51.22%) (12522/24448)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 200 |  Loss: (1.3604) | Acc: (51.50%) (13249/25728)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 210 |  Loss: (1.3531) | Acc: (51.73%) (13971/27008)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 220 |  Loss: (1.3471) | Acc: (51.93%) (14691/28288)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 230 |  Loss: (1.3428) | Acc: (52.09%) (15401/29568)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 240 |  Loss: (1.3403) | Acc: (52.17%) (16094/30848)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 250 |  Loss: (1.3374) | Acc: (52.37%) (16824/32128)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 260 |  Loss: (1.3334) | Acc: (52.44%) (17520/33408)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 270 |  Loss: (1.3316) | Acc: (52.54%) (18226/34688)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 280 |  Loss: (1.3278) | Acc: (52.79%) (18988/35968)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 290 |  Loss: (1.3245) | Acc: (52.90%) (19704/37248)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 300 |  Loss: (1.3208) | Acc: (53.07%) (20448/38528)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 310 |  Loss: (1.3172) | Acc: (53.14%) (21154/39808)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 320 |  Loss: (1.3118) | Acc: (53.30%) (21898/41088)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 330 |  Loss: (1.3093) | Acc: (53.45%) (22644/42368)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 340 |  Loss: (1.3047) | Acc: (53.61%) (23401/43648)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 350 |  Loss: (1.3009) | Acc: (53.73%) (24141/44928)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 360 |  Loss: (1.2991) | Acc: (53.78%) (24849/46208)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 370 |  Loss: (1.2962) | Acc: (53.84%) (25569/47488)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 380 |  Loss: (1.2941) | Acc: (53.92%) (26294/48768)\n",
      "lr: 0.001\n",
      "Epoch: 1 | Batch_idx: 390 |  Loss: (1.2911) | Acc: (54.01%) (27003/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.9951) | Acc: (15.43%) (1543/10000)\n",
      "Epoch: 2 | Batch_idx: 0 |  Loss: (1.1486) | Acc: (63.28%) (81/128)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 10 |  Loss: (1.1378) | Acc: (59.80%) (842/1408)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 20 |  Loss: (1.1541) | Acc: (59.60%) (1602/2688)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 30 |  Loss: (1.1664) | Acc: (58.74%) (2331/3968)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 40 |  Loss: (1.1680) | Acc: (58.73%) (3082/5248)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 50 |  Loss: (1.1694) | Acc: (58.73%) (3834/6528)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 60 |  Loss: (1.1702) | Acc: (58.79%) (4590/7808)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 70 |  Loss: (1.1649) | Acc: (58.84%) (5347/9088)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 80 |  Loss: (1.1674) | Acc: (58.72%) (6088/10368)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 90 |  Loss: (1.1650) | Acc: (58.51%) (6815/11648)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 100 |  Loss: (1.1661) | Acc: (58.53%) (7567/12928)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 110 |  Loss: (1.1651) | Acc: (58.66%) (8334/14208)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 120 |  Loss: (1.1637) | Acc: (58.76%) (9100/15488)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 130 |  Loss: (1.1620) | Acc: (58.85%) (9868/16768)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 140 |  Loss: (1.1622) | Acc: (58.93%) (10635/18048)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 150 |  Loss: (1.1603) | Acc: (59.11%) (11424/19328)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 160 |  Loss: (1.1548) | Acc: (59.28%) (12216/20608)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 170 |  Loss: (1.1508) | Acc: (59.32%) (12983/21888)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 180 |  Loss: (1.1465) | Acc: (59.44%) (13772/23168)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 190 |  Loss: (1.1430) | Acc: (59.57%) (14563/24448)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 200 |  Loss: (1.1419) | Acc: (59.68%) (15355/25728)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 210 |  Loss: (1.1397) | Acc: (59.77%) (16142/27008)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 220 |  Loss: (1.1358) | Acc: (59.92%) (16949/28288)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 230 |  Loss: (1.1300) | Acc: (60.19%) (17797/29568)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 240 |  Loss: (1.1297) | Acc: (60.22%) (18578/30848)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 250 |  Loss: (1.1293) | Acc: (60.21%) (19345/32128)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 260 |  Loss: (1.1258) | Acc: (60.36%) (20165/33408)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 270 |  Loss: (1.1249) | Acc: (60.32%) (20925/34688)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 280 |  Loss: (1.1230) | Acc: (60.35%) (21705/35968)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 290 |  Loss: (1.1227) | Acc: (60.31%) (22466/37248)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 300 |  Loss: (1.1202) | Acc: (60.37%) (23259/38528)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 310 |  Loss: (1.1180) | Acc: (60.42%) (24052/39808)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 320 |  Loss: (1.1151) | Acc: (60.50%) (24857/41088)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 330 |  Loss: (1.1134) | Acc: (60.52%) (25639/42368)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 340 |  Loss: (1.1114) | Acc: (60.59%) (26445/43648)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 350 |  Loss: (1.1103) | Acc: (60.57%) (27212/44928)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 360 |  Loss: (1.1091) | Acc: (60.66%) (28030/46208)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 370 |  Loss: (1.1075) | Acc: (60.75%) (28851/47488)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 380 |  Loss: (1.1037) | Acc: (60.89%) (29694/48768)\n",
      "lr: 0.001\n",
      "Epoch: 2 | Batch_idx: 390 |  Loss: (1.1014) | Acc: (60.99%) (30494/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (5.3732) | Acc: (16.55%) (1655/10000)\n",
      "Epoch: 3 | Batch_idx: 0 |  Loss: (0.8318) | Acc: (71.88%) (92/128)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 10 |  Loss: (0.9829) | Acc: (65.13%) (917/1408)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 20 |  Loss: (1.0219) | Acc: (63.88%) (1717/2688)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 30 |  Loss: (1.0042) | Acc: (64.34%) (2553/3968)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 40 |  Loss: (1.0048) | Acc: (64.25%) (3372/5248)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 50 |  Loss: (1.0059) | Acc: (64.29%) (4197/6528)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 60 |  Loss: (0.9995) | Acc: (64.64%) (5047/7808)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 70 |  Loss: (1.0024) | Acc: (64.33%) (5846/9088)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 80 |  Loss: (0.9979) | Acc: (64.45%) (6682/10368)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 90 |  Loss: (0.9991) | Acc: (64.50%) (7513/11648)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 100 |  Loss: (0.9989) | Acc: (64.56%) (8346/12928)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 110 |  Loss: (0.9940) | Acc: (64.82%) (9210/14208)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 120 |  Loss: (0.9909) | Acc: (64.97%) (10062/15488)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 130 |  Loss: (0.9907) | Acc: (64.95%) (10891/16768)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 140 |  Loss: (0.9922) | Acc: (64.91%) (11715/18048)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 150 |  Loss: (0.9950) | Acc: (64.83%) (12531/19328)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 160 |  Loss: (0.9943) | Acc: (64.92%) (13378/20608)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 170 |  Loss: (0.9939) | Acc: (65.05%) (14238/21888)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 180 |  Loss: (0.9928) | Acc: (65.06%) (15073/23168)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 190 |  Loss: (0.9910) | Acc: (65.14%) (15925/24448)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 200 |  Loss: (0.9893) | Acc: (65.23%) (16783/25728)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 210 |  Loss: (0.9886) | Acc: (65.24%) (17621/27008)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 220 |  Loss: (0.9874) | Acc: (65.30%) (18473/28288)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 230 |  Loss: (0.9867) | Acc: (65.38%) (19332/29568)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 240 |  Loss: (0.9871) | Acc: (65.43%) (20185/30848)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 250 |  Loss: (0.9857) | Acc: (65.45%) (21027/32128)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 260 |  Loss: (0.9865) | Acc: (65.46%) (21868/33408)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 270 |  Loss: (0.9871) | Acc: (65.49%) (22718/34688)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 280 |  Loss: (0.9851) | Acc: (65.51%) (23564/35968)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 290 |  Loss: (0.9842) | Acc: (65.52%) (24404/37248)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 300 |  Loss: (0.9845) | Acc: (65.51%) (25241/38528)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 310 |  Loss: (0.9834) | Acc: (65.52%) (26083/39808)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 320 |  Loss: (0.9820) | Acc: (65.54%) (26928/41088)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 330 |  Loss: (0.9810) | Acc: (65.56%) (27775/42368)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 340 |  Loss: (0.9798) | Acc: (65.61%) (28637/43648)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 350 |  Loss: (0.9795) | Acc: (65.63%) (29487/44928)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 360 |  Loss: (0.9775) | Acc: (65.70%) (30360/46208)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 370 |  Loss: (0.9759) | Acc: (65.76%) (31227/47488)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 380 |  Loss: (0.9728) | Acc: (65.86%) (32119/48768)\n",
      "lr: 0.001\n",
      "Epoch: 3 | Batch_idx: 390 |  Loss: (0.9696) | Acc: (65.98%) (32990/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (4.3655) | Acc: (17.63%) (1763/10000)\n",
      "Epoch: 4 | Batch_idx: 0 |  Loss: (0.8505) | Acc: (68.75%) (88/128)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 10 |  Loss: (0.9053) | Acc: (66.83%) (941/1408)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 20 |  Loss: (0.9192) | Acc: (67.15%) (1805/2688)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 30 |  Loss: (0.9022) | Acc: (67.74%) (2688/3968)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 40 |  Loss: (0.9055) | Acc: (67.74%) (3555/5248)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 50 |  Loss: (0.9024) | Acc: (67.77%) (4424/6528)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 60 |  Loss: (0.9032) | Acc: (67.71%) (5287/7808)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 70 |  Loss: (0.9001) | Acc: (67.95%) (6175/9088)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 80 |  Loss: (0.9039) | Acc: (67.73%) (7022/10368)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 90 |  Loss: (0.9078) | Acc: (67.73%) (7889/11648)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 100 |  Loss: (0.9040) | Acc: (67.89%) (8777/12928)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 110 |  Loss: (0.9101) | Acc: (67.79%) (9631/14208)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 120 |  Loss: (0.9075) | Acc: (68.03%) (10536/15488)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 130 |  Loss: (0.9047) | Acc: (68.19%) (11434/16768)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 140 |  Loss: (0.9036) | Acc: (68.36%) (12337/18048)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 150 |  Loss: (0.9003) | Acc: (68.46%) (13232/19328)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 160 |  Loss: (0.8987) | Acc: (68.50%) (14117/20608)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 170 |  Loss: (0.8988) | Acc: (68.59%) (15012/21888)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 180 |  Loss: (0.8979) | Acc: (68.61%) (15895/23168)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 190 |  Loss: (0.8954) | Acc: (68.69%) (16793/24448)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 200 |  Loss: (0.8931) | Acc: (68.74%) (17686/25728)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 210 |  Loss: (0.8923) | Acc: (68.72%) (18559/27008)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 220 |  Loss: (0.8901) | Acc: (68.75%) (19449/28288)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 230 |  Loss: (0.8890) | Acc: (68.78%) (20337/29568)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 240 |  Loss: (0.8881) | Acc: (68.84%) (21237/30848)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 250 |  Loss: (0.8882) | Acc: (68.83%) (22114/32128)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 260 |  Loss: (0.8865) | Acc: (68.89%) (23015/33408)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 270 |  Loss: (0.8844) | Acc: (68.99%) (23931/34688)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 280 |  Loss: (0.8824) | Acc: (69.06%) (24841/35968)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 290 |  Loss: (0.8825) | Acc: (69.06%) (25723/37248)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 300 |  Loss: (0.8813) | Acc: (69.09%) (26620/38528)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 310 |  Loss: (0.8793) | Acc: (69.17%) (27534/39808)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 320 |  Loss: (0.8763) | Acc: (69.30%) (28472/41088)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 330 |  Loss: (0.8754) | Acc: (69.35%) (29381/42368)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 340 |  Loss: (0.8744) | Acc: (69.36%) (30275/43648)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 350 |  Loss: (0.8723) | Acc: (69.44%) (31198/44928)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 360 |  Loss: (0.8713) | Acc: (69.52%) (32122/46208)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 370 |  Loss: (0.8709) | Acc: (69.58%) (33044/47488)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 380 |  Loss: (0.8687) | Acc: (69.66%) (33972/48768)\n",
      "lr: 0.001\n",
      "Epoch: 4 | Batch_idx: 390 |  Loss: (0.8679) | Acc: (69.70%) (34848/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.7685) | Acc: (21.43%) (2143/10000)\n",
      "Epoch: 5 | Batch_idx: 0 |  Loss: (0.8311) | Acc: (71.09%) (91/128)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 10 |  Loss: (0.8182) | Acc: (71.16%) (1002/1408)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 20 |  Loss: (0.7777) | Acc: (73.33%) (1971/2688)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 30 |  Loss: (0.8089) | Acc: (72.10%) (2861/3968)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 40 |  Loss: (0.8075) | Acc: (72.03%) (3780/5248)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 50 |  Loss: (0.8132) | Acc: (71.54%) (4670/6528)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 60 |  Loss: (0.8093) | Acc: (71.86%) (5611/7808)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 70 |  Loss: (0.8093) | Acc: (71.88%) (6532/9088)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 80 |  Loss: (0.8030) | Acc: (72.18%) (7484/10368)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 90 |  Loss: (0.8061) | Acc: (71.92%) (8377/11648)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 100 |  Loss: (0.8068) | Acc: (71.85%) (9289/12928)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 110 |  Loss: (0.8142) | Acc: (71.45%) (10152/14208)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 120 |  Loss: (0.8180) | Acc: (71.39%) (11057/15488)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 130 |  Loss: (0.8201) | Acc: (71.37%) (11968/16768)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 140 |  Loss: (0.8180) | Acc: (71.45%) (12895/18048)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 150 |  Loss: (0.8195) | Acc: (71.36%) (13792/19328)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 160 |  Loss: (0.8167) | Acc: (71.48%) (14731/20608)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 170 |  Loss: (0.8140) | Acc: (71.58%) (15668/21888)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 180 |  Loss: (0.8113) | Acc: (71.76%) (16625/23168)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 190 |  Loss: (0.8095) | Acc: (71.85%) (17566/24448)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 200 |  Loss: (0.8109) | Acc: (71.75%) (18460/25728)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 210 |  Loss: (0.8109) | Acc: (71.80%) (19392/27008)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 220 |  Loss: (0.8092) | Acc: (71.85%) (20325/28288)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 230 |  Loss: (0.8080) | Acc: (71.92%) (21265/29568)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 240 |  Loss: (0.8082) | Acc: (71.91%) (22183/30848)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 250 |  Loss: (0.8061) | Acc: (71.97%) (23123/32128)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 260 |  Loss: (0.8050) | Acc: (72.04%) (24067/33408)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 270 |  Loss: (0.8031) | Acc: (72.08%) (25004/34688)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 280 |  Loss: (0.8006) | Acc: (72.18%) (25960/35968)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 290 |  Loss: (0.7988) | Acc: (72.23%) (26905/37248)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 300 |  Loss: (0.7980) | Acc: (72.26%) (27839/38528)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 310 |  Loss: (0.7995) | Acc: (72.21%) (28744/39808)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 320 |  Loss: (0.7974) | Acc: (72.25%) (29687/41088)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 330 |  Loss: (0.7974) | Acc: (72.26%) (30614/42368)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 340 |  Loss: (0.7958) | Acc: (72.30%) (31556/43648)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 350 |  Loss: (0.7949) | Acc: (72.35%) (32506/44928)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 360 |  Loss: (0.7933) | Acc: (72.41%) (33461/46208)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 370 |  Loss: (0.7921) | Acc: (72.42%) (34389/47488)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 380 |  Loss: (0.7916) | Acc: (72.42%) (35316/48768)\n",
      "lr: 0.001\n",
      "Epoch: 5 | Batch_idx: 390 |  Loss: (0.7921) | Acc: (72.40%) (36201/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (4.4136) | Acc: (20.58%) (2058/10000)\n",
      "Epoch: 6 | Batch_idx: 0 |  Loss: (0.5607) | Acc: (80.47%) (103/128)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 10 |  Loss: (0.7647) | Acc: (72.87%) (1026/1408)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 20 |  Loss: (0.7679) | Acc: (73.10%) (1965/2688)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 30 |  Loss: (0.7592) | Acc: (74.02%) (2937/3968)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 40 |  Loss: (0.7713) | Acc: (73.59%) (3862/5248)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 50 |  Loss: (0.7547) | Acc: (74.07%) (4835/6528)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 60 |  Loss: (0.7486) | Acc: (74.28%) (5800/7808)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 70 |  Loss: (0.7568) | Acc: (73.95%) (6721/9088)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 80 |  Loss: (0.7558) | Acc: (73.97%) (7669/10368)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 90 |  Loss: (0.7534) | Acc: (74.05%) (8625/11648)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 100 |  Loss: (0.7527) | Acc: (74.01%) (9568/12928)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 110 |  Loss: (0.7561) | Acc: (73.91%) (10501/14208)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 120 |  Loss: (0.7583) | Acc: (73.79%) (11429/15488)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 130 |  Loss: (0.7560) | Acc: (73.85%) (12383/16768)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 140 |  Loss: (0.7541) | Acc: (73.86%) (13330/18048)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 150 |  Loss: (0.7548) | Acc: (73.85%) (14274/19328)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 160 |  Loss: (0.7550) | Acc: (73.87%) (15223/20608)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 170 |  Loss: (0.7540) | Acc: (73.88%) (16171/21888)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 180 |  Loss: (0.7515) | Acc: (73.89%) (17118/23168)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 190 |  Loss: (0.7504) | Acc: (73.94%) (18078/24448)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 200 |  Loss: (0.7499) | Acc: (73.92%) (19019/25728)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 210 |  Loss: (0.7486) | Acc: (74.00%) (19985/27008)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 220 |  Loss: (0.7460) | Acc: (74.05%) (20947/28288)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 230 |  Loss: (0.7470) | Acc: (74.05%) (21894/29568)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 240 |  Loss: (0.7452) | Acc: (74.09%) (22854/30848)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 250 |  Loss: (0.7441) | Acc: (74.06%) (23794/32128)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 260 |  Loss: (0.7442) | Acc: (74.07%) (24744/33408)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 270 |  Loss: (0.7428) | Acc: (74.13%) (25714/34688)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 280 |  Loss: (0.7416) | Acc: (74.19%) (26686/35968)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 290 |  Loss: (0.7399) | Acc: (74.25%) (27655/37248)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 300 |  Loss: (0.7387) | Acc: (74.33%) (28636/38528)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 310 |  Loss: (0.7379) | Acc: (74.38%) (29611/39808)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 320 |  Loss: (0.7367) | Acc: (74.44%) (30585/41088)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 330 |  Loss: (0.7358) | Acc: (74.45%) (31543/42368)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 340 |  Loss: (0.7364) | Acc: (74.44%) (32490/43648)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 350 |  Loss: (0.7362) | Acc: (74.47%) (33457/44928)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 360 |  Loss: (0.7365) | Acc: (74.47%) (34410/46208)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 370 |  Loss: (0.7351) | Acc: (74.50%) (35378/47488)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 380 |  Loss: (0.7355) | Acc: (74.51%) (36335/48768)\n",
      "lr: 0.001\n",
      "Epoch: 6 | Batch_idx: 390 |  Loss: (0.7361) | Acc: (74.50%) (37249/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.4097) | Acc: (26.77%) (2677/10000)\n",
      "Epoch: 7 | Batch_idx: 0 |  Loss: (0.6937) | Acc: (71.09%) (91/128)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 10 |  Loss: (0.7243) | Acc: (73.58%) (1036/1408)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 20 |  Loss: (0.7361) | Acc: (74.59%) (2005/2688)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 30 |  Loss: (0.7218) | Acc: (75.10%) (2980/3968)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 40 |  Loss: (0.7157) | Acc: (75.21%) (3947/5248)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 50 |  Loss: (0.7122) | Acc: (75.37%) (4920/6528)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 60 |  Loss: (0.7087) | Acc: (75.46%) (5892/7808)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 70 |  Loss: (0.7076) | Acc: (75.52%) (6863/9088)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 80 |  Loss: (0.7123) | Acc: (75.25%) (7802/10368)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 90 |  Loss: (0.7106) | Acc: (75.38%) (8780/11648)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 100 |  Loss: (0.7135) | Acc: (75.21%) (9723/12928)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 110 |  Loss: (0.7133) | Acc: (75.20%) (10685/14208)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 120 |  Loss: (0.7107) | Acc: (75.31%) (11664/15488)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 130 |  Loss: (0.7088) | Acc: (75.45%) (12651/16768)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 140 |  Loss: (0.7115) | Acc: (75.35%) (13600/18048)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 150 |  Loss: (0.7107) | Acc: (75.38%) (14569/19328)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 160 |  Loss: (0.7085) | Acc: (75.42%) (15543/20608)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 170 |  Loss: (0.7046) | Acc: (75.55%) (16537/21888)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 180 |  Loss: (0.7009) | Acc: (75.59%) (17513/23168)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 190 |  Loss: (0.6984) | Acc: (75.65%) (18494/24448)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 200 |  Loss: (0.6970) | Acc: (75.71%) (19479/25728)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 210 |  Loss: (0.6962) | Acc: (75.76%) (20461/27008)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 220 |  Loss: (0.6965) | Acc: (75.71%) (21416/28288)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 230 |  Loss: (0.6946) | Acc: (75.80%) (22412/29568)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 240 |  Loss: (0.6969) | Acc: (75.75%) (23366/30848)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 250 |  Loss: (0.6984) | Acc: (75.67%) (24312/32128)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 260 |  Loss: (0.6981) | Acc: (75.66%) (25277/33408)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 270 |  Loss: (0.6983) | Acc: (75.69%) (26255/34688)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 280 |  Loss: (0.6965) | Acc: (75.76%) (27251/35968)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 290 |  Loss: (0.6958) | Acc: (75.82%) (28243/37248)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 300 |  Loss: (0.6962) | Acc: (75.81%) (29210/38528)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 310 |  Loss: (0.6956) | Acc: (75.86%) (30198/39808)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 320 |  Loss: (0.6964) | Acc: (75.83%) (31159/41088)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 330 |  Loss: (0.6963) | Acc: (75.84%) (32132/42368)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 340 |  Loss: (0.6952) | Acc: (75.89%) (33126/43648)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 350 |  Loss: (0.6957) | Acc: (75.89%) (34098/44928)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 360 |  Loss: (0.6953) | Acc: (75.90%) (35073/46208)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 370 |  Loss: (0.6956) | Acc: (75.89%) (36041/47488)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 380 |  Loss: (0.6953) | Acc: (75.92%) (37023/48768)\n",
      "lr: 0.001\n",
      "Epoch: 7 | Batch_idx: 390 |  Loss: (0.6937) | Acc: (75.96%) (37982/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.7406) | Acc: (27.53%) (2753/10000)\n",
      "Epoch: 8 | Batch_idx: 0 |  Loss: (0.5265) | Acc: (79.69%) (102/128)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 10 |  Loss: (0.6305) | Acc: (78.55%) (1106/1408)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 20 |  Loss: (0.6491) | Acc: (77.38%) (2080/2688)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 30 |  Loss: (0.6594) | Acc: (76.92%) (3052/3968)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 40 |  Loss: (0.6512) | Acc: (77.46%) (4065/5248)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 50 |  Loss: (0.6574) | Acc: (77.36%) (5050/6528)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 60 |  Loss: (0.6582) | Acc: (77.41%) (6044/7808)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 70 |  Loss: (0.6610) | Acc: (77.24%) (7020/9088)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 80 |  Loss: (0.6632) | Acc: (77.15%) (7999/10368)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 90 |  Loss: (0.6578) | Acc: (77.38%) (9013/11648)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 100 |  Loss: (0.6564) | Acc: (77.45%) (10013/12928)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 110 |  Loss: (0.6510) | Acc: (77.58%) (11023/14208)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 120 |  Loss: (0.6468) | Acc: (77.71%) (12035/15488)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 130 |  Loss: (0.6461) | Acc: (77.64%) (13019/16768)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 140 |  Loss: (0.6466) | Acc: (77.65%) (14015/18048)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 150 |  Loss: (0.6464) | Acc: (77.70%) (15017/19328)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 160 |  Loss: (0.6427) | Acc: (77.82%) (16037/20608)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 170 |  Loss: (0.6413) | Acc: (77.87%) (17045/21888)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 180 |  Loss: (0.6412) | Acc: (77.87%) (18040/23168)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 190 |  Loss: (0.6437) | Acc: (77.77%) (19012/24448)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 200 |  Loss: (0.6429) | Acc: (77.78%) (20011/25728)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 210 |  Loss: (0.6437) | Acc: (77.75%) (20998/27008)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 220 |  Loss: (0.6443) | Acc: (77.66%) (21969/28288)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 230 |  Loss: (0.6440) | Acc: (77.65%) (22961/29568)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 240 |  Loss: (0.6434) | Acc: (77.67%) (23961/30848)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 250 |  Loss: (0.6449) | Acc: (77.61%) (24934/32128)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 260 |  Loss: (0.6461) | Acc: (77.59%) (25920/33408)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 270 |  Loss: (0.6459) | Acc: (77.60%) (26917/34688)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 280 |  Loss: (0.6488) | Acc: (77.49%) (27871/35968)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 290 |  Loss: (0.6496) | Acc: (77.47%) (28855/37248)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 300 |  Loss: (0.6515) | Acc: (77.41%) (29826/38528)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 310 |  Loss: (0.6511) | Acc: (77.47%) (30839/39808)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 320 |  Loss: (0.6514) | Acc: (77.45%) (31824/41088)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 330 |  Loss: (0.6508) | Acc: (77.47%) (32824/42368)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 340 |  Loss: (0.6500) | Acc: (77.51%) (33830/43648)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 350 |  Loss: (0.6488) | Acc: (77.56%) (34846/44928)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 360 |  Loss: (0.6496) | Acc: (77.53%) (35827/46208)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 370 |  Loss: (0.6493) | Acc: (77.58%) (36840/47488)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 380 |  Loss: (0.6487) | Acc: (77.59%) (37839/48768)\n",
      "lr: 0.001\n",
      "Epoch: 8 | Batch_idx: 390 |  Loss: (0.6492) | Acc: (77.59%) (38795/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.1896) | Acc: (24.57%) (2457/10000)\n",
      "Epoch: 9 | Batch_idx: 0 |  Loss: (0.5802) | Acc: (82.03%) (105/128)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 10 |  Loss: (0.6223) | Acc: (79.05%) (1113/1408)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 20 |  Loss: (0.6281) | Acc: (78.76%) (2117/2688)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 30 |  Loss: (0.6236) | Acc: (78.78%) (3126/3968)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 40 |  Loss: (0.6123) | Acc: (78.81%) (4136/5248)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 50 |  Loss: (0.6165) | Acc: (78.89%) (5150/6528)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 60 |  Loss: (0.6135) | Acc: (78.89%) (6160/7808)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 70 |  Loss: (0.6104) | Acc: (78.96%) (7176/9088)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 80 |  Loss: (0.6060) | Acc: (79.12%) (8203/10368)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 90 |  Loss: (0.6072) | Acc: (79.03%) (9205/11648)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 100 |  Loss: (0.6135) | Acc: (78.81%) (10189/12928)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 110 |  Loss: (0.6127) | Acc: (78.77%) (11191/14208)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 120 |  Loss: (0.6122) | Acc: (78.80%) (12205/15488)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 130 |  Loss: (0.6119) | Acc: (78.87%) (13225/16768)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 140 |  Loss: (0.6116) | Acc: (78.94%) (14247/18048)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 150 |  Loss: (0.6155) | Acc: (78.76%) (15223/19328)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 160 |  Loss: (0.6178) | Acc: (78.69%) (16217/20608)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 170 |  Loss: (0.6183) | Acc: (78.56%) (17195/21888)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 180 |  Loss: (0.6194) | Acc: (78.47%) (18179/23168)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 190 |  Loss: (0.6183) | Acc: (78.45%) (19180/24448)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 200 |  Loss: (0.6201) | Acc: (78.42%) (20175/25728)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 210 |  Loss: (0.6221) | Acc: (78.37%) (21167/27008)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 220 |  Loss: (0.6212) | Acc: (78.43%) (22185/28288)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 230 |  Loss: (0.6223) | Acc: (78.42%) (23187/29568)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 240 |  Loss: (0.6220) | Acc: (78.42%) (24191/30848)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 250 |  Loss: (0.6231) | Acc: (78.38%) (25181/32128)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 260 |  Loss: (0.6222) | Acc: (78.39%) (26187/33408)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 270 |  Loss: (0.6229) | Acc: (78.36%) (27180/34688)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 280 |  Loss: (0.6227) | Acc: (78.38%) (28190/35968)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 290 |  Loss: (0.6229) | Acc: (78.31%) (29170/37248)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 300 |  Loss: (0.6230) | Acc: (78.27%) (30155/38528)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 310 |  Loss: (0.6214) | Acc: (78.32%) (31177/39808)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 320 |  Loss: (0.6211) | Acc: (78.27%) (32161/41088)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 330 |  Loss: (0.6215) | Acc: (78.29%) (33171/42368)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 340 |  Loss: (0.6208) | Acc: (78.32%) (34183/43648)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 350 |  Loss: (0.6218) | Acc: (78.29%) (35174/44928)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 360 |  Loss: (0.6222) | Acc: (78.29%) (36178/46208)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 370 |  Loss: (0.6224) | Acc: (78.29%) (37177/47488)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 380 |  Loss: (0.6214) | Acc: (78.32%) (38197/48768)\n",
      "lr: 0.001\n",
      "Epoch: 9 | Batch_idx: 390 |  Loss: (0.6213) | Acc: (78.35%) (39173/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.6983) | Acc: (31.05%) (3105/10000)\n",
      "Epoch: 10 | Batch_idx: 0 |  Loss: (0.5623) | Acc: (82.03%) (105/128)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 10 |  Loss: (0.5823) | Acc: (79.55%) (1120/1408)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 20 |  Loss: (0.5751) | Acc: (80.25%) (2157/2688)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 30 |  Loss: (0.5786) | Acc: (80.65%) (3200/3968)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 40 |  Loss: (0.5829) | Acc: (80.37%) (4218/5248)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 50 |  Loss: (0.5816) | Acc: (80.45%) (5252/6528)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 60 |  Loss: (0.5890) | Acc: (80.10%) (6254/7808)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 70 |  Loss: (0.5869) | Acc: (80.13%) (7282/9088)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 80 |  Loss: (0.5940) | Acc: (79.75%) (8268/10368)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 90 |  Loss: (0.5968) | Acc: (79.61%) (9273/11648)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 100 |  Loss: (0.5958) | Acc: (79.53%) (10281/12928)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 110 |  Loss: (0.5921) | Acc: (79.72%) (11327/14208)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 120 |  Loss: (0.5946) | Acc: (79.60%) (12329/15488)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 130 |  Loss: (0.5951) | Acc: (79.62%) (13351/16768)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 140 |  Loss: (0.5999) | Acc: (79.43%) (14335/18048)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 150 |  Loss: (0.5992) | Acc: (79.41%) (15349/19328)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 160 |  Loss: (0.5972) | Acc: (79.54%) (16391/20608)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 170 |  Loss: (0.5984) | Acc: (79.53%) (17407/21888)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 180 |  Loss: (0.5994) | Acc: (79.45%) (18406/23168)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 190 |  Loss: (0.5988) | Acc: (79.37%) (19404/24448)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 200 |  Loss: (0.5984) | Acc: (79.35%) (20414/25728)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 210 |  Loss: (0.5993) | Acc: (79.30%) (21418/27008)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 220 |  Loss: (0.6010) | Acc: (79.21%) (22408/28288)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 230 |  Loss: (0.5991) | Acc: (79.30%) (23446/29568)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 240 |  Loss: (0.5972) | Acc: (79.34%) (24476/30848)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 250 |  Loss: (0.5957) | Acc: (79.41%) (25512/32128)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 260 |  Loss: (0.5944) | Acc: (79.44%) (26539/33408)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 270 |  Loss: (0.5938) | Acc: (79.47%) (27567/34688)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 280 |  Loss: (0.5942) | Acc: (79.47%) (28583/35968)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 290 |  Loss: (0.5944) | Acc: (79.45%) (29595/37248)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 300 |  Loss: (0.5940) | Acc: (79.42%) (30600/38528)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 310 |  Loss: (0.5963) | Acc: (79.36%) (31592/39808)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 320 |  Loss: (0.5966) | Acc: (79.34%) (32598/41088)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 330 |  Loss: (0.5966) | Acc: (79.36%) (33622/42368)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 340 |  Loss: (0.5962) | Acc: (79.37%) (34644/43648)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 350 |  Loss: (0.5967) | Acc: (79.41%) (35677/44928)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 360 |  Loss: (0.5970) | Acc: (79.41%) (36692/46208)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 370 |  Loss: (0.5971) | Acc: (79.41%) (37709/47488)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 380 |  Loss: (0.5959) | Acc: (79.46%) (38749/48768)\n",
      "lr: 0.001\n",
      "Epoch: 10 | Batch_idx: 390 |  Loss: (0.5941) | Acc: (79.52%) (39761/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.1196) | Acc: (22.48%) (2248/10000)\n",
      "Epoch: 11 | Batch_idx: 0 |  Loss: (0.4928) | Acc: (81.25%) (104/128)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 10 |  Loss: (0.5477) | Acc: (81.04%) (1141/1408)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 20 |  Loss: (0.5554) | Acc: (79.91%) (2148/2688)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 30 |  Loss: (0.5361) | Acc: (81.02%) (3215/3968)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 40 |  Loss: (0.5532) | Acc: (80.28%) (4213/5248)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 50 |  Loss: (0.5613) | Acc: (80.12%) (5230/6528)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 60 |  Loss: (0.5629) | Acc: (80.21%) (6263/7808)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 70 |  Loss: (0.5599) | Acc: (80.45%) (7311/9088)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 80 |  Loss: (0.5623) | Acc: (80.37%) (8333/10368)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 90 |  Loss: (0.5649) | Acc: (80.27%) (9350/11648)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 100 |  Loss: (0.5667) | Acc: (80.08%) (10353/12928)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 110 |  Loss: (0.5636) | Acc: (80.24%) (11400/14208)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 120 |  Loss: (0.5648) | Acc: (80.21%) (12423/15488)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 130 |  Loss: (0.5657) | Acc: (80.18%) (13445/16768)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 140 |  Loss: (0.5692) | Acc: (80.03%) (14443/18048)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 150 |  Loss: (0.5700) | Acc: (80.02%) (15466/19328)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 160 |  Loss: (0.5701) | Acc: (80.00%) (16486/20608)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 170 |  Loss: (0.5714) | Acc: (79.97%) (17503/21888)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 180 |  Loss: (0.5705) | Acc: (80.01%) (18536/23168)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 190 |  Loss: (0.5685) | Acc: (80.08%) (19577/24448)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 200 |  Loss: (0.5672) | Acc: (80.12%) (20614/25728)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 210 |  Loss: (0.5690) | Acc: (80.04%) (21618/27008)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 220 |  Loss: (0.5676) | Acc: (80.10%) (22658/28288)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 230 |  Loss: (0.5677) | Acc: (80.15%) (23700/29568)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 240 |  Loss: (0.5662) | Acc: (80.22%) (24745/30848)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 250 |  Loss: (0.5657) | Acc: (80.29%) (25797/32128)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 260 |  Loss: (0.5654) | Acc: (80.28%) (26821/33408)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 270 |  Loss: (0.5689) | Acc: (80.21%) (27824/34688)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 280 |  Loss: (0.5689) | Acc: (80.24%) (28859/35968)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 290 |  Loss: (0.5700) | Acc: (80.24%) (29887/37248)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 300 |  Loss: (0.5704) | Acc: (80.23%) (30912/38528)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 310 |  Loss: (0.5699) | Acc: (80.31%) (31969/39808)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 320 |  Loss: (0.5691) | Acc: (80.32%) (33001/41088)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 330 |  Loss: (0.5682) | Acc: (80.36%) (34046/42368)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 340 |  Loss: (0.5672) | Acc: (80.42%) (35102/43648)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 350 |  Loss: (0.5668) | Acc: (80.42%) (36132/44928)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 360 |  Loss: (0.5654) | Acc: (80.46%) (37177/46208)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 370 |  Loss: (0.5671) | Acc: (80.43%) (38193/47488)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 380 |  Loss: (0.5660) | Acc: (80.41%) (39216/48768)\n",
      "lr: 0.001\n",
      "Epoch: 11 | Batch_idx: 390 |  Loss: (0.5657) | Acc: (80.42%) (40209/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.9211) | Acc: (26.40%) (2640/10000)\n",
      "Epoch: 12 | Batch_idx: 0 |  Loss: (0.5076) | Acc: (86.72%) (111/128)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 10 |  Loss: (0.5103) | Acc: (82.46%) (1161/1408)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 20 |  Loss: (0.5119) | Acc: (82.11%) (2207/2688)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 30 |  Loss: (0.5286) | Acc: (81.58%) (3237/3968)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 40 |  Loss: (0.5297) | Acc: (81.23%) (4263/5248)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 50 |  Loss: (0.5344) | Acc: (81.50%) (5320/6528)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 60 |  Loss: (0.5373) | Acc: (81.31%) (6349/7808)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 70 |  Loss: (0.5420) | Acc: (81.15%) (7375/9088)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 80 |  Loss: (0.5413) | Acc: (81.14%) (8413/10368)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 90 |  Loss: (0.5421) | Acc: (81.06%) (9442/11648)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 100 |  Loss: (0.5347) | Acc: (81.38%) (10521/12928)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 110 |  Loss: (0.5378) | Acc: (81.28%) (11548/14208)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 120 |  Loss: (0.5393) | Acc: (81.26%) (12585/15488)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 130 |  Loss: (0.5387) | Acc: (81.21%) (13618/16768)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 140 |  Loss: (0.5389) | Acc: (81.17%) (14649/18048)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 150 |  Loss: (0.5421) | Acc: (81.13%) (15680/19328)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 160 |  Loss: (0.5429) | Acc: (81.05%) (16703/20608)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 170 |  Loss: (0.5437) | Acc: (81.00%) (17730/21888)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 180 |  Loss: (0.5426) | Acc: (81.05%) (18777/23168)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 190 |  Loss: (0.5428) | Acc: (81.07%) (19821/24448)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 200 |  Loss: (0.5434) | Acc: (81.05%) (20853/25728)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 210 |  Loss: (0.5427) | Acc: (81.06%) (21893/27008)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 220 |  Loss: (0.5440) | Acc: (81.04%) (22924/28288)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 230 |  Loss: (0.5432) | Acc: (81.05%) (23965/29568)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 240 |  Loss: (0.5445) | Acc: (80.95%) (24970/30848)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 250 |  Loss: (0.5433) | Acc: (81.02%) (26029/32128)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 260 |  Loss: (0.5443) | Acc: (81.02%) (27066/33408)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 270 |  Loss: (0.5434) | Acc: (81.03%) (28108/34688)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 280 |  Loss: (0.5433) | Acc: (81.01%) (29139/35968)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 290 |  Loss: (0.5417) | Acc: (81.07%) (30198/37248)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 300 |  Loss: (0.5411) | Acc: (81.10%) (31245/38528)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 310 |  Loss: (0.5408) | Acc: (81.11%) (32287/39808)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 320 |  Loss: (0.5405) | Acc: (81.10%) (33324/41088)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 330 |  Loss: (0.5401) | Acc: (81.13%) (34375/42368)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 340 |  Loss: (0.5403) | Acc: (81.12%) (35407/43648)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 350 |  Loss: (0.5419) | Acc: (81.06%) (36418/44928)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 360 |  Loss: (0.5422) | Acc: (81.03%) (37444/46208)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 370 |  Loss: (0.5413) | Acc: (81.08%) (38504/47488)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 380 |  Loss: (0.5414) | Acc: (81.07%) (39538/48768)\n",
      "lr: 0.001\n",
      "Epoch: 12 | Batch_idx: 390 |  Loss: (0.5422) | Acc: (81.07%) (40536/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.0564) | Acc: (34.42%) (3442/10000)\n",
      "Epoch: 13 | Batch_idx: 0 |  Loss: (0.5807) | Acc: (80.47%) (103/128)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 10 |  Loss: (0.5784) | Acc: (81.11%) (1142/1408)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 20 |  Loss: (0.5436) | Acc: (81.40%) (2188/2688)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 30 |  Loss: (0.5453) | Acc: (81.07%) (3217/3968)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 40 |  Loss: (0.5422) | Acc: (81.36%) (4270/5248)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 50 |  Loss: (0.5336) | Acc: (81.69%) (5333/6528)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 60 |  Loss: (0.5307) | Acc: (81.81%) (6388/7808)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 70 |  Loss: (0.5352) | Acc: (81.71%) (7426/9088)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 80 |  Loss: (0.5271) | Acc: (82.04%) (8506/10368)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 90 |  Loss: (0.5268) | Acc: (82.08%) (9561/11648)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 100 |  Loss: (0.5261) | Acc: (82.03%) (10605/12928)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 110 |  Loss: (0.5276) | Acc: (81.89%) (11635/14208)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 120 |  Loss: (0.5290) | Acc: (81.82%) (12673/15488)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 130 |  Loss: (0.5297) | Acc: (81.80%) (13716/16768)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 140 |  Loss: (0.5322) | Acc: (81.78%) (14759/18048)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 150 |  Loss: (0.5309) | Acc: (81.80%) (15810/19328)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 160 |  Loss: (0.5315) | Acc: (81.80%) (16857/20608)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 170 |  Loss: (0.5279) | Acc: (81.87%) (17920/21888)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 180 |  Loss: (0.5272) | Acc: (81.91%) (18976/23168)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 190 |  Loss: (0.5265) | Acc: (81.91%) (20026/24448)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 200 |  Loss: (0.5291) | Acc: (81.77%) (21038/25728)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 210 |  Loss: (0.5277) | Acc: (81.78%) (22086/27008)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 220 |  Loss: (0.5271) | Acc: (81.76%) (23128/28288)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 230 |  Loss: (0.5276) | Acc: (81.71%) (24160/29568)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 240 |  Loss: (0.5262) | Acc: (81.74%) (25214/30848)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 250 |  Loss: (0.5275) | Acc: (81.74%) (26260/32128)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 260 |  Loss: (0.5279) | Acc: (81.70%) (27296/33408)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 270 |  Loss: (0.5251) | Acc: (81.82%) (28382/34688)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 280 |  Loss: (0.5230) | Acc: (81.89%) (29453/35968)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 290 |  Loss: (0.5224) | Acc: (81.95%) (30524/37248)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 300 |  Loss: (0.5239) | Acc: (81.87%) (31543/38528)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 310 |  Loss: (0.5237) | Acc: (81.87%) (32589/39808)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 320 |  Loss: (0.5230) | Acc: (81.91%) (33657/41088)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 330 |  Loss: (0.5229) | Acc: (81.92%) (34709/42368)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 340 |  Loss: (0.5227) | Acc: (81.94%) (35764/43648)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 350 |  Loss: (0.5236) | Acc: (81.91%) (36800/44928)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 360 |  Loss: (0.5234) | Acc: (81.90%) (37845/46208)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 370 |  Loss: (0.5228) | Acc: (81.95%) (38916/47488)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 380 |  Loss: (0.5214) | Acc: (82.00%) (39989/48768)\n",
      "lr: 0.001\n",
      "Epoch: 13 | Batch_idx: 390 |  Loss: (0.5208) | Acc: (82.02%) (41009/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.6223) | Acc: (33.01%) (3301/10000)\n",
      "Epoch: 14 | Batch_idx: 0 |  Loss: (0.5366) | Acc: (78.91%) (101/128)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 10 |  Loss: (0.5018) | Acc: (81.89%) (1153/1408)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 20 |  Loss: (0.4989) | Acc: (82.74%) (2224/2688)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 30 |  Loss: (0.4972) | Acc: (82.71%) (3282/3968)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 40 |  Loss: (0.4988) | Acc: (82.89%) (4350/5248)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 50 |  Loss: (0.4920) | Acc: (83.10%) (5425/6528)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 60 |  Loss: (0.4896) | Acc: (83.09%) (6488/7808)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 70 |  Loss: (0.4922) | Acc: (82.83%) (7528/9088)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 80 |  Loss: (0.4897) | Acc: (82.98%) (8603/10368)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 90 |  Loss: (0.4896) | Acc: (83.03%) (9671/11648)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 100 |  Loss: (0.4889) | Acc: (82.87%) (10713/12928)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 110 |  Loss: (0.4902) | Acc: (82.86%) (11773/14208)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 120 |  Loss: (0.4940) | Acc: (82.70%) (12809/15488)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 130 |  Loss: (0.4978) | Acc: (82.58%) (13847/16768)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 140 |  Loss: (0.4993) | Acc: (82.54%) (14897/18048)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 150 |  Loss: (0.5003) | Acc: (82.54%) (15953/19328)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 160 |  Loss: (0.4999) | Acc: (82.62%) (17027/20608)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 170 |  Loss: (0.4991) | Acc: (82.63%) (18085/21888)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 180 |  Loss: (0.4992) | Acc: (82.58%) (19132/23168)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 190 |  Loss: (0.4988) | Acc: (82.60%) (20193/24448)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 200 |  Loss: (0.5007) | Acc: (82.51%) (21229/25728)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 210 |  Loss: (0.5033) | Acc: (82.39%) (22252/27008)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 220 |  Loss: (0.5045) | Acc: (82.37%) (23301/28288)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 230 |  Loss: (0.5059) | Acc: (82.33%) (24342/29568)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 240 |  Loss: (0.5057) | Acc: (82.33%) (25396/30848)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 250 |  Loss: (0.5054) | Acc: (82.33%) (26452/32128)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 260 |  Loss: (0.5059) | Acc: (82.38%) (27522/33408)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 270 |  Loss: (0.5051) | Acc: (82.43%) (28595/34688)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 280 |  Loss: (0.5041) | Acc: (82.50%) (29672/35968)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 290 |  Loss: (0.5057) | Acc: (82.44%) (30709/37248)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 300 |  Loss: (0.5052) | Acc: (82.44%) (31761/38528)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 310 |  Loss: (0.5052) | Acc: (82.43%) (32812/39808)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 320 |  Loss: (0.5043) | Acc: (82.47%) (33885/41088)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 330 |  Loss: (0.5046) | Acc: (82.48%) (34945/42368)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 340 |  Loss: (0.5053) | Acc: (82.46%) (35994/43648)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 350 |  Loss: (0.5055) | Acc: (82.47%) (37053/44928)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 360 |  Loss: (0.5050) | Acc: (82.47%) (38109/46208)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 370 |  Loss: (0.5044) | Acc: (82.49%) (39174/47488)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 380 |  Loss: (0.5039) | Acc: (82.50%) (40236/48768)\n",
      "lr: 0.001\n",
      "Epoch: 14 | Batch_idx: 390 |  Loss: (0.5030) | Acc: (82.52%) (41260/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.9453) | Acc: (29.16%) (2916/10000)\n",
      "Epoch: 15 | Batch_idx: 0 |  Loss: (0.6368) | Acc: (74.22%) (95/128)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 10 |  Loss: (0.5090) | Acc: (81.32%) (1145/1408)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 20 |  Loss: (0.5064) | Acc: (81.73%) (2197/2688)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 30 |  Loss: (0.4953) | Acc: (82.48%) (3273/3968)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 40 |  Loss: (0.4925) | Acc: (82.53%) (4331/5248)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 50 |  Loss: (0.4899) | Acc: (82.84%) (5408/6528)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 60 |  Loss: (0.4831) | Acc: (83.27%) (6502/7808)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 70 |  Loss: (0.4767) | Acc: (83.51%) (7589/9088)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 80 |  Loss: (0.4747) | Acc: (83.52%) (8659/10368)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 90 |  Loss: (0.4758) | Acc: (83.48%) (9724/11648)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 100 |  Loss: (0.4759) | Acc: (83.44%) (10787/12928)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 110 |  Loss: (0.4744) | Acc: (83.54%) (11870/14208)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 120 |  Loss: (0.4733) | Acc: (83.57%) (12944/15488)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 130 |  Loss: (0.4731) | Acc: (83.63%) (14023/16768)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 140 |  Loss: (0.4705) | Acc: (83.71%) (15108/18048)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 150 |  Loss: (0.4736) | Acc: (83.62%) (16162/19328)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 160 |  Loss: (0.4730) | Acc: (83.67%) (17243/20608)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 170 |  Loss: (0.4721) | Acc: (83.68%) (18316/21888)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 180 |  Loss: (0.4716) | Acc: (83.74%) (19400/23168)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 190 |  Loss: (0.4750) | Acc: (83.61%) (20440/24448)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 200 |  Loss: (0.4756) | Acc: (83.59%) (21505/25728)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 210 |  Loss: (0.4768) | Acc: (83.52%) (22557/27008)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 220 |  Loss: (0.4769) | Acc: (83.53%) (23628/28288)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 230 |  Loss: (0.4764) | Acc: (83.49%) (24686/29568)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 240 |  Loss: (0.4758) | Acc: (83.48%) (25753/30848)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 250 |  Loss: (0.4765) | Acc: (83.42%) (26800/32128)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 260 |  Loss: (0.4763) | Acc: (83.43%) (27872/33408)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 270 |  Loss: (0.4774) | Acc: (83.38%) (28922/34688)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 280 |  Loss: (0.4769) | Acc: (83.42%) (30003/35968)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 290 |  Loss: (0.4783) | Acc: (83.37%) (31053/37248)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 300 |  Loss: (0.4808) | Acc: (83.28%) (32088/38528)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 310 |  Loss: (0.4812) | Acc: (83.26%) (33145/39808)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 320 |  Loss: (0.4818) | Acc: (83.22%) (34195/41088)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 330 |  Loss: (0.4818) | Acc: (83.22%) (35260/42368)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 340 |  Loss: (0.4807) | Acc: (83.24%) (36334/43648)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 350 |  Loss: (0.4806) | Acc: (83.24%) (37398/44928)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 360 |  Loss: (0.4801) | Acc: (83.27%) (38476/46208)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 370 |  Loss: (0.4793) | Acc: (83.30%) (39557/47488)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 380 |  Loss: (0.4791) | Acc: (83.34%) (40644/48768)\n",
      "lr: 0.001\n",
      "Epoch: 15 | Batch_idx: 390 |  Loss: (0.4797) | Acc: (83.32%) (41658/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.5248) | Acc: (28.26%) (2826/10000)\n",
      "Epoch: 16 | Batch_idx: 0 |  Loss: (0.4524) | Acc: (85.94%) (110/128)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 10 |  Loss: (0.4467) | Acc: (84.45%) (1189/1408)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 20 |  Loss: (0.4438) | Acc: (84.23%) (2264/2688)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 30 |  Loss: (0.4430) | Acc: (84.05%) (3335/3968)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 40 |  Loss: (0.4540) | Acc: (83.92%) (4404/5248)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 50 |  Loss: (0.4563) | Acc: (83.67%) (5462/6528)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 60 |  Loss: (0.4555) | Acc: (83.71%) (6536/7808)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 70 |  Loss: (0.4543) | Acc: (83.74%) (7610/9088)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 80 |  Loss: (0.4571) | Acc: (83.78%) (8686/10368)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 90 |  Loss: (0.4577) | Acc: (83.79%) (9760/11648)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 100 |  Loss: (0.4542) | Acc: (84.03%) (10863/12928)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 110 |  Loss: (0.4579) | Acc: (83.96%) (11929/14208)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 120 |  Loss: (0.4606) | Acc: (83.87%) (12990/15488)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 130 |  Loss: (0.4609) | Acc: (83.87%) (14063/16768)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 140 |  Loss: (0.4600) | Acc: (83.91%) (15144/18048)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 150 |  Loss: (0.4594) | Acc: (83.86%) (16209/19328)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 160 |  Loss: (0.4591) | Acc: (83.81%) (17271/20608)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 170 |  Loss: (0.4579) | Acc: (83.84%) (18350/21888)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 180 |  Loss: (0.4556) | Acc: (83.94%) (19448/23168)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 190 |  Loss: (0.4557) | Acc: (83.91%) (20515/24448)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 200 |  Loss: (0.4542) | Acc: (83.95%) (21599/25728)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 210 |  Loss: (0.4541) | Acc: (83.93%) (22669/27008)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 220 |  Loss: (0.4566) | Acc: (83.90%) (23734/28288)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 230 |  Loss: (0.4574) | Acc: (83.89%) (24806/29568)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 240 |  Loss: (0.4579) | Acc: (83.92%) (25887/30848)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 250 |  Loss: (0.4571) | Acc: (83.95%) (26971/32128)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 260 |  Loss: (0.4570) | Acc: (83.96%) (28051/33408)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 270 |  Loss: (0.4563) | Acc: (83.99%) (29135/34688)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 280 |  Loss: (0.4577) | Acc: (83.96%) (30198/35968)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 290 |  Loss: (0.4578) | Acc: (83.98%) (31282/37248)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 300 |  Loss: (0.4565) | Acc: (84.02%) (32373/38528)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 310 |  Loss: (0.4576) | Acc: (84.01%) (33441/39808)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 320 |  Loss: (0.4584) | Acc: (83.99%) (34511/41088)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 330 |  Loss: (0.4580) | Acc: (84.04%) (35606/42368)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 340 |  Loss: (0.4576) | Acc: (84.05%) (36686/43648)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 350 |  Loss: (0.4584) | Acc: (83.97%) (37727/44928)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 360 |  Loss: (0.4591) | Acc: (83.98%) (38806/46208)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 370 |  Loss: (0.4600) | Acc: (83.95%) (39867/47488)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 380 |  Loss: (0.4597) | Acc: (83.97%) (40951/48768)\n",
      "lr: 0.001\n",
      "Epoch: 16 | Batch_idx: 390 |  Loss: (0.4598) | Acc: (83.98%) (41988/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.3229) | Acc: (29.80%) (2980/10000)\n",
      "Epoch: 17 | Batch_idx: 0 |  Loss: (0.4153) | Acc: (88.28%) (113/128)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 10 |  Loss: (0.4432) | Acc: (85.16%) (1199/1408)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 20 |  Loss: (0.4266) | Acc: (85.42%) (2296/2688)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 30 |  Loss: (0.4264) | Acc: (85.53%) (3394/3968)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 40 |  Loss: (0.4311) | Acc: (85.52%) (4488/5248)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 50 |  Loss: (0.4283) | Acc: (85.62%) (5589/6528)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 60 |  Loss: (0.4266) | Acc: (85.59%) (6683/7808)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 70 |  Loss: (0.4276) | Acc: (85.49%) (7769/9088)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 80 |  Loss: (0.4282) | Acc: (85.40%) (8854/10368)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 90 |  Loss: (0.4281) | Acc: (85.41%) (9949/11648)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 100 |  Loss: (0.4290) | Acc: (85.30%) (11027/12928)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 110 |  Loss: (0.4293) | Acc: (85.30%) (12119/14208)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 120 |  Loss: (0.4304) | Acc: (85.32%) (13215/15488)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 130 |  Loss: (0.4313) | Acc: (85.24%) (14293/16768)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 140 |  Loss: (0.4326) | Acc: (85.18%) (15374/18048)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 150 |  Loss: (0.4325) | Acc: (85.18%) (16463/19328)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 160 |  Loss: (0.4333) | Acc: (85.15%) (17548/20608)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 170 |  Loss: (0.4357) | Acc: (85.05%) (18616/21888)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 180 |  Loss: (0.4355) | Acc: (85.00%) (19692/23168)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 190 |  Loss: (0.4362) | Acc: (84.98%) (20775/24448)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 200 |  Loss: (0.4391) | Acc: (84.89%) (21840/25728)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 210 |  Loss: (0.4390) | Acc: (84.86%) (22918/27008)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 220 |  Loss: (0.4398) | Acc: (84.89%) (24013/28288)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 230 |  Loss: (0.4413) | Acc: (84.80%) (25074/29568)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 240 |  Loss: (0.4421) | Acc: (84.73%) (26136/30848)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 250 |  Loss: (0.4428) | Acc: (84.71%) (27216/32128)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 260 |  Loss: (0.4420) | Acc: (84.74%) (28311/33408)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 270 |  Loss: (0.4428) | Acc: (84.72%) (29389/34688)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 280 |  Loss: (0.4430) | Acc: (84.73%) (30477/35968)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 290 |  Loss: (0.4437) | Acc: (84.70%) (31548/37248)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 300 |  Loss: (0.4442) | Acc: (84.70%) (32635/38528)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 310 |  Loss: (0.4452) | Acc: (84.67%) (33706/39808)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 320 |  Loss: (0.4444) | Acc: (84.70%) (34803/41088)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 330 |  Loss: (0.4444) | Acc: (84.70%) (35884/42368)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 340 |  Loss: (0.4455) | Acc: (84.64%) (36944/43648)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 350 |  Loss: (0.4454) | Acc: (84.63%) (38022/44928)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 360 |  Loss: (0.4452) | Acc: (84.62%) (39099/46208)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 370 |  Loss: (0.4449) | Acc: (84.63%) (40187/47488)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 380 |  Loss: (0.4455) | Acc: (84.62%) (41268/48768)\n",
      "lr: 0.001\n",
      "Epoch: 17 | Batch_idx: 390 |  Loss: (0.4466) | Acc: (84.59%) (42295/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.5463) | Acc: (35.35%) (3535/10000)\n",
      "Epoch: 18 | Batch_idx: 0 |  Loss: (0.3726) | Acc: (86.72%) (111/128)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 10 |  Loss: (0.4313) | Acc: (84.94%) (1196/1408)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 20 |  Loss: (0.4143) | Acc: (85.49%) (2298/2688)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 30 |  Loss: (0.4059) | Acc: (85.64%) (3398/3968)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 40 |  Loss: (0.4148) | Acc: (85.59%) (4492/5248)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 50 |  Loss: (0.4195) | Acc: (85.31%) (5569/6528)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 60 |  Loss: (0.4244) | Acc: (85.14%) (6648/7808)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 70 |  Loss: (0.4270) | Acc: (85.09%) (7733/9088)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 80 |  Loss: (0.4295) | Acc: (85.00%) (8813/10368)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 90 |  Loss: (0.4274) | Acc: (85.05%) (9907/11648)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 100 |  Loss: (0.4265) | Acc: (85.15%) (11008/12928)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 110 |  Loss: (0.4231) | Acc: (85.25%) (12112/14208)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 120 |  Loss: (0.4224) | Acc: (85.29%) (13209/15488)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 130 |  Loss: (0.4243) | Acc: (85.26%) (14297/16768)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 140 |  Loss: (0.4231) | Acc: (85.32%) (15398/18048)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 150 |  Loss: (0.4247) | Acc: (85.25%) (16478/19328)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 160 |  Loss: (0.4266) | Acc: (85.20%) (17557/20608)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 170 |  Loss: (0.4260) | Acc: (85.19%) (18647/21888)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 180 |  Loss: (0.4285) | Acc: (85.12%) (19720/23168)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 190 |  Loss: (0.4280) | Acc: (85.15%) (20818/24448)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 200 |  Loss: (0.4297) | Acc: (85.08%) (21890/25728)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 210 |  Loss: (0.4315) | Acc: (85.07%) (22977/27008)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 220 |  Loss: (0.4317) | Acc: (85.10%) (24074/28288)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 230 |  Loss: (0.4326) | Acc: (85.06%) (25151/29568)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 240 |  Loss: (0.4329) | Acc: (84.98%) (26216/30848)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 250 |  Loss: (0.4333) | Acc: (84.95%) (27294/32128)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 260 |  Loss: (0.4335) | Acc: (84.93%) (28373/33408)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 270 |  Loss: (0.4337) | Acc: (84.91%) (29455/34688)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 280 |  Loss: (0.4339) | Acc: (84.89%) (30532/35968)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 290 |  Loss: (0.4345) | Acc: (84.85%) (31606/37248)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 300 |  Loss: (0.4357) | Acc: (84.80%) (32672/38528)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 310 |  Loss: (0.4378) | Acc: (84.74%) (33733/39808)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 320 |  Loss: (0.4380) | Acc: (84.72%) (34811/41088)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 330 |  Loss: (0.4371) | Acc: (84.78%) (35921/42368)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 340 |  Loss: (0.4370) | Acc: (84.79%) (37010/43648)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 350 |  Loss: (0.4365) | Acc: (84.80%) (38100/44928)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 360 |  Loss: (0.4376) | Acc: (84.76%) (39166/46208)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 370 |  Loss: (0.4358) | Acc: (84.82%) (40277/47488)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 380 |  Loss: (0.4371) | Acc: (84.79%) (41349/48768)\n",
      "lr: 0.001\n",
      "Epoch: 18 | Batch_idx: 390 |  Loss: (0.4386) | Acc: (84.75%) (42375/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.1558) | Acc: (30.88%) (3088/10000)\n",
      "Epoch: 19 | Batch_idx: 0 |  Loss: (0.4793) | Acc: (81.25%) (104/128)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 10 |  Loss: (0.3725) | Acc: (87.07%) (1226/1408)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 20 |  Loss: (0.3842) | Acc: (86.50%) (2325/2688)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 30 |  Loss: (0.3863) | Acc: (86.44%) (3430/3968)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 40 |  Loss: (0.3936) | Acc: (86.20%) (4524/5248)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 50 |  Loss: (0.3952) | Acc: (86.18%) (5626/6528)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 60 |  Loss: (0.3985) | Acc: (86.09%) (6722/7808)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 70 |  Loss: (0.3951) | Acc: (86.23%) (7837/9088)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 80 |  Loss: (0.3942) | Acc: (86.32%) (8950/10368)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 90 |  Loss: (0.3953) | Acc: (86.14%) (10034/11648)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 100 |  Loss: (0.3932) | Acc: (86.13%) (11135/12928)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 110 |  Loss: (0.3961) | Acc: (86.02%) (12222/14208)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 120 |  Loss: (0.4002) | Acc: (85.92%) (13308/15488)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 130 |  Loss: (0.4044) | Acc: (85.85%) (14396/16768)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 140 |  Loss: (0.4077) | Acc: (85.72%) (15470/18048)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 150 |  Loss: (0.4079) | Acc: (85.66%) (16557/19328)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 160 |  Loss: (0.4095) | Acc: (85.68%) (17657/20608)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 170 |  Loss: (0.4095) | Acc: (85.71%) (18761/21888)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 180 |  Loss: (0.4077) | Acc: (85.81%) (19881/23168)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 190 |  Loss: (0.4072) | Acc: (85.82%) (20981/24448)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 200 |  Loss: (0.4108) | Acc: (85.69%) (22047/25728)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 210 |  Loss: (0.4125) | Acc: (85.66%) (23135/27008)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 220 |  Loss: (0.4115) | Acc: (85.64%) (24227/28288)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 230 |  Loss: (0.4109) | Acc: (85.63%) (25320/29568)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 240 |  Loss: (0.4129) | Acc: (85.57%) (26397/30848)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 250 |  Loss: (0.4141) | Acc: (85.53%) (27480/32128)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 260 |  Loss: (0.4148) | Acc: (85.54%) (28578/33408)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 270 |  Loss: (0.4141) | Acc: (85.58%) (29685/34688)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 280 |  Loss: (0.4155) | Acc: (85.54%) (30766/35968)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 290 |  Loss: (0.4153) | Acc: (85.56%) (31871/37248)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 300 |  Loss: (0.4168) | Acc: (85.53%) (32954/38528)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 310 |  Loss: (0.4170) | Acc: (85.54%) (34050/39808)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 320 |  Loss: (0.4166) | Acc: (85.54%) (35148/41088)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 330 |  Loss: (0.4166) | Acc: (85.56%) (36249/42368)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 340 |  Loss: (0.4170) | Acc: (85.53%) (37332/43648)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 350 |  Loss: (0.4169) | Acc: (85.51%) (38420/44928)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 360 |  Loss: (0.4169) | Acc: (85.52%) (39518/46208)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 370 |  Loss: (0.4170) | Acc: (85.52%) (40612/47488)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 380 |  Loss: (0.4171) | Acc: (85.54%) (41718/48768)\n",
      "lr: 0.001\n",
      "Epoch: 19 | Batch_idx: 390 |  Loss: (0.4159) | Acc: (85.59%) (42794/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.8277) | Acc: (26.94%) (2694/10000)\n",
      "Epoch: 20 | Batch_idx: 0 |  Loss: (0.3413) | Acc: (89.06%) (114/128)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 10 |  Loss: (0.3843) | Acc: (86.65%) (1220/1408)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 20 |  Loss: (0.3945) | Acc: (86.46%) (2324/2688)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 30 |  Loss: (0.4063) | Acc: (85.84%) (3406/3968)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 40 |  Loss: (0.4099) | Acc: (85.84%) (4505/5248)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 50 |  Loss: (0.4111) | Acc: (85.81%) (5602/6528)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 60 |  Loss: (0.4110) | Acc: (85.51%) (6677/7808)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 70 |  Loss: (0.4116) | Acc: (85.49%) (7769/9088)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 80 |  Loss: (0.4027) | Acc: (85.91%) (8907/10368)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 90 |  Loss: (0.4010) | Acc: (86.03%) (10021/11648)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 100 |  Loss: (0.4002) | Acc: (86.09%) (11130/12928)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 110 |  Loss: (0.4003) | Acc: (86.13%) (12237/14208)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 120 |  Loss: (0.3991) | Acc: (86.17%) (13346/15488)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 130 |  Loss: (0.4025) | Acc: (85.97%) (14416/16768)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 140 |  Loss: (0.4013) | Acc: (85.98%) (15517/18048)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 150 |  Loss: (0.4005) | Acc: (86.03%) (16627/19328)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 160 |  Loss: (0.4008) | Acc: (85.98%) (17719/20608)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 170 |  Loss: (0.4025) | Acc: (85.93%) (18809/21888)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 180 |  Loss: (0.4024) | Acc: (85.92%) (19907/23168)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 190 |  Loss: (0.4026) | Acc: (85.93%) (21009/24448)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 200 |  Loss: (0.4041) | Acc: (85.91%) (22103/25728)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 210 |  Loss: (0.4043) | Acc: (85.86%) (23190/27008)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 220 |  Loss: (0.4073) | Acc: (85.83%) (24280/28288)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 230 |  Loss: (0.4070) | Acc: (85.87%) (25391/29568)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 240 |  Loss: (0.4081) | Acc: (85.86%) (26486/30848)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 250 |  Loss: (0.4075) | Acc: (85.82%) (27573/32128)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 260 |  Loss: (0.4071) | Acc: (85.86%) (28683/33408)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 270 |  Loss: (0.4091) | Acc: (85.78%) (29757/34688)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 280 |  Loss: (0.4092) | Acc: (85.79%) (30858/35968)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 290 |  Loss: (0.4090) | Acc: (85.80%) (31960/37248)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 300 |  Loss: (0.4084) | Acc: (85.78%) (33049/38528)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 310 |  Loss: (0.4073) | Acc: (85.81%) (34160/39808)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 320 |  Loss: (0.4072) | Acc: (85.84%) (35271/41088)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 330 |  Loss: (0.4064) | Acc: (85.85%) (36371/42368)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 340 |  Loss: (0.4071) | Acc: (85.84%) (37467/43648)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 350 |  Loss: (0.4059) | Acc: (85.88%) (38585/44928)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 360 |  Loss: (0.4062) | Acc: (85.85%) (39671/46208)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 370 |  Loss: (0.4066) | Acc: (85.85%) (40768/47488)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 380 |  Loss: (0.4068) | Acc: (85.86%) (41871/48768)\n",
      "lr: 0.001\n",
      "Epoch: 20 | Batch_idx: 390 |  Loss: (0.4079) | Acc: (85.81%) (42906/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3391) | Acc: (39.49%) (3949/10000)\n",
      "Epoch: 21 | Batch_idx: 0 |  Loss: (0.4583) | Acc: (85.16%) (109/128)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 10 |  Loss: (0.4108) | Acc: (85.87%) (1209/1408)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 20 |  Loss: (0.3752) | Acc: (86.98%) (2338/2688)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 30 |  Loss: (0.3695) | Acc: (87.12%) (3457/3968)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 40 |  Loss: (0.3760) | Acc: (86.79%) (4555/5248)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 50 |  Loss: (0.3712) | Acc: (87.13%) (5688/6528)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 60 |  Loss: (0.3741) | Acc: (87.12%) (6802/7808)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 70 |  Loss: (0.3793) | Acc: (86.96%) (7903/9088)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 80 |  Loss: (0.3831) | Acc: (86.88%) (9008/10368)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 90 |  Loss: (0.3801) | Acc: (87.00%) (10134/11648)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 100 |  Loss: (0.3811) | Acc: (86.90%) (11234/12928)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 110 |  Loss: (0.3860) | Acc: (86.71%) (12320/14208)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 120 |  Loss: (0.3841) | Acc: (86.81%) (13445/15488)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 130 |  Loss: (0.3845) | Acc: (86.83%) (14560/16768)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 140 |  Loss: (0.3857) | Acc: (86.72%) (15651/18048)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 150 |  Loss: (0.3861) | Acc: (86.67%) (16752/19328)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 160 |  Loss: (0.3890) | Acc: (86.53%) (17832/20608)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 170 |  Loss: (0.3899) | Acc: (86.49%) (18930/21888)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 180 |  Loss: (0.3911) | Acc: (86.47%) (20033/23168)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 190 |  Loss: (0.3920) | Acc: (86.40%) (21123/24448)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 200 |  Loss: (0.3926) | Acc: (86.40%) (22228/25728)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 210 |  Loss: (0.3919) | Acc: (86.45%) (23348/27008)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 220 |  Loss: (0.3908) | Acc: (86.49%) (24467/28288)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 230 |  Loss: (0.3914) | Acc: (86.47%) (25566/29568)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 240 |  Loss: (0.3910) | Acc: (86.46%) (26672/30848)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 250 |  Loss: (0.3924) | Acc: (86.42%) (27765/32128)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 260 |  Loss: (0.3944) | Acc: (86.33%) (28842/33408)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 270 |  Loss: (0.3942) | Acc: (86.35%) (29953/34688)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 280 |  Loss: (0.3958) | Acc: (86.29%) (31035/35968)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 290 |  Loss: (0.3962) | Acc: (86.25%) (32125/37248)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 300 |  Loss: (0.3963) | Acc: (86.25%) (33232/38528)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 310 |  Loss: (0.3965) | Acc: (86.26%) (34338/39808)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 320 |  Loss: (0.3982) | Acc: (86.20%) (35416/41088)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 330 |  Loss: (0.3974) | Acc: (86.21%) (36526/42368)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 340 |  Loss: (0.3981) | Acc: (86.16%) (37608/43648)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 350 |  Loss: (0.3984) | Acc: (86.12%) (38692/44928)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 360 |  Loss: (0.3983) | Acc: (86.13%) (39797/46208)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 370 |  Loss: (0.3994) | Acc: (86.06%) (40868/47488)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 380 |  Loss: (0.3998) | Acc: (86.03%) (41954/48768)\n",
      "lr: 0.001\n",
      "Epoch: 21 | Batch_idx: 390 |  Loss: (0.4013) | Acc: (85.97%) (42984/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.9074) | Acc: (33.03%) (3303/10000)\n",
      "Epoch: 22 | Batch_idx: 0 |  Loss: (0.3103) | Acc: (88.28%) (113/128)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 10 |  Loss: (0.3930) | Acc: (86.15%) (1213/1408)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 20 |  Loss: (0.3929) | Acc: (86.27%) (2319/2688)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 30 |  Loss: (0.4030) | Acc: (86.21%) (3421/3968)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 40 |  Loss: (0.4025) | Acc: (86.17%) (4522/5248)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 50 |  Loss: (0.4005) | Acc: (86.29%) (5633/6528)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 60 |  Loss: (0.3957) | Acc: (86.35%) (6742/7808)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 70 |  Loss: (0.3918) | Acc: (86.43%) (7855/9088)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 80 |  Loss: (0.3925) | Acc: (86.32%) (8950/10368)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 90 |  Loss: (0.3967) | Acc: (86.26%) (10047/11648)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 100 |  Loss: (0.3961) | Acc: (86.22%) (11147/12928)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 110 |  Loss: (0.3952) | Acc: (86.28%) (12258/14208)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 120 |  Loss: (0.3929) | Acc: (86.39%) (13380/15488)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 130 |  Loss: (0.3943) | Acc: (86.39%) (14486/16768)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 140 |  Loss: (0.3916) | Acc: (86.51%) (15613/18048)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 150 |  Loss: (0.3904) | Acc: (86.56%) (16730/19328)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 160 |  Loss: (0.3893) | Acc: (86.54%) (17834/20608)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 170 |  Loss: (0.3907) | Acc: (86.49%) (18930/21888)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 180 |  Loss: (0.3889) | Acc: (86.52%) (20045/23168)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 190 |  Loss: (0.3878) | Acc: (86.56%) (21161/24448)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 200 |  Loss: (0.3881) | Acc: (86.51%) (22257/25728)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 210 |  Loss: (0.3876) | Acc: (86.53%) (23371/27008)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 220 |  Loss: (0.3871) | Acc: (86.57%) (24489/28288)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 230 |  Loss: (0.3864) | Acc: (86.62%) (25611/29568)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 240 |  Loss: (0.3859) | Acc: (86.64%) (26728/30848)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 250 |  Loss: (0.3854) | Acc: (86.66%) (27842/32128)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 260 |  Loss: (0.3845) | Acc: (86.67%) (28955/33408)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 270 |  Loss: (0.3854) | Acc: (86.65%) (30056/34688)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 280 |  Loss: (0.3857) | Acc: (86.61%) (31152/35968)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 290 |  Loss: (0.3849) | Acc: (86.64%) (32273/37248)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 300 |  Loss: (0.3851) | Acc: (86.67%) (33394/38528)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 310 |  Loss: (0.3852) | Acc: (86.66%) (34498/39808)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 320 |  Loss: (0.3861) | Acc: (86.61%) (35587/41088)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 330 |  Loss: (0.3848) | Acc: (86.66%) (36715/42368)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 340 |  Loss: (0.3837) | Acc: (86.69%) (37839/43648)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 350 |  Loss: (0.3842) | Acc: (86.67%) (38940/44928)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 360 |  Loss: (0.3832) | Acc: (86.71%) (40069/46208)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 370 |  Loss: (0.3832) | Acc: (86.70%) (41171/47488)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 380 |  Loss: (0.3847) | Acc: (86.68%) (42272/48768)\n",
      "lr: 0.001\n",
      "Epoch: 22 | Batch_idx: 390 |  Loss: (0.3841) | Acc: (86.72%) (43362/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.6162) | Acc: (35.61%) (3561/10000)\n",
      "Epoch: 23 | Batch_idx: 0 |  Loss: (0.4188) | Acc: (86.72%) (111/128)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 10 |  Loss: (0.3956) | Acc: (85.65%) (1206/1408)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 20 |  Loss: (0.3782) | Acc: (86.31%) (2320/2688)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 30 |  Loss: (0.3971) | Acc: (86.16%) (3419/3968)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 40 |  Loss: (0.3915) | Acc: (86.22%) (4525/5248)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 50 |  Loss: (0.3882) | Acc: (86.17%) (5625/6528)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 60 |  Loss: (0.3863) | Acc: (86.31%) (6739/7808)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 70 |  Loss: (0.3816) | Acc: (86.45%) (7857/9088)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 80 |  Loss: (0.3788) | Acc: (86.48%) (8966/10368)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 90 |  Loss: (0.3806) | Acc: (86.38%) (10061/11648)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 100 |  Loss: (0.3798) | Acc: (86.46%) (11178/12928)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 110 |  Loss: (0.3768) | Acc: (86.56%) (12298/14208)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 120 |  Loss: (0.3779) | Acc: (86.54%) (13404/15488)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 130 |  Loss: (0.3808) | Acc: (86.50%) (14505/16768)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 140 |  Loss: (0.3783) | Acc: (86.56%) (15622/18048)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 150 |  Loss: (0.3766) | Acc: (86.69%) (16755/19328)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 160 |  Loss: (0.3776) | Acc: (86.70%) (17868/20608)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 170 |  Loss: (0.3761) | Acc: (86.79%) (18996/21888)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 180 |  Loss: (0.3736) | Acc: (86.88%) (20129/23168)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 190 |  Loss: (0.3741) | Acc: (86.86%) (21236/24448)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 200 |  Loss: (0.3758) | Acc: (86.83%) (22339/25728)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 210 |  Loss: (0.3763) | Acc: (86.83%) (23452/27008)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 220 |  Loss: (0.3756) | Acc: (86.89%) (24579/28288)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 230 |  Loss: (0.3772) | Acc: (86.89%) (25693/29568)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 240 |  Loss: (0.3764) | Acc: (86.93%) (26817/30848)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 250 |  Loss: (0.3760) | Acc: (86.94%) (27933/32128)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 260 |  Loss: (0.3758) | Acc: (86.94%) (29044/33408)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 270 |  Loss: (0.3781) | Acc: (86.89%) (30140/34688)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 280 |  Loss: (0.3788) | Acc: (86.90%) (31255/35968)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 290 |  Loss: (0.3779) | Acc: (86.93%) (32378/37248)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 300 |  Loss: (0.3782) | Acc: (86.89%) (33477/38528)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 310 |  Loss: (0.3779) | Acc: (86.90%) (34592/39808)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 320 |  Loss: (0.3780) | Acc: (86.89%) (35700/41088)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 330 |  Loss: (0.3780) | Acc: (86.90%) (36819/42368)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 340 |  Loss: (0.3793) | Acc: (86.86%) (37914/43648)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 350 |  Loss: (0.3794) | Acc: (86.83%) (39009/44928)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 360 |  Loss: (0.3797) | Acc: (86.83%) (40122/46208)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 370 |  Loss: (0.3807) | Acc: (86.82%) (41227/47488)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 380 |  Loss: (0.3802) | Acc: (86.82%) (42342/48768)\n",
      "lr: 0.001\n",
      "Epoch: 23 | Batch_idx: 390 |  Loss: (0.3794) | Acc: (86.83%) (43415/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.1230) | Acc: (32.42%) (3242/10000)\n",
      "Epoch: 24 | Batch_idx: 0 |  Loss: (0.3129) | Acc: (87.50%) (112/128)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 10 |  Loss: (0.3502) | Acc: (88.35%) (1244/1408)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 20 |  Loss: (0.3599) | Acc: (87.50%) (2352/2688)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 30 |  Loss: (0.3603) | Acc: (87.47%) (3471/3968)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 40 |  Loss: (0.3661) | Acc: (87.02%) (4567/5248)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 50 |  Loss: (0.3735) | Acc: (86.67%) (5658/6528)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 60 |  Loss: (0.3673) | Acc: (86.82%) (6779/7808)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 70 |  Loss: (0.3697) | Acc: (86.91%) (7898/9088)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 80 |  Loss: (0.3688) | Acc: (86.91%) (9011/10368)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 90 |  Loss: (0.3676) | Acc: (86.93%) (10126/11648)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 100 |  Loss: (0.3689) | Acc: (86.95%) (11241/12928)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 110 |  Loss: (0.3689) | Acc: (86.99%) (12359/14208)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 120 |  Loss: (0.3700) | Acc: (86.98%) (13471/15488)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 130 |  Loss: (0.3679) | Acc: (87.14%) (14612/16768)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 140 |  Loss: (0.3658) | Acc: (87.20%) (15738/18048)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 150 |  Loss: (0.3625) | Acc: (87.28%) (16870/19328)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 160 |  Loss: (0.3588) | Acc: (87.44%) (18019/20608)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 170 |  Loss: (0.3598) | Acc: (87.40%) (19131/21888)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 180 |  Loss: (0.3595) | Acc: (87.44%) (20258/23168)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 190 |  Loss: (0.3617) | Acc: (87.40%) (21368/24448)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 200 |  Loss: (0.3631) | Acc: (87.33%) (22468/25728)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 210 |  Loss: (0.3617) | Acc: (87.40%) (23606/27008)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 220 |  Loss: (0.3614) | Acc: (87.37%) (24715/28288)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 230 |  Loss: (0.3606) | Acc: (87.34%) (25825/29568)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 240 |  Loss: (0.3619) | Acc: (87.30%) (26930/30848)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 250 |  Loss: (0.3620) | Acc: (87.30%) (28047/32128)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 260 |  Loss: (0.3624) | Acc: (87.27%) (29156/33408)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 270 |  Loss: (0.3627) | Acc: (87.26%) (30269/34688)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 280 |  Loss: (0.3634) | Acc: (87.26%) (31387/35968)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 290 |  Loss: (0.3632) | Acc: (87.29%) (32514/37248)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 300 |  Loss: (0.3632) | Acc: (87.28%) (33629/38528)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 310 |  Loss: (0.3644) | Acc: (87.24%) (34729/39808)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 320 |  Loss: (0.3653) | Acc: (87.23%) (35840/41088)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 330 |  Loss: (0.3658) | Acc: (87.21%) (36951/42368)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 340 |  Loss: (0.3665) | Acc: (87.17%) (38046/43648)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 350 |  Loss: (0.3678) | Acc: (87.12%) (39140/44928)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 360 |  Loss: (0.3684) | Acc: (87.12%) (40258/46208)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 370 |  Loss: (0.3683) | Acc: (87.09%) (41358/47488)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 380 |  Loss: (0.3686) | Acc: (87.09%) (42470/48768)\n",
      "lr: 0.001\n",
      "Epoch: 24 | Batch_idx: 390 |  Loss: (0.3688) | Acc: (87.07%) (43534/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.5871) | Acc: (31.11%) (3111/10000)\n",
      "Epoch: 25 | Batch_idx: 0 |  Loss: (0.3356) | Acc: (88.28%) (113/128)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 10 |  Loss: (0.3710) | Acc: (87.00%) (1225/1408)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 20 |  Loss: (0.3668) | Acc: (87.28%) (2346/2688)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 30 |  Loss: (0.3700) | Acc: (87.17%) (3459/3968)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 40 |  Loss: (0.3651) | Acc: (87.16%) (4574/5248)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 50 |  Loss: (0.3640) | Acc: (87.53%) (5714/6528)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 60 |  Loss: (0.3594) | Acc: (87.54%) (6835/7808)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 70 |  Loss: (0.3626) | Acc: (87.38%) (7941/9088)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 80 |  Loss: (0.3616) | Acc: (87.39%) (9061/10368)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 90 |  Loss: (0.3559) | Acc: (87.62%) (10206/11648)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 100 |  Loss: (0.3555) | Acc: (87.60%) (11325/12928)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 110 |  Loss: (0.3532) | Acc: (87.68%) (12457/14208)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 120 |  Loss: (0.3531) | Acc: (87.66%) (13577/15488)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 130 |  Loss: (0.3522) | Acc: (87.66%) (14699/16768)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 140 |  Loss: (0.3524) | Acc: (87.63%) (15815/18048)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 150 |  Loss: (0.3550) | Acc: (87.56%) (16923/19328)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 160 |  Loss: (0.3564) | Acc: (87.53%) (18038/20608)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 170 |  Loss: (0.3568) | Acc: (87.54%) (19160/21888)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 180 |  Loss: (0.3562) | Acc: (87.53%) (20278/23168)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 190 |  Loss: (0.3562) | Acc: (87.49%) (21389/24448)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 200 |  Loss: (0.3553) | Acc: (87.53%) (22520/25728)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 210 |  Loss: (0.3557) | Acc: (87.54%) (23642/27008)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 220 |  Loss: (0.3560) | Acc: (87.52%) (24757/28288)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 230 |  Loss: (0.3550) | Acc: (87.55%) (25888/29568)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 240 |  Loss: (0.3553) | Acc: (87.55%) (27008/30848)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 250 |  Loss: (0.3566) | Acc: (87.52%) (28119/32128)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 260 |  Loss: (0.3567) | Acc: (87.47%) (29221/33408)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 270 |  Loss: (0.3570) | Acc: (87.45%) (30336/34688)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 280 |  Loss: (0.3583) | Acc: (87.46%) (31459/35968)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 290 |  Loss: (0.3590) | Acc: (87.45%) (32573/37248)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 300 |  Loss: (0.3584) | Acc: (87.49%) (33709/38528)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 310 |  Loss: (0.3581) | Acc: (87.51%) (34835/39808)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 320 |  Loss: (0.3579) | Acc: (87.48%) (35945/41088)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 330 |  Loss: (0.3583) | Acc: (87.48%) (37064/42368)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 340 |  Loss: (0.3587) | Acc: (87.44%) (38165/43648)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 350 |  Loss: (0.3595) | Acc: (87.40%) (39265/44928)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 360 |  Loss: (0.3610) | Acc: (87.34%) (40357/46208)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 370 |  Loss: (0.3621) | Acc: (87.32%) (41465/47488)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 380 |  Loss: (0.3629) | Acc: (87.29%) (42569/48768)\n",
      "lr: 0.001\n",
      "Epoch: 25 | Batch_idx: 390 |  Loss: (0.3623) | Acc: (87.32%) (43658/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.5843) | Acc: (34.63%) (3463/10000)\n",
      "Epoch: 26 | Batch_idx: 0 |  Loss: (0.4230) | Acc: (85.16%) (109/128)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 10 |  Loss: (0.3494) | Acc: (87.43%) (1231/1408)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 20 |  Loss: (0.3401) | Acc: (88.21%) (2371/2688)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 30 |  Loss: (0.3387) | Acc: (88.26%) (3502/3968)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 40 |  Loss: (0.3307) | Acc: (88.47%) (4643/5248)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 50 |  Loss: (0.3310) | Acc: (88.25%) (5761/6528)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 60 |  Loss: (0.3287) | Acc: (88.46%) (6907/7808)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 70 |  Loss: (0.3380) | Acc: (88.01%) (7998/9088)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 80 |  Loss: (0.3388) | Acc: (88.00%) (9124/10368)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 90 |  Loss: (0.3366) | Acc: (88.05%) (10256/11648)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 100 |  Loss: (0.3387) | Acc: (88.03%) (11380/12928)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 110 |  Loss: (0.3389) | Acc: (88.03%) (12508/14208)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 120 |  Loss: (0.3392) | Acc: (88.01%) (13631/15488)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 130 |  Loss: (0.3387) | Acc: (88.05%) (14765/16768)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 140 |  Loss: (0.3409) | Acc: (87.95%) (15874/18048)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 150 |  Loss: (0.3401) | Acc: (87.98%) (17004/19328)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 160 |  Loss: (0.3400) | Acc: (87.97%) (18128/20608)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 170 |  Loss: (0.3408) | Acc: (87.94%) (19249/21888)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 180 |  Loss: (0.3399) | Acc: (87.96%) (20379/23168)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 190 |  Loss: (0.3420) | Acc: (87.93%) (21497/24448)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 200 |  Loss: (0.3423) | Acc: (87.92%) (22619/25728)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 210 |  Loss: (0.3428) | Acc: (87.93%) (23748/27008)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 220 |  Loss: (0.3445) | Acc: (87.86%) (24854/28288)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 230 |  Loss: (0.3449) | Acc: (87.86%) (25978/29568)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 240 |  Loss: (0.3448) | Acc: (87.86%) (27103/30848)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 250 |  Loss: (0.3459) | Acc: (87.80%) (28207/32128)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 260 |  Loss: (0.3458) | Acc: (87.82%) (29340/33408)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 270 |  Loss: (0.3449) | Acc: (87.83%) (30466/34688)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 280 |  Loss: (0.3465) | Acc: (87.79%) (31575/35968)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 290 |  Loss: (0.3471) | Acc: (87.75%) (32684/37248)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 300 |  Loss: (0.3473) | Acc: (87.74%) (33803/38528)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 310 |  Loss: (0.3471) | Acc: (87.76%) (34935/39808)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 320 |  Loss: (0.3466) | Acc: (87.76%) (36059/41088)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 330 |  Loss: (0.3465) | Acc: (87.75%) (37180/42368)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 340 |  Loss: (0.3470) | Acc: (87.74%) (38296/43648)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 350 |  Loss: (0.3471) | Acc: (87.74%) (39421/44928)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 360 |  Loss: (0.3464) | Acc: (87.77%) (40557/46208)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 370 |  Loss: (0.3472) | Acc: (87.77%) (41681/47488)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 380 |  Loss: (0.3468) | Acc: (87.78%) (42809/48768)\n",
      "lr: 0.001\n",
      "Epoch: 26 | Batch_idx: 390 |  Loss: (0.3474) | Acc: (87.75%) (43876/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.7656) | Acc: (34.83%) (3483/10000)\n",
      "Epoch: 27 | Batch_idx: 0 |  Loss: (0.3379) | Acc: (85.94%) (110/128)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 10 |  Loss: (0.3073) | Acc: (88.99%) (1253/1408)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 20 |  Loss: (0.3084) | Acc: (89.17%) (2397/2688)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 30 |  Loss: (0.3247) | Acc: (88.33%) (3505/3968)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 40 |  Loss: (0.3319) | Acc: (88.43%) (4641/5248)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 50 |  Loss: (0.3388) | Acc: (88.16%) (5755/6528)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 60 |  Loss: (0.3349) | Acc: (88.29%) (6894/7808)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 70 |  Loss: (0.3368) | Acc: (88.18%) (8014/9088)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 80 |  Loss: (0.3375) | Acc: (88.18%) (9143/10368)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 90 |  Loss: (0.3373) | Acc: (88.17%) (10270/11648)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 100 |  Loss: (0.3393) | Acc: (88.13%) (11393/12928)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 110 |  Loss: (0.3382) | Acc: (88.06%) (12511/14208)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 120 |  Loss: (0.3385) | Acc: (88.03%) (13634/15488)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 130 |  Loss: (0.3396) | Acc: (87.98%) (14752/16768)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 140 |  Loss: (0.3399) | Acc: (87.92%) (15868/18048)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 150 |  Loss: (0.3392) | Acc: (88.01%) (17010/19328)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 160 |  Loss: (0.3415) | Acc: (87.94%) (18123/20608)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 170 |  Loss: (0.3425) | Acc: (87.92%) (19244/21888)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 180 |  Loss: (0.3429) | Acc: (87.89%) (20362/23168)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 190 |  Loss: (0.3434) | Acc: (87.86%) (21481/24448)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 200 |  Loss: (0.3437) | Acc: (87.88%) (22610/25728)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 210 |  Loss: (0.3430) | Acc: (87.92%) (23745/27008)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 220 |  Loss: (0.3442) | Acc: (87.91%) (24868/28288)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 230 |  Loss: (0.3444) | Acc: (87.90%) (25990/29568)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 240 |  Loss: (0.3446) | Acc: (87.88%) (27110/30848)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 250 |  Loss: (0.3442) | Acc: (87.90%) (28239/32128)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 260 |  Loss: (0.3434) | Acc: (87.93%) (29374/33408)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 270 |  Loss: (0.3428) | Acc: (87.92%) (30496/34688)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 280 |  Loss: (0.3425) | Acc: (87.94%) (31632/35968)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 290 |  Loss: (0.3432) | Acc: (87.94%) (32755/37248)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 300 |  Loss: (0.3430) | Acc: (87.94%) (33883/38528)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 310 |  Loss: (0.3441) | Acc: (87.91%) (34994/39808)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 320 |  Loss: (0.3432) | Acc: (87.91%) (36122/41088)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 330 |  Loss: (0.3434) | Acc: (87.92%) (37251/42368)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 340 |  Loss: (0.3432) | Acc: (87.94%) (38386/43648)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 350 |  Loss: (0.3431) | Acc: (87.97%) (39522/44928)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 360 |  Loss: (0.3428) | Acc: (87.97%) (40650/46208)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 370 |  Loss: (0.3433) | Acc: (87.97%) (41773/47488)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 380 |  Loss: (0.3428) | Acc: (87.96%) (42896/48768)\n",
      "lr: 0.001\n",
      "Epoch: 27 | Batch_idx: 390 |  Loss: (0.3430) | Acc: (87.98%) (43992/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.4956) | Acc: (32.95%) (3295/10000)\n",
      "Epoch: 28 | Batch_idx: 0 |  Loss: (0.1940) | Acc: (96.09%) (123/128)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 10 |  Loss: (0.3004) | Acc: (89.56%) (1261/1408)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 20 |  Loss: (0.3127) | Acc: (89.69%) (2411/2688)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 30 |  Loss: (0.3156) | Acc: (89.39%) (3547/3968)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 40 |  Loss: (0.3179) | Acc: (89.06%) (4674/5248)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 50 |  Loss: (0.3167) | Acc: (88.99%) (5809/6528)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 60 |  Loss: (0.3204) | Acc: (88.90%) (6941/7808)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 70 |  Loss: (0.3194) | Acc: (89.01%) (8089/9088)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 80 |  Loss: (0.3206) | Acc: (89.01%) (9229/10368)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 90 |  Loss: (0.3243) | Acc: (88.88%) (10353/11648)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 100 |  Loss: (0.3212) | Acc: (88.87%) (11489/12928)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 110 |  Loss: (0.3235) | Acc: (88.77%) (12612/14208)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 120 |  Loss: (0.3244) | Acc: (88.77%) (13748/15488)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 130 |  Loss: (0.3267) | Acc: (88.60%) (14856/16768)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 140 |  Loss: (0.3253) | Acc: (88.69%) (16007/18048)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 150 |  Loss: (0.3271) | Acc: (88.60%) (17125/19328)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 160 |  Loss: (0.3271) | Acc: (88.57%) (18253/20608)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 170 |  Loss: (0.3268) | Acc: (88.56%) (19385/21888)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 180 |  Loss: (0.3277) | Acc: (88.54%) (20513/23168)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 190 |  Loss: (0.3299) | Acc: (88.50%) (21636/24448)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 200 |  Loss: (0.3302) | Acc: (88.47%) (22761/25728)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 210 |  Loss: (0.3295) | Acc: (88.47%) (23895/27008)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 220 |  Loss: (0.3301) | Acc: (88.47%) (25026/28288)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 230 |  Loss: (0.3296) | Acc: (88.50%) (26169/29568)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 240 |  Loss: (0.3302) | Acc: (88.50%) (27301/30848)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 250 |  Loss: (0.3310) | Acc: (88.52%) (28439/32128)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 260 |  Loss: (0.3307) | Acc: (88.52%) (29573/33408)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 270 |  Loss: (0.3308) | Acc: (88.53%) (30709/34688)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 280 |  Loss: (0.3308) | Acc: (88.51%) (31836/35968)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 290 |  Loss: (0.3329) | Acc: (88.40%) (32929/37248)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 300 |  Loss: (0.3330) | Acc: (88.41%) (34063/38528)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 310 |  Loss: (0.3328) | Acc: (88.42%) (35199/39808)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 320 |  Loss: (0.3338) | Acc: (88.36%) (36305/41088)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 330 |  Loss: (0.3341) | Acc: (88.35%) (37432/42368)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 340 |  Loss: (0.3348) | Acc: (88.32%) (38550/43648)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 350 |  Loss: (0.3342) | Acc: (88.34%) (39689/44928)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 360 |  Loss: (0.3325) | Acc: (88.39%) (40845/46208)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 370 |  Loss: (0.3339) | Acc: (88.35%) (41956/47488)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 380 |  Loss: (0.3337) | Acc: (88.34%) (43080/48768)\n",
      "lr: 0.001\n",
      "Epoch: 28 | Batch_idx: 390 |  Loss: (0.3342) | Acc: (88.34%) (44169/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.9766) | Acc: (37.05%) (3705/10000)\n",
      "Epoch: 29 | Batch_idx: 0 |  Loss: (0.2564) | Acc: (89.84%) (115/128)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 10 |  Loss: (0.2973) | Acc: (89.70%) (1263/1408)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 20 |  Loss: (0.3163) | Acc: (88.99%) (2392/2688)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 30 |  Loss: (0.3081) | Acc: (89.21%) (3540/3968)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 40 |  Loss: (0.3159) | Acc: (88.99%) (4670/5248)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 50 |  Loss: (0.3163) | Acc: (88.96%) (5807/6528)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 60 |  Loss: (0.3199) | Acc: (88.76%) (6930/7808)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 70 |  Loss: (0.3158) | Acc: (88.88%) (8077/9088)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 80 |  Loss: (0.3186) | Acc: (88.74%) (9201/10368)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 90 |  Loss: (0.3184) | Acc: (88.79%) (10342/11648)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 100 |  Loss: (0.3176) | Acc: (88.77%) (11476/12928)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 110 |  Loss: (0.3157) | Acc: (88.84%) (12622/14208)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 120 |  Loss: (0.3171) | Acc: (88.84%) (13760/15488)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 130 |  Loss: (0.3201) | Acc: (88.67%) (14868/16768)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 140 |  Loss: (0.3212) | Acc: (88.69%) (16007/18048)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 150 |  Loss: (0.3202) | Acc: (88.71%) (17145/19328)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 160 |  Loss: (0.3211) | Acc: (88.68%) (18276/20608)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 170 |  Loss: (0.3220) | Acc: (88.63%) (19399/21888)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 180 |  Loss: (0.3229) | Acc: (88.55%) (20516/23168)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 190 |  Loss: (0.3225) | Acc: (88.60%) (21661/24448)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 200 |  Loss: (0.3237) | Acc: (88.55%) (22781/25728)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 210 |  Loss: (0.3244) | Acc: (88.48%) (23897/27008)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 220 |  Loss: (0.3250) | Acc: (88.47%) (25027/28288)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 230 |  Loss: (0.3242) | Acc: (88.53%) (26177/29568)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 240 |  Loss: (0.3252) | Acc: (88.52%) (27307/30848)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 250 |  Loss: (0.3246) | Acc: (88.55%) (28449/32128)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 260 |  Loss: (0.3251) | Acc: (88.54%) (29579/33408)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 270 |  Loss: (0.3257) | Acc: (88.52%) (30707/34688)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 280 |  Loss: (0.3252) | Acc: (88.53%) (31841/35968)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 290 |  Loss: (0.3255) | Acc: (88.53%) (32974/37248)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 300 |  Loss: (0.3261) | Acc: (88.52%) (34104/38528)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 310 |  Loss: (0.3242) | Acc: (88.59%) (35264/39808)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 320 |  Loss: (0.3235) | Acc: (88.59%) (36399/41088)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 330 |  Loss: (0.3247) | Acc: (88.54%) (37511/42368)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 340 |  Loss: (0.3260) | Acc: (88.51%) (38632/43648)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 350 |  Loss: (0.3258) | Acc: (88.50%) (39760/44928)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 360 |  Loss: (0.3260) | Acc: (88.49%) (40888/46208)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 370 |  Loss: (0.3267) | Acc: (88.44%) (41998/47488)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 380 |  Loss: (0.3265) | Acc: (88.45%) (43134/48768)\n",
      "lr: 0.001\n",
      "Epoch: 29 | Batch_idx: 390 |  Loss: (0.3272) | Acc: (88.43%) (44216/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (4.6688) | Acc: (28.37%) (2837/10000)\n",
      "Epoch: 30 | Batch_idx: 0 |  Loss: (0.2651) | Acc: (89.84%) (115/128)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 10 |  Loss: (0.2923) | Acc: (89.70%) (1263/1408)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 20 |  Loss: (0.3014) | Acc: (89.69%) (2411/2688)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 30 |  Loss: (0.2991) | Acc: (89.72%) (3560/3968)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 40 |  Loss: (0.2948) | Acc: (89.86%) (4716/5248)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 50 |  Loss: (0.3017) | Acc: (89.57%) (5847/6528)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 60 |  Loss: (0.3008) | Acc: (89.59%) (6995/7808)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 70 |  Loss: (0.2993) | Acc: (89.63%) (8146/9088)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 80 |  Loss: (0.2997) | Acc: (89.57%) (9287/10368)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 90 |  Loss: (0.3004) | Acc: (89.61%) (10438/11648)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 100 |  Loss: (0.3035) | Acc: (89.53%) (11575/12928)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 110 |  Loss: (0.3067) | Acc: (89.40%) (12702/14208)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 120 |  Loss: (0.3099) | Acc: (89.20%) (13816/15488)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 130 |  Loss: (0.3120) | Acc: (89.19%) (14955/16768)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 140 |  Loss: (0.3140) | Acc: (89.01%) (16065/18048)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 150 |  Loss: (0.3135) | Acc: (89.06%) (17214/19328)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 160 |  Loss: (0.3150) | Acc: (89.02%) (18346/20608)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 170 |  Loss: (0.3146) | Acc: (89.04%) (19490/21888)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 180 |  Loss: (0.3171) | Acc: (88.98%) (20615/23168)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 190 |  Loss: (0.3181) | Acc: (88.90%) (21735/24448)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 200 |  Loss: (0.3167) | Acc: (88.99%) (22896/25728)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 210 |  Loss: (0.3173) | Acc: (88.94%) (24022/27008)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 220 |  Loss: (0.3181) | Acc: (88.92%) (25155/28288)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 230 |  Loss: (0.3186) | Acc: (88.96%) (26304/29568)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 240 |  Loss: (0.3185) | Acc: (89.01%) (27459/30848)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 250 |  Loss: (0.3184) | Acc: (89.02%) (28601/32128)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 260 |  Loss: (0.3182) | Acc: (89.01%) (29737/33408)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 270 |  Loss: (0.3179) | Acc: (89.01%) (30877/34688)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 280 |  Loss: (0.3177) | Acc: (89.01%) (32014/35968)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 290 |  Loss: (0.3184) | Acc: (88.98%) (33143/37248)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 300 |  Loss: (0.3186) | Acc: (89.00%) (34288/38528)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 310 |  Loss: (0.3191) | Acc: (88.97%) (35418/39808)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 320 |  Loss: (0.3195) | Acc: (88.96%) (36553/41088)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 330 |  Loss: (0.3198) | Acc: (88.94%) (37683/42368)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 340 |  Loss: (0.3202) | Acc: (88.89%) (38798/43648)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 350 |  Loss: (0.3196) | Acc: (88.90%) (39940/44928)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 360 |  Loss: (0.3196) | Acc: (88.90%) (41081/46208)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 370 |  Loss: (0.3187) | Acc: (88.91%) (42221/47488)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 380 |  Loss: (0.3184) | Acc: (88.91%) (43358/48768)\n",
      "lr: 0.001\n",
      "Epoch: 30 | Batch_idx: 390 |  Loss: (0.3190) | Acc: (88.88%) (44439/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.1234) | Acc: (33.07%) (3307/10000)\n",
      "Epoch: 31 | Batch_idx: 0 |  Loss: (0.2726) | Acc: (91.41%) (117/128)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 10 |  Loss: (0.3002) | Acc: (89.56%) (1261/1408)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 20 |  Loss: (0.3122) | Acc: (89.32%) (2401/2688)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 30 |  Loss: (0.3200) | Acc: (89.16%) (3538/3968)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 40 |  Loss: (0.3204) | Acc: (88.89%) (4665/5248)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 50 |  Loss: (0.3180) | Acc: (88.86%) (5801/6528)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 60 |  Loss: (0.3202) | Acc: (88.83%) (6936/7808)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 70 |  Loss: (0.3142) | Acc: (89.02%) (8090/9088)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 80 |  Loss: (0.3116) | Acc: (89.13%) (9241/10368)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 90 |  Loss: (0.3115) | Acc: (89.17%) (10386/11648)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 100 |  Loss: (0.3140) | Acc: (89.11%) (11520/12928)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 110 |  Loss: (0.3124) | Acc: (89.10%) (12659/14208)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 120 |  Loss: (0.3146) | Acc: (89.02%) (13787/15488)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 130 |  Loss: (0.3162) | Acc: (88.90%) (14907/16768)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 140 |  Loss: (0.3162) | Acc: (88.92%) (16048/18048)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 150 |  Loss: (0.3171) | Acc: (88.90%) (17182/19328)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 160 |  Loss: (0.3174) | Acc: (88.86%) (18312/20608)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 170 |  Loss: (0.3172) | Acc: (88.88%) (19453/21888)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 180 |  Loss: (0.3179) | Acc: (88.89%) (20595/23168)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 190 |  Loss: (0.3170) | Acc: (88.90%) (21735/24448)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 200 |  Loss: (0.3162) | Acc: (88.93%) (22880/25728)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 210 |  Loss: (0.3162) | Acc: (88.91%) (24012/27008)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 220 |  Loss: (0.3166) | Acc: (88.88%) (25142/28288)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 230 |  Loss: (0.3164) | Acc: (88.91%) (26289/29568)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 240 |  Loss: (0.3165) | Acc: (88.87%) (27416/30848)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 250 |  Loss: (0.3161) | Acc: (88.90%) (28562/32128)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 260 |  Loss: (0.3172) | Acc: (88.86%) (29687/33408)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 270 |  Loss: (0.3170) | Acc: (88.87%) (30826/34688)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 280 |  Loss: (0.3164) | Acc: (88.89%) (31972/35968)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 290 |  Loss: (0.3182) | Acc: (88.80%) (33075/37248)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 300 |  Loss: (0.3184) | Acc: (88.81%) (34215/38528)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 310 |  Loss: (0.3185) | Acc: (88.81%) (35352/39808)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 320 |  Loss: (0.3180) | Acc: (88.88%) (36517/41088)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 330 |  Loss: (0.3176) | Acc: (88.87%) (37652/42368)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 340 |  Loss: (0.3169) | Acc: (88.92%) (38810/43648)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 350 |  Loss: (0.3158) | Acc: (88.95%) (39963/44928)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 360 |  Loss: (0.3156) | Acc: (88.97%) (41112/46208)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 370 |  Loss: (0.3139) | Acc: (89.04%) (42282/47488)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 380 |  Loss: (0.3140) | Acc: (89.03%) (43417/48768)\n",
      "lr: 0.001\n",
      "Epoch: 31 | Batch_idx: 390 |  Loss: (0.3146) | Acc: (89.03%) (44513/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.6943) | Acc: (34.45%) (3445/10000)\n",
      "Epoch: 32 | Batch_idx: 0 |  Loss: (0.3583) | Acc: (89.06%) (114/128)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 10 |  Loss: (0.2807) | Acc: (90.27%) (1271/1408)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 20 |  Loss: (0.2826) | Acc: (90.10%) (2422/2688)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 30 |  Loss: (0.2890) | Acc: (89.82%) (3564/3968)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 40 |  Loss: (0.2849) | Acc: (90.02%) (4724/5248)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 50 |  Loss: (0.2812) | Acc: (90.17%) (5886/6528)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 60 |  Loss: (0.2846) | Acc: (90.02%) (7029/7808)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 70 |  Loss: (0.2857) | Acc: (89.94%) (8174/9088)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 80 |  Loss: (0.2876) | Acc: (89.87%) (9318/10368)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 90 |  Loss: (0.2882) | Acc: (89.80%) (10460/11648)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 100 |  Loss: (0.2850) | Acc: (89.88%) (11620/12928)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 110 |  Loss: (0.2884) | Acc: (89.72%) (12748/14208)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 120 |  Loss: (0.2900) | Acc: (89.64%) (13884/15488)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 130 |  Loss: (0.2925) | Acc: (89.60%) (15024/16768)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 140 |  Loss: (0.2969) | Acc: (89.51%) (16155/18048)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 150 |  Loss: (0.2966) | Acc: (89.54%) (17307/19328)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 160 |  Loss: (0.2946) | Acc: (89.59%) (18462/20608)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 170 |  Loss: (0.2959) | Acc: (89.57%) (19606/21888)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 180 |  Loss: (0.2966) | Acc: (89.56%) (20750/23168)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 190 |  Loss: (0.2968) | Acc: (89.55%) (21892/24448)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 200 |  Loss: (0.2969) | Acc: (89.53%) (23034/25728)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 210 |  Loss: (0.2965) | Acc: (89.56%) (24189/27008)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 220 |  Loss: (0.2958) | Acc: (89.57%) (25338/28288)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 230 |  Loss: (0.2964) | Acc: (89.55%) (26477/29568)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 240 |  Loss: (0.2973) | Acc: (89.56%) (27627/30848)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 250 |  Loss: (0.2978) | Acc: (89.55%) (28772/32128)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 260 |  Loss: (0.2979) | Acc: (89.54%) (29912/33408)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 270 |  Loss: (0.2981) | Acc: (89.52%) (31054/34688)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 280 |  Loss: (0.2984) | Acc: (89.52%) (32198/35968)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 290 |  Loss: (0.2997) | Acc: (89.50%) (33337/37248)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 300 |  Loss: (0.2999) | Acc: (89.50%) (34481/38528)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 310 |  Loss: (0.3002) | Acc: (89.47%) (35617/39808)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 320 |  Loss: (0.3000) | Acc: (89.46%) (36759/41088)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 330 |  Loss: (0.2993) | Acc: (89.52%) (37927/42368)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 340 |  Loss: (0.2989) | Acc: (89.53%) (39079/43648)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 350 |  Loss: (0.3012) | Acc: (89.46%) (40194/44928)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 360 |  Loss: (0.3002) | Acc: (89.52%) (41366/46208)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 370 |  Loss: (0.3013) | Acc: (89.47%) (42488/47488)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 380 |  Loss: (0.3024) | Acc: (89.45%) (43621/48768)\n",
      "lr: 0.001\n",
      "Epoch: 32 | Batch_idx: 390 |  Loss: (0.3024) | Acc: (89.44%) (44720/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4001) | Acc: (36.07%) (3607/10000)\n",
      "Epoch: 33 | Batch_idx: 0 |  Loss: (0.2580) | Acc: (89.84%) (115/128)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 10 |  Loss: (0.2693) | Acc: (91.26%) (1285/1408)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 20 |  Loss: (0.2753) | Acc: (90.66%) (2437/2688)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 30 |  Loss: (0.2966) | Acc: (89.74%) (3561/3968)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 40 |  Loss: (0.3140) | Acc: (89.14%) (4678/5248)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 50 |  Loss: (0.3083) | Acc: (89.35%) (5833/6528)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 60 |  Loss: (0.3047) | Acc: (89.42%) (6982/7808)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 70 |  Loss: (0.3078) | Acc: (89.43%) (8127/9088)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 80 |  Loss: (0.3076) | Acc: (89.39%) (9268/10368)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 90 |  Loss: (0.3053) | Acc: (89.43%) (10417/11648)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 100 |  Loss: (0.3020) | Acc: (89.59%) (11582/12928)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 110 |  Loss: (0.3031) | Acc: (89.55%) (12723/14208)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 120 |  Loss: (0.3053) | Acc: (89.50%) (13861/15488)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 130 |  Loss: (0.3070) | Acc: (89.42%) (14994/16768)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 140 |  Loss: (0.3077) | Acc: (89.40%) (16135/18048)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 150 |  Loss: (0.3077) | Acc: (89.37%) (17273/19328)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 160 |  Loss: (0.3089) | Acc: (89.37%) (18417/20608)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 170 |  Loss: (0.3072) | Acc: (89.40%) (19567/21888)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 180 |  Loss: (0.3080) | Acc: (89.36%) (20704/23168)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 190 |  Loss: (0.3066) | Acc: (89.44%) (21866/24448)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 200 |  Loss: (0.3062) | Acc: (89.51%) (23029/25728)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 210 |  Loss: (0.3074) | Acc: (89.49%) (24170/27008)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 220 |  Loss: (0.3067) | Acc: (89.51%) (25320/28288)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 230 |  Loss: (0.3056) | Acc: (89.53%) (26473/29568)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 240 |  Loss: (0.3063) | Acc: (89.48%) (27604/30848)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 250 |  Loss: (0.3066) | Acc: (89.48%) (28747/32128)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 260 |  Loss: (0.3056) | Acc: (89.51%) (29904/33408)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 270 |  Loss: (0.3047) | Acc: (89.53%) (31055/34688)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 280 |  Loss: (0.3052) | Acc: (89.51%) (32195/35968)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 290 |  Loss: (0.3046) | Acc: (89.55%) (33354/37248)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 300 |  Loss: (0.3041) | Acc: (89.56%) (34504/38528)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 310 |  Loss: (0.3039) | Acc: (89.56%) (35652/39808)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 320 |  Loss: (0.3037) | Acc: (89.58%) (36806/41088)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 330 |  Loss: (0.3029) | Acc: (89.60%) (37961/42368)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 340 |  Loss: (0.3027) | Acc: (89.64%) (39127/43648)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 350 |  Loss: (0.3027) | Acc: (89.62%) (40266/44928)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 360 |  Loss: (0.3021) | Acc: (89.64%) (41420/46208)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 370 |  Loss: (0.3030) | Acc: (89.61%) (42552/47488)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 380 |  Loss: (0.3037) | Acc: (89.58%) (43684/48768)\n",
      "lr: 0.001\n",
      "Epoch: 33 | Batch_idx: 390 |  Loss: (0.3039) | Acc: (89.56%) (44781/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3483) | Acc: (35.07%) (3507/10000)\n",
      "Epoch: 34 | Batch_idx: 0 |  Loss: (0.3702) | Acc: (86.72%) (111/128)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 10 |  Loss: (0.3028) | Acc: (89.35%) (1258/1408)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 20 |  Loss: (0.2952) | Acc: (89.43%) (2404/2688)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 30 |  Loss: (0.2948) | Acc: (89.64%) (3557/3968)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 40 |  Loss: (0.3021) | Acc: (89.35%) (4689/5248)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 50 |  Loss: (0.3008) | Acc: (89.52%) (5844/6528)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 60 |  Loss: (0.2988) | Acc: (89.55%) (6992/7808)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 70 |  Loss: (0.2966) | Acc: (89.62%) (8145/9088)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 80 |  Loss: (0.2988) | Acc: (89.55%) (9285/10368)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 90 |  Loss: (0.2971) | Acc: (89.61%) (10438/11648)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 100 |  Loss: (0.2934) | Acc: (89.80%) (11609/12928)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 110 |  Loss: (0.2929) | Acc: (89.83%) (12763/14208)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 120 |  Loss: (0.2947) | Acc: (89.83%) (13913/15488)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 130 |  Loss: (0.2942) | Acc: (89.87%) (15070/16768)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 140 |  Loss: (0.2934) | Acc: (89.92%) (16228/18048)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 150 |  Loss: (0.2919) | Acc: (89.96%) (17388/19328)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 160 |  Loss: (0.2910) | Acc: (89.99%) (18546/20608)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 170 |  Loss: (0.2914) | Acc: (89.97%) (19692/21888)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 180 |  Loss: (0.2915) | Acc: (89.96%) (20842/23168)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 190 |  Loss: (0.2934) | Acc: (89.88%) (21975/24448)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 200 |  Loss: (0.2929) | Acc: (89.92%) (23135/25728)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 210 |  Loss: (0.2921) | Acc: (89.97%) (24298/27008)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 220 |  Loss: (0.2942) | Acc: (89.88%) (25425/28288)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 230 |  Loss: (0.2936) | Acc: (89.95%) (26595/29568)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 240 |  Loss: (0.2950) | Acc: (89.91%) (27734/30848)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 250 |  Loss: (0.2953) | Acc: (89.87%) (28872/32128)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 260 |  Loss: (0.2938) | Acc: (89.90%) (30033/33408)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 270 |  Loss: (0.2948) | Acc: (89.82%) (31158/34688)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 280 |  Loss: (0.2944) | Acc: (89.86%) (32320/35968)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 290 |  Loss: (0.2941) | Acc: (89.88%) (33479/37248)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 300 |  Loss: (0.2949) | Acc: (89.87%) (34624/38528)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 310 |  Loss: (0.2944) | Acc: (89.89%) (35782/39808)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 320 |  Loss: (0.2937) | Acc: (89.91%) (36941/41088)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 330 |  Loss: (0.2937) | Acc: (89.91%) (38095/42368)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 340 |  Loss: (0.2944) | Acc: (89.89%) (39237/43648)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 350 |  Loss: (0.2936) | Acc: (89.90%) (40391/44928)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 360 |  Loss: (0.2941) | Acc: (89.87%) (41527/46208)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 370 |  Loss: (0.2958) | Acc: (89.81%) (42649/47488)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 380 |  Loss: (0.2959) | Acc: (89.78%) (43786/48768)\n",
      "lr: 0.001\n",
      "Epoch: 34 | Batch_idx: 390 |  Loss: (0.2961) | Acc: (89.78%) (44889/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.0109) | Acc: (32.58%) (3258/10000)\n",
      "Epoch: 35 | Batch_idx: 0 |  Loss: (0.2747) | Acc: (92.97%) (119/128)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 10 |  Loss: (0.2755) | Acc: (90.62%) (1276/1408)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 20 |  Loss: (0.2722) | Acc: (90.81%) (2441/2688)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 30 |  Loss: (0.2716) | Acc: (90.42%) (3588/3968)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 40 |  Loss: (0.2718) | Acc: (90.61%) (4755/5248)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 50 |  Loss: (0.2658) | Acc: (90.85%) (5931/6528)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 60 |  Loss: (0.2716) | Acc: (90.54%) (7069/7808)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 70 |  Loss: (0.2713) | Acc: (90.67%) (8240/9088)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 80 |  Loss: (0.2711) | Acc: (90.73%) (9407/10368)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 90 |  Loss: (0.2745) | Acc: (90.57%) (10550/11648)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 100 |  Loss: (0.2727) | Acc: (90.59%) (11711/12928)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 110 |  Loss: (0.2731) | Acc: (90.55%) (12866/14208)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 120 |  Loss: (0.2749) | Acc: (90.52%) (14020/15488)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 130 |  Loss: (0.2767) | Acc: (90.41%) (15160/16768)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 140 |  Loss: (0.2759) | Acc: (90.43%) (16320/18048)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 150 |  Loss: (0.2761) | Acc: (90.41%) (17474/19328)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 160 |  Loss: (0.2784) | Acc: (90.31%) (18612/20608)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 170 |  Loss: (0.2782) | Acc: (90.31%) (19768/21888)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 180 |  Loss: (0.2776) | Acc: (90.34%) (20929/23168)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 190 |  Loss: (0.2767) | Acc: (90.36%) (22092/24448)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 200 |  Loss: (0.2780) | Acc: (90.30%) (23233/25728)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 210 |  Loss: (0.2800) | Acc: (90.25%) (24376/27008)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 220 |  Loss: (0.2812) | Acc: (90.20%) (25516/28288)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 230 |  Loss: (0.2828) | Acc: (90.12%) (26646/29568)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 240 |  Loss: (0.2834) | Acc: (90.09%) (27791/30848)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 250 |  Loss: (0.2837) | Acc: (90.12%) (28953/32128)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 260 |  Loss: (0.2834) | Acc: (90.16%) (30122/33408)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 270 |  Loss: (0.2838) | Acc: (90.15%) (31272/34688)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 280 |  Loss: (0.2832) | Acc: (90.18%) (32435/35968)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 290 |  Loss: (0.2836) | Acc: (90.18%) (33589/37248)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 300 |  Loss: (0.2835) | Acc: (90.17%) (34741/38528)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 310 |  Loss: (0.2834) | Acc: (90.17%) (35893/39808)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 320 |  Loss: (0.2835) | Acc: (90.17%) (37048/41088)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 330 |  Loss: (0.2837) | Acc: (90.19%) (38211/42368)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 340 |  Loss: (0.2855) | Acc: (90.12%) (39335/43648)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 350 |  Loss: (0.2862) | Acc: (90.08%) (40472/44928)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 360 |  Loss: (0.2863) | Acc: (90.08%) (41625/46208)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 370 |  Loss: (0.2854) | Acc: (90.12%) (42795/47488)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 380 |  Loss: (0.2867) | Acc: (90.08%) (43931/48768)\n",
      "lr: 0.001\n",
      "Epoch: 35 | Batch_idx: 390 |  Loss: (0.2862) | Acc: (90.09%) (45045/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.9979) | Acc: (36.43%) (3643/10000)\n",
      "Epoch: 36 | Batch_idx: 0 |  Loss: (0.2905) | Acc: (89.06%) (114/128)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 10 |  Loss: (0.2642) | Acc: (91.34%) (1286/1408)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 20 |  Loss: (0.2669) | Acc: (91.07%) (2448/2688)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 30 |  Loss: (0.2697) | Acc: (90.83%) (3604/3968)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 40 |  Loss: (0.2648) | Acc: (90.74%) (4762/5248)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 50 |  Loss: (0.2678) | Acc: (90.61%) (5915/6528)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 60 |  Loss: (0.2707) | Acc: (90.57%) (7072/7808)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 70 |  Loss: (0.2712) | Acc: (90.56%) (8230/9088)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 80 |  Loss: (0.2713) | Acc: (90.58%) (9391/10368)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 90 |  Loss: (0.2716) | Acc: (90.58%) (10551/11648)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 100 |  Loss: (0.2731) | Acc: (90.52%) (11703/12928)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 110 |  Loss: (0.2745) | Acc: (90.46%) (12853/14208)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 120 |  Loss: (0.2724) | Acc: (90.48%) (14014/15488)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 130 |  Loss: (0.2747) | Acc: (90.43%) (15163/16768)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 140 |  Loss: (0.2755) | Acc: (90.41%) (16318/18048)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 150 |  Loss: (0.2763) | Acc: (90.38%) (17469/19328)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 160 |  Loss: (0.2767) | Acc: (90.43%) (18635/20608)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 170 |  Loss: (0.2771) | Acc: (90.40%) (19787/21888)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 180 |  Loss: (0.2768) | Acc: (90.40%) (20944/23168)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 190 |  Loss: (0.2785) | Acc: (90.34%) (22086/24448)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 200 |  Loss: (0.2776) | Acc: (90.34%) (23242/25728)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 210 |  Loss: (0.2769) | Acc: (90.34%) (24400/27008)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 220 |  Loss: (0.2761) | Acc: (90.37%) (25565/28288)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 230 |  Loss: (0.2752) | Acc: (90.38%) (26725/29568)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 240 |  Loss: (0.2757) | Acc: (90.32%) (27862/30848)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 250 |  Loss: (0.2750) | Acc: (90.36%) (29031/32128)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 260 |  Loss: (0.2760) | Acc: (90.36%) (30186/33408)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 270 |  Loss: (0.2768) | Acc: (90.34%) (31337/34688)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 280 |  Loss: (0.2764) | Acc: (90.33%) (32491/35968)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 290 |  Loss: (0.2761) | Acc: (90.35%) (33655/37248)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 300 |  Loss: (0.2759) | Acc: (90.37%) (34816/38528)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 310 |  Loss: (0.2765) | Acc: (90.36%) (35972/39808)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 320 |  Loss: (0.2761) | Acc: (90.38%) (37135/41088)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 330 |  Loss: (0.2765) | Acc: (90.37%) (38288/42368)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 340 |  Loss: (0.2760) | Acc: (90.36%) (39441/43648)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 350 |  Loss: (0.2765) | Acc: (90.36%) (40596/44928)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 360 |  Loss: (0.2771) | Acc: (90.35%) (41750/46208)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 370 |  Loss: (0.2774) | Acc: (90.34%) (42900/47488)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 380 |  Loss: (0.2778) | Acc: (90.31%) (44042/48768)\n",
      "lr: 0.001\n",
      "Epoch: 36 | Batch_idx: 390 |  Loss: (0.2773) | Acc: (90.32%) (45162/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4169) | Acc: (35.81%) (3581/10000)\n",
      "Epoch: 37 | Batch_idx: 0 |  Loss: (0.2819) | Acc: (89.06%) (114/128)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 10 |  Loss: (0.2873) | Acc: (90.06%) (1268/1408)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 20 |  Loss: (0.2769) | Acc: (90.10%) (2422/2688)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 30 |  Loss: (0.2823) | Acc: (90.30%) (3583/3968)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 40 |  Loss: (0.2805) | Acc: (90.38%) (4743/5248)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 50 |  Loss: (0.2792) | Acc: (90.36%) (5899/6528)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 60 |  Loss: (0.2758) | Acc: (90.46%) (7063/7808)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 70 |  Loss: (0.2753) | Acc: (90.50%) (8225/9088)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 80 |  Loss: (0.2789) | Acc: (90.40%) (9373/10368)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 90 |  Loss: (0.2750) | Acc: (90.46%) (10537/11648)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 100 |  Loss: (0.2751) | Acc: (90.43%) (11691/12928)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 110 |  Loss: (0.2745) | Acc: (90.47%) (12854/14208)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 120 |  Loss: (0.2777) | Acc: (90.32%) (13989/15488)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 130 |  Loss: (0.2789) | Acc: (90.27%) (15136/16768)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 140 |  Loss: (0.2777) | Acc: (90.33%) (16303/18048)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 150 |  Loss: (0.2761) | Acc: (90.30%) (17454/19328)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 160 |  Loss: (0.2755) | Acc: (90.33%) (18615/20608)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 170 |  Loss: (0.2750) | Acc: (90.37%) (19780/21888)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 180 |  Loss: (0.2740) | Acc: (90.40%) (20944/23168)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 190 |  Loss: (0.2746) | Acc: (90.40%) (22101/24448)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 200 |  Loss: (0.2769) | Acc: (90.32%) (23238/25728)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 210 |  Loss: (0.2763) | Acc: (90.34%) (24400/27008)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 220 |  Loss: (0.2755) | Acc: (90.43%) (25580/28288)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 230 |  Loss: (0.2749) | Acc: (90.47%) (26749/29568)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 240 |  Loss: (0.2744) | Acc: (90.46%) (27905/30848)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 250 |  Loss: (0.2753) | Acc: (90.42%) (29050/32128)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 260 |  Loss: (0.2775) | Acc: (90.35%) (30184/33408)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 270 |  Loss: (0.2775) | Acc: (90.35%) (31341/34688)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 280 |  Loss: (0.2770) | Acc: (90.37%) (32506/35968)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 290 |  Loss: (0.2769) | Acc: (90.40%) (33673/37248)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 300 |  Loss: (0.2764) | Acc: (90.43%) (34841/38528)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 310 |  Loss: (0.2767) | Acc: (90.42%) (35995/39808)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 320 |  Loss: (0.2771) | Acc: (90.38%) (37137/41088)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 330 |  Loss: (0.2778) | Acc: (90.35%) (38278/42368)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 340 |  Loss: (0.2777) | Acc: (90.36%) (39440/43648)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 350 |  Loss: (0.2777) | Acc: (90.35%) (40591/44928)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 360 |  Loss: (0.2768) | Acc: (90.39%) (41769/46208)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 370 |  Loss: (0.2767) | Acc: (90.40%) (42928/47488)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 380 |  Loss: (0.2768) | Acc: (90.39%) (44079/48768)\n",
      "lr: 0.001\n",
      "Epoch: 37 | Batch_idx: 390 |  Loss: (0.2774) | Acc: (90.38%) (45191/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.2713) | Acc: (35.81%) (3581/10000)\n",
      "Epoch: 38 | Batch_idx: 0 |  Loss: (0.2180) | Acc: (93.75%) (120/128)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 10 |  Loss: (0.2653) | Acc: (91.12%) (1283/1408)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 20 |  Loss: (0.2632) | Acc: (91.00%) (2446/2688)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 30 |  Loss: (0.2604) | Acc: (91.10%) (3615/3968)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 40 |  Loss: (0.2678) | Acc: (90.61%) (4755/5248)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 50 |  Loss: (0.2728) | Acc: (90.29%) (5894/6528)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 60 |  Loss: (0.2738) | Acc: (90.34%) (7054/7808)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 70 |  Loss: (0.2707) | Acc: (90.54%) (8228/9088)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 80 |  Loss: (0.2754) | Acc: (90.40%) (9373/10368)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 90 |  Loss: (0.2761) | Acc: (90.38%) (10527/11648)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 100 |  Loss: (0.2780) | Acc: (90.35%) (11680/12928)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 110 |  Loss: (0.2752) | Acc: (90.44%) (12850/14208)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 120 |  Loss: (0.2760) | Acc: (90.41%) (14002/15488)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 130 |  Loss: (0.2769) | Acc: (90.37%) (15153/16768)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 140 |  Loss: (0.2753) | Acc: (90.37%) (16310/18048)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 150 |  Loss: (0.2740) | Acc: (90.38%) (17469/19328)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 160 |  Loss: (0.2731) | Acc: (90.43%) (18635/20608)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 170 |  Loss: (0.2722) | Acc: (90.44%) (19795/21888)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 180 |  Loss: (0.2737) | Acc: (90.38%) (20940/23168)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 190 |  Loss: (0.2723) | Acc: (90.43%) (22108/24448)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 200 |  Loss: (0.2727) | Acc: (90.40%) (23258/25728)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 210 |  Loss: (0.2727) | Acc: (90.41%) (24418/27008)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 220 |  Loss: (0.2724) | Acc: (90.44%) (25583/28288)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 230 |  Loss: (0.2738) | Acc: (90.39%) (26726/29568)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 240 |  Loss: (0.2735) | Acc: (90.40%) (27887/30848)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 250 |  Loss: (0.2723) | Acc: (90.44%) (29056/32128)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 260 |  Loss: (0.2728) | Acc: (90.41%) (30203/33408)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 270 |  Loss: (0.2736) | Acc: (90.39%) (31356/34688)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 280 |  Loss: (0.2739) | Acc: (90.39%) (32513/35968)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 290 |  Loss: (0.2740) | Acc: (90.40%) (33672/37248)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 300 |  Loss: (0.2734) | Acc: (90.42%) (34838/38528)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 310 |  Loss: (0.2742) | Acc: (90.42%) (35994/39808)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 320 |  Loss: (0.2744) | Acc: (90.44%) (37158/41088)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 330 |  Loss: (0.2747) | Acc: (90.44%) (38316/42368)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 340 |  Loss: (0.2736) | Acc: (90.48%) (39491/43648)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 350 |  Loss: (0.2722) | Acc: (90.53%) (40675/44928)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 360 |  Loss: (0.2722) | Acc: (90.54%) (41836/46208)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 370 |  Loss: (0.2710) | Acc: (90.57%) (43010/47488)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 380 |  Loss: (0.2714) | Acc: (90.54%) (44156/48768)\n",
      "lr: 0.001\n",
      "Epoch: 38 | Batch_idx: 390 |  Loss: (0.2709) | Acc: (90.54%) (45270/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.9363) | Acc: (45.37%) (4537/10000)\n",
      "Epoch: 39 | Batch_idx: 0 |  Loss: (0.2908) | Acc: (87.50%) (112/128)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 10 |  Loss: (0.2684) | Acc: (90.41%) (1273/1408)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 20 |  Loss: (0.2564) | Acc: (91.03%) (2447/2688)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 30 |  Loss: (0.2663) | Acc: (90.78%) (3602/3968)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 40 |  Loss: (0.2686) | Acc: (90.34%) (4741/5248)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 50 |  Loss: (0.2645) | Acc: (90.53%) (5910/6528)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 60 |  Loss: (0.2652) | Acc: (90.66%) (7079/7808)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 70 |  Loss: (0.2680) | Acc: (90.66%) (8239/9088)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 80 |  Loss: (0.2670) | Acc: (90.63%) (9397/10368)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 90 |  Loss: (0.2667) | Acc: (90.69%) (10564/11648)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 100 |  Loss: (0.2658) | Acc: (90.76%) (11734/12928)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 110 |  Loss: (0.2677) | Acc: (90.72%) (12890/14208)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 120 |  Loss: (0.2666) | Acc: (90.73%) (14052/15488)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 130 |  Loss: (0.2666) | Acc: (90.70%) (15209/16768)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 140 |  Loss: (0.2644) | Acc: (90.76%) (16381/18048)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 150 |  Loss: (0.2648) | Acc: (90.70%) (17531/19328)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 160 |  Loss: (0.2664) | Acc: (90.64%) (18679/20608)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 170 |  Loss: (0.2662) | Acc: (90.69%) (19850/21888)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 180 |  Loss: (0.2665) | Acc: (90.66%) (21004/23168)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 190 |  Loss: (0.2676) | Acc: (90.62%) (22154/24448)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 200 |  Loss: (0.2682) | Acc: (90.61%) (23313/25728)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 210 |  Loss: (0.2666) | Acc: (90.66%) (24485/27008)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 220 |  Loss: (0.2673) | Acc: (90.62%) (25636/28288)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 230 |  Loss: (0.2666) | Acc: (90.65%) (26802/29568)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 240 |  Loss: (0.2659) | Acc: (90.67%) (27969/30848)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 250 |  Loss: (0.2654) | Acc: (90.71%) (29142/32128)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 260 |  Loss: (0.2662) | Acc: (90.69%) (30297/33408)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 270 |  Loss: (0.2663) | Acc: (90.70%) (31461/34688)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 280 |  Loss: (0.2660) | Acc: (90.70%) (32624/35968)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 290 |  Loss: (0.2655) | Acc: (90.76%) (33806/37248)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 300 |  Loss: (0.2655) | Acc: (90.78%) (34976/38528)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 310 |  Loss: (0.2658) | Acc: (90.76%) (36128/39808)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 320 |  Loss: (0.2661) | Acc: (90.77%) (37294/41088)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 330 |  Loss: (0.2667) | Acc: (90.75%) (38448/42368)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 340 |  Loss: (0.2662) | Acc: (90.79%) (39627/43648)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 350 |  Loss: (0.2665) | Acc: (90.78%) (40785/44928)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 360 |  Loss: (0.2668) | Acc: (90.77%) (41944/46208)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 370 |  Loss: (0.2673) | Acc: (90.76%) (43098/47488)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 380 |  Loss: (0.2680) | Acc: (90.72%) (44244/48768)\n",
      "lr: 0.001\n",
      "Epoch: 39 | Batch_idx: 390 |  Loss: (0.2678) | Acc: (90.73%) (45365/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.8247) | Acc: (44.61%) (4461/10000)\n",
      "Epoch: 40 | Batch_idx: 0 |  Loss: (0.2010) | Acc: (93.75%) (120/128)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 10 |  Loss: (0.2547) | Acc: (91.34%) (1286/1408)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 20 |  Loss: (0.2610) | Acc: (91.03%) (2447/2688)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 30 |  Loss: (0.2576) | Acc: (90.85%) (3605/3968)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 40 |  Loss: (0.2612) | Acc: (90.70%) (4760/5248)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 50 |  Loss: (0.2579) | Acc: (90.87%) (5932/6528)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 60 |  Loss: (0.2502) | Acc: (91.30%) (7129/7808)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 70 |  Loss: (0.2534) | Acc: (91.15%) (8284/9088)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 80 |  Loss: (0.2580) | Acc: (91.00%) (9435/10368)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 90 |  Loss: (0.2579) | Acc: (91.04%) (10604/11648)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 100 |  Loss: (0.2612) | Acc: (90.87%) (11748/12928)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 110 |  Loss: (0.2625) | Acc: (90.85%) (12908/14208)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 120 |  Loss: (0.2619) | Acc: (90.84%) (14069/15488)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 130 |  Loss: (0.2615) | Acc: (90.84%) (15232/16768)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 140 |  Loss: (0.2604) | Acc: (90.92%) (16409/18048)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 150 |  Loss: (0.2577) | Acc: (91.01%) (17591/19328)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 160 |  Loss: (0.2577) | Acc: (91.05%) (18764/20608)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 170 |  Loss: (0.2593) | Acc: (90.97%) (19911/21888)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 180 |  Loss: (0.2605) | Acc: (90.90%) (21060/23168)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 190 |  Loss: (0.2611) | Acc: (90.88%) (22219/24448)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 200 |  Loss: (0.2594) | Acc: (90.92%) (23392/25728)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 210 |  Loss: (0.2603) | Acc: (90.86%) (24540/27008)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 220 |  Loss: (0.2604) | Acc: (90.84%) (25698/28288)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 230 |  Loss: (0.2612) | Acc: (90.79%) (26845/29568)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 240 |  Loss: (0.2630) | Acc: (90.73%) (27988/30848)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 250 |  Loss: (0.2639) | Acc: (90.68%) (29135/32128)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 260 |  Loss: (0.2642) | Acc: (90.66%) (30288/33408)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 270 |  Loss: (0.2643) | Acc: (90.66%) (31449/34688)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 280 |  Loss: (0.2650) | Acc: (90.65%) (32606/35968)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 290 |  Loss: (0.2673) | Acc: (90.58%) (33740/37248)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 300 |  Loss: (0.2670) | Acc: (90.61%) (34912/38528)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 310 |  Loss: (0.2673) | Acc: (90.63%) (36077/39808)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 320 |  Loss: (0.2688) | Acc: (90.56%) (37211/41088)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 330 |  Loss: (0.2682) | Acc: (90.60%) (38387/42368)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 340 |  Loss: (0.2690) | Acc: (90.58%) (39535/43648)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 350 |  Loss: (0.2690) | Acc: (90.56%) (40688/44928)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 360 |  Loss: (0.2695) | Acc: (90.54%) (41835/46208)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 370 |  Loss: (0.2702) | Acc: (90.53%) (42990/47488)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 380 |  Loss: (0.2690) | Acc: (90.59%) (44178/48768)\n",
      "lr: 0.001\n",
      "Epoch: 40 | Batch_idx: 390 |  Loss: (0.2686) | Acc: (90.60%) (45299/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.8697) | Acc: (28.66%) (2866/10000)\n",
      "Epoch: 41 | Batch_idx: 0 |  Loss: (0.2939) | Acc: (89.06%) (114/128)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 10 |  Loss: (0.2371) | Acc: (92.19%) (1298/1408)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 20 |  Loss: (0.2449) | Acc: (91.59%) (2462/2688)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 30 |  Loss: (0.2413) | Acc: (91.83%) (3644/3968)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 40 |  Loss: (0.2490) | Acc: (91.48%) (4801/5248)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 50 |  Loss: (0.2460) | Acc: (91.51%) (5974/6528)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 60 |  Loss: (0.2450) | Acc: (91.55%) (7148/7808)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 70 |  Loss: (0.2453) | Acc: (91.55%) (8320/9088)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 80 |  Loss: (0.2515) | Acc: (91.27%) (9463/10368)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 90 |  Loss: (0.2553) | Acc: (91.08%) (10609/11648)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 100 |  Loss: (0.2532) | Acc: (91.13%) (11781/12928)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 110 |  Loss: (0.2505) | Acc: (91.26%) (12966/14208)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 120 |  Loss: (0.2503) | Acc: (91.30%) (14141/15488)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 130 |  Loss: (0.2494) | Acc: (91.36%) (15319/16768)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 140 |  Loss: (0.2492) | Acc: (91.37%) (16491/18048)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 150 |  Loss: (0.2517) | Acc: (91.33%) (17652/19328)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 160 |  Loss: (0.2524) | Acc: (91.27%) (18809/20608)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 170 |  Loss: (0.2527) | Acc: (91.24%) (19970/21888)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 180 |  Loss: (0.2554) | Acc: (91.19%) (21127/23168)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 190 |  Loss: (0.2548) | Acc: (91.18%) (22291/24448)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 200 |  Loss: (0.2554) | Acc: (91.14%) (23449/25728)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 210 |  Loss: (0.2562) | Acc: (91.17%) (24622/27008)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 220 |  Loss: (0.2568) | Acc: (91.14%) (25782/28288)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 230 |  Loss: (0.2579) | Acc: (91.11%) (26940/29568)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 240 |  Loss: (0.2581) | Acc: (91.10%) (28101/30848)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 250 |  Loss: (0.2580) | Acc: (91.11%) (29271/32128)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 260 |  Loss: (0.2591) | Acc: (91.09%) (30430/33408)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 270 |  Loss: (0.2590) | Acc: (91.10%) (31600/34688)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 280 |  Loss: (0.2596) | Acc: (91.08%) (32759/35968)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 290 |  Loss: (0.2598) | Acc: (91.09%) (33929/37248)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 300 |  Loss: (0.2600) | Acc: (91.08%) (35090/38528)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 310 |  Loss: (0.2600) | Acc: (91.04%) (36240/39808)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 320 |  Loss: (0.2618) | Acc: (90.97%) (37379/41088)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 330 |  Loss: (0.2614) | Acc: (90.97%) (38544/42368)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 340 |  Loss: (0.2617) | Acc: (90.96%) (39701/43648)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 350 |  Loss: (0.2621) | Acc: (90.94%) (40858/44928)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 360 |  Loss: (0.2619) | Acc: (90.94%) (42023/46208)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 370 |  Loss: (0.2626) | Acc: (90.91%) (43169/47488)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 380 |  Loss: (0.2630) | Acc: (90.90%) (44329/48768)\n",
      "lr: 0.001\n",
      "Epoch: 41 | Batch_idx: 390 |  Loss: (0.2626) | Acc: (90.93%) (45466/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.3995) | Acc: (30.35%) (3035/10000)\n",
      "Epoch: 42 | Batch_idx: 0 |  Loss: (0.2962) | Acc: (89.84%) (115/128)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 10 |  Loss: (0.2497) | Acc: (91.48%) (1288/1408)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 20 |  Loss: (0.2612) | Acc: (91.29%) (2454/2688)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 30 |  Loss: (0.2522) | Acc: (91.61%) (3635/3968)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 40 |  Loss: (0.2644) | Acc: (90.97%) (4774/5248)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 50 |  Loss: (0.2592) | Acc: (91.02%) (5942/6528)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 60 |  Loss: (0.2590) | Acc: (91.05%) (7109/7808)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 70 |  Loss: (0.2543) | Acc: (91.24%) (8292/9088)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 80 |  Loss: (0.2558) | Acc: (91.18%) (9454/10368)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 90 |  Loss: (0.2556) | Acc: (91.23%) (10627/11648)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 100 |  Loss: (0.2545) | Acc: (91.26%) (11798/12928)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 110 |  Loss: (0.2535) | Acc: (91.24%) (12963/14208)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 120 |  Loss: (0.2534) | Acc: (91.24%) (14132/15488)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 130 |  Loss: (0.2558) | Acc: (91.17%) (15287/16768)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 140 |  Loss: (0.2561) | Acc: (91.16%) (16452/18048)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 150 |  Loss: (0.2562) | Acc: (91.18%) (17624/19328)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 160 |  Loss: (0.2545) | Acc: (91.23%) (18800/20608)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 170 |  Loss: (0.2549) | Acc: (91.19%) (19959/21888)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 180 |  Loss: (0.2556) | Acc: (91.13%) (21113/23168)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 190 |  Loss: (0.2553) | Acc: (91.12%) (22276/24448)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 200 |  Loss: (0.2563) | Acc: (91.06%) (23427/25728)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 210 |  Loss: (0.2558) | Acc: (91.05%) (24590/27008)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 220 |  Loss: (0.2571) | Acc: (90.99%) (25738/28288)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 230 |  Loss: (0.2573) | Acc: (90.97%) (26899/29568)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 240 |  Loss: (0.2581) | Acc: (90.94%) (28053/30848)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 250 |  Loss: (0.2575) | Acc: (90.95%) (29222/32128)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 260 |  Loss: (0.2575) | Acc: (90.98%) (30395/33408)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 270 |  Loss: (0.2572) | Acc: (91.00%) (31566/34688)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 280 |  Loss: (0.2577) | Acc: (90.99%) (32728/35968)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 290 |  Loss: (0.2574) | Acc: (91.03%) (33906/37248)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 300 |  Loss: (0.2568) | Acc: (91.03%) (35072/38528)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 310 |  Loss: (0.2578) | Acc: (90.99%) (36223/39808)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 320 |  Loss: (0.2586) | Acc: (90.96%) (37374/41088)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 330 |  Loss: (0.2580) | Acc: (90.97%) (38544/42368)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 340 |  Loss: (0.2565) | Acc: (91.03%) (39732/43648)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 350 |  Loss: (0.2574) | Acc: (91.01%) (40889/44928)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 360 |  Loss: (0.2584) | Acc: (90.96%) (42033/46208)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 370 |  Loss: (0.2582) | Acc: (90.99%) (43208/47488)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 380 |  Loss: (0.2591) | Acc: (90.94%) (44350/48768)\n",
      "lr: 0.001\n",
      "Epoch: 42 | Batch_idx: 390 |  Loss: (0.2588) | Acc: (90.95%) (45475/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.7762) | Acc: (35.64%) (3564/10000)\n",
      "Epoch: 43 | Batch_idx: 0 |  Loss: (0.2337) | Acc: (92.97%) (119/128)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 10 |  Loss: (0.2223) | Acc: (92.61%) (1304/1408)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 20 |  Loss: (0.2237) | Acc: (92.41%) (2484/2688)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 30 |  Loss: (0.2261) | Acc: (92.39%) (3666/3968)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 40 |  Loss: (0.2312) | Acc: (92.21%) (4839/5248)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 50 |  Loss: (0.2329) | Acc: (91.84%) (5995/6528)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 60 |  Loss: (0.2314) | Acc: (92.02%) (7185/7808)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 70 |  Loss: (0.2333) | Acc: (91.97%) (8358/9088)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 80 |  Loss: (0.2317) | Acc: (92.00%) (9539/10368)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 90 |  Loss: (0.2306) | Acc: (92.07%) (10724/11648)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 100 |  Loss: (0.2324) | Acc: (92.09%) (11906/12928)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 110 |  Loss: (0.2337) | Acc: (92.07%) (13081/14208)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 120 |  Loss: (0.2333) | Acc: (92.06%) (14258/15488)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 130 |  Loss: (0.2347) | Acc: (92.03%) (15432/16768)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 140 |  Loss: (0.2384) | Acc: (91.87%) (16581/18048)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 150 |  Loss: (0.2381) | Acc: (91.89%) (17760/19328)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 160 |  Loss: (0.2388) | Acc: (91.89%) (18936/20608)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 170 |  Loss: (0.2401) | Acc: (91.83%) (20099/21888)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 180 |  Loss: (0.2406) | Acc: (91.78%) (21263/23168)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 190 |  Loss: (0.2419) | Acc: (91.72%) (22424/24448)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 200 |  Loss: (0.2419) | Acc: (91.72%) (23597/25728)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 210 |  Loss: (0.2444) | Acc: (91.65%) (24754/27008)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 220 |  Loss: (0.2451) | Acc: (91.60%) (25913/28288)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 230 |  Loss: (0.2469) | Acc: (91.56%) (27071/29568)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 240 |  Loss: (0.2492) | Acc: (91.48%) (28221/30848)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 250 |  Loss: (0.2507) | Acc: (91.44%) (29378/32128)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 260 |  Loss: (0.2517) | Acc: (91.39%) (30533/33408)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 270 |  Loss: (0.2520) | Acc: (91.39%) (31700/34688)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 280 |  Loss: (0.2512) | Acc: (91.40%) (32874/35968)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 290 |  Loss: (0.2506) | Acc: (91.39%) (34042/37248)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 300 |  Loss: (0.2504) | Acc: (91.39%) (35209/38528)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 310 |  Loss: (0.2494) | Acc: (91.40%) (36385/39808)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 320 |  Loss: (0.2496) | Acc: (91.40%) (37554/41088)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 330 |  Loss: (0.2493) | Acc: (91.40%) (38725/42368)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 340 |  Loss: (0.2499) | Acc: (91.37%) (39883/43648)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 350 |  Loss: (0.2497) | Acc: (91.38%) (41055/44928)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 360 |  Loss: (0.2498) | Acc: (91.39%) (42228/46208)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 370 |  Loss: (0.2503) | Acc: (91.38%) (43393/47488)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 380 |  Loss: (0.2503) | Acc: (91.38%) (44563/48768)\n",
      "lr: 0.001\n",
      "Epoch: 43 | Batch_idx: 390 |  Loss: (0.2496) | Acc: (91.40%) (45698/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.6165) | Acc: (35.96%) (3596/10000)\n",
      "Epoch: 44 | Batch_idx: 0 |  Loss: (0.2048) | Acc: (90.62%) (116/128)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 10 |  Loss: (0.2690) | Acc: (90.41%) (1273/1408)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 20 |  Loss: (0.2484) | Acc: (90.89%) (2443/2688)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 30 |  Loss: (0.2548) | Acc: (90.68%) (3598/3968)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 40 |  Loss: (0.2593) | Acc: (90.85%) (4768/5248)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 50 |  Loss: (0.2520) | Acc: (91.21%) (5954/6528)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 60 |  Loss: (0.2445) | Acc: (91.48%) (7143/7808)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 70 |  Loss: (0.2436) | Acc: (91.56%) (8321/9088)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 80 |  Loss: (0.2470) | Acc: (91.46%) (9483/10368)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 90 |  Loss: (0.2471) | Acc: (91.43%) (10650/11648)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 100 |  Loss: (0.2479) | Acc: (91.37%) (11812/12928)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 110 |  Loss: (0.2501) | Acc: (91.36%) (12981/14208)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 120 |  Loss: (0.2482) | Acc: (91.42%) (14159/15488)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 130 |  Loss: (0.2472) | Acc: (91.44%) (15333/16768)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 140 |  Loss: (0.2465) | Acc: (91.48%) (16510/18048)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 150 |  Loss: (0.2448) | Acc: (91.52%) (17689/19328)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 160 |  Loss: (0.2451) | Acc: (91.51%) (18858/20608)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 170 |  Loss: (0.2459) | Acc: (91.50%) (20028/21888)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 180 |  Loss: (0.2456) | Acc: (91.51%) (21202/23168)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 190 |  Loss: (0.2466) | Acc: (91.52%) (22374/24448)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 200 |  Loss: (0.2472) | Acc: (91.45%) (23527/25728)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 210 |  Loss: (0.2466) | Acc: (91.43%) (24694/27008)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 220 |  Loss: (0.2462) | Acc: (91.46%) (25873/28288)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 230 |  Loss: (0.2451) | Acc: (91.50%) (27054/29568)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 240 |  Loss: (0.2445) | Acc: (91.53%) (28235/30848)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 250 |  Loss: (0.2440) | Acc: (91.57%) (29419/32128)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 260 |  Loss: (0.2451) | Acc: (91.55%) (30584/33408)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 270 |  Loss: (0.2465) | Acc: (91.49%) (31737/34688)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 280 |  Loss: (0.2474) | Acc: (91.43%) (32887/35968)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 290 |  Loss: (0.2484) | Acc: (91.42%) (34051/37248)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 300 |  Loss: (0.2485) | Acc: (91.42%) (35222/38528)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 310 |  Loss: (0.2490) | Acc: (91.39%) (36380/39808)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 320 |  Loss: (0.2484) | Acc: (91.40%) (37556/41088)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 330 |  Loss: (0.2491) | Acc: (91.37%) (38711/42368)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 340 |  Loss: (0.2498) | Acc: (91.35%) (39874/43648)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 350 |  Loss: (0.2498) | Acc: (91.34%) (41039/44928)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 360 |  Loss: (0.2491) | Acc: (91.36%) (42216/46208)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 370 |  Loss: (0.2485) | Acc: (91.37%) (43392/47488)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 380 |  Loss: (0.2480) | Acc: (91.41%) (44579/48768)\n",
      "lr: 0.001\n",
      "Epoch: 44 | Batch_idx: 390 |  Loss: (0.2481) | Acc: (91.40%) (45699/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.1314) | Acc: (36.30%) (3630/10000)\n",
      "Epoch: 45 | Batch_idx: 0 |  Loss: (0.2889) | Acc: (91.41%) (117/128)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 10 |  Loss: (0.2350) | Acc: (92.05%) (1296/1408)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 20 |  Loss: (0.2546) | Acc: (91.33%) (2455/2688)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 30 |  Loss: (0.2384) | Acc: (91.89%) (3646/3968)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 40 |  Loss: (0.2361) | Acc: (91.83%) (4819/5248)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 50 |  Loss: (0.2359) | Acc: (92.02%) (6007/6528)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 60 |  Loss: (0.2392) | Acc: (91.73%) (7162/7808)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 70 |  Loss: (0.2396) | Acc: (91.69%) (8333/9088)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 80 |  Loss: (0.2359) | Acc: (91.84%) (9522/10368)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 90 |  Loss: (0.2384) | Acc: (91.86%) (10700/11648)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 100 |  Loss: (0.2366) | Acc: (91.86%) (11876/12928)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 110 |  Loss: (0.2389) | Acc: (91.81%) (13045/14208)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 120 |  Loss: (0.2400) | Acc: (91.74%) (14209/15488)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 130 |  Loss: (0.2417) | Acc: (91.70%) (15376/16768)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 140 |  Loss: (0.2436) | Acc: (91.65%) (16541/18048)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 150 |  Loss: (0.2446) | Acc: (91.64%) (17713/19328)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 160 |  Loss: (0.2433) | Acc: (91.68%) (18894/20608)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 170 |  Loss: (0.2419) | Acc: (91.72%) (20076/21888)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 180 |  Loss: (0.2417) | Acc: (91.68%) (21241/23168)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 190 |  Loss: (0.2420) | Acc: (91.64%) (22404/24448)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 200 |  Loss: (0.2406) | Acc: (91.69%) (23589/25728)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 210 |  Loss: (0.2416) | Acc: (91.65%) (24753/27008)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 220 |  Loss: (0.2413) | Acc: (91.68%) (25934/28288)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 230 |  Loss: (0.2432) | Acc: (91.60%) (27083/29568)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 240 |  Loss: (0.2432) | Acc: (91.61%) (28259/30848)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 250 |  Loss: (0.2438) | Acc: (91.57%) (29421/32128)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 260 |  Loss: (0.2427) | Acc: (91.62%) (30608/33408)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 270 |  Loss: (0.2437) | Acc: (91.58%) (31766/34688)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 280 |  Loss: (0.2436) | Acc: (91.57%) (32936/35968)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 290 |  Loss: (0.2462) | Acc: (91.49%) (34078/37248)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 300 |  Loss: (0.2459) | Acc: (91.48%) (35244/38528)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 310 |  Loss: (0.2468) | Acc: (91.46%) (36408/39808)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 320 |  Loss: (0.2461) | Acc: (91.48%) (37588/41088)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 330 |  Loss: (0.2459) | Acc: (91.49%) (38764/42368)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 340 |  Loss: (0.2462) | Acc: (91.49%) (39933/43648)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 350 |  Loss: (0.2468) | Acc: (91.47%) (41094/44928)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 360 |  Loss: (0.2471) | Acc: (91.47%) (42267/46208)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 370 |  Loss: (0.2473) | Acc: (91.44%) (43425/47488)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 380 |  Loss: (0.2490) | Acc: (91.35%) (44552/48768)\n",
      "lr: 0.001\n",
      "Epoch: 45 | Batch_idx: 390 |  Loss: (0.2492) | Acc: (91.36%) (45680/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.5485) | Acc: (32.83%) (3283/10000)\n",
      "Epoch: 46 | Batch_idx: 0 |  Loss: (0.2216) | Acc: (92.19%) (118/128)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 10 |  Loss: (0.2339) | Acc: (92.05%) (1296/1408)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 20 |  Loss: (0.2325) | Acc: (92.26%) (2480/2688)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 30 |  Loss: (0.2354) | Acc: (91.99%) (3650/3968)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 40 |  Loss: (0.2434) | Acc: (91.46%) (4800/5248)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 50 |  Loss: (0.2419) | Acc: (91.39%) (5966/6528)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 60 |  Loss: (0.2369) | Acc: (91.71%) (7161/7808)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 70 |  Loss: (0.2367) | Acc: (91.56%) (8321/9088)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 80 |  Loss: (0.2426) | Acc: (91.32%) (9468/10368)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 90 |  Loss: (0.2382) | Acc: (91.47%) (10654/11648)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 100 |  Loss: (0.2370) | Acc: (91.54%) (11834/12928)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 110 |  Loss: (0.2358) | Acc: (91.58%) (13011/14208)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 120 |  Loss: (0.2324) | Acc: (91.72%) (14206/15488)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 130 |  Loss: (0.2322) | Acc: (91.75%) (15384/16768)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 140 |  Loss: (0.2330) | Acc: (91.76%) (16561/18048)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 150 |  Loss: (0.2339) | Acc: (91.69%) (17722/19328)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 160 |  Loss: (0.2338) | Acc: (91.73%) (18904/20608)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 170 |  Loss: (0.2339) | Acc: (91.75%) (20083/21888)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 180 |  Loss: (0.2375) | Acc: (91.65%) (21234/23168)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 190 |  Loss: (0.2372) | Acc: (91.66%) (22410/24448)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 200 |  Loss: (0.2370) | Acc: (91.68%) (23588/25728)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 210 |  Loss: (0.2369) | Acc: (91.68%) (24761/27008)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 220 |  Loss: (0.2373) | Acc: (91.67%) (25933/28288)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 230 |  Loss: (0.2379) | Acc: (91.66%) (27103/29568)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 240 |  Loss: (0.2377) | Acc: (91.67%) (28279/30848)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 250 |  Loss: (0.2367) | Acc: (91.70%) (29462/32128)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 260 |  Loss: (0.2367) | Acc: (91.71%) (30637/33408)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 270 |  Loss: (0.2364) | Acc: (91.71%) (31812/34688)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 280 |  Loss: (0.2361) | Acc: (91.70%) (32981/35968)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 290 |  Loss: (0.2364) | Acc: (91.69%) (34152/37248)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 300 |  Loss: (0.2365) | Acc: (91.73%) (35341/38528)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 310 |  Loss: (0.2360) | Acc: (91.73%) (36517/39808)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 320 |  Loss: (0.2358) | Acc: (91.75%) (37699/41088)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 330 |  Loss: (0.2360) | Acc: (91.76%) (38875/42368)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 340 |  Loss: (0.2361) | Acc: (91.76%) (40051/43648)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 350 |  Loss: (0.2354) | Acc: (91.78%) (41236/44928)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 360 |  Loss: (0.2357) | Acc: (91.76%) (42402/46208)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 370 |  Loss: (0.2360) | Acc: (91.74%) (43566/47488)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 380 |  Loss: (0.2365) | Acc: (91.72%) (44729/48768)\n",
      "lr: 0.001\n",
      "Epoch: 46 | Batch_idx: 390 |  Loss: (0.2371) | Acc: (91.69%) (45846/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.2421) | Acc: (39.02%) (3902/10000)\n",
      "Epoch: 47 | Batch_idx: 0 |  Loss: (0.2427) | Acc: (91.41%) (117/128)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 10 |  Loss: (0.2354) | Acc: (91.48%) (1288/1408)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 20 |  Loss: (0.2421) | Acc: (91.18%) (2451/2688)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 30 |  Loss: (0.2375) | Acc: (91.51%) (3631/3968)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 40 |  Loss: (0.2416) | Acc: (91.54%) (4804/5248)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 50 |  Loss: (0.2431) | Acc: (91.42%) (5968/6528)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 60 |  Loss: (0.2448) | Acc: (91.33%) (7131/7808)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 70 |  Loss: (0.2402) | Acc: (91.49%) (8315/9088)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 80 |  Loss: (0.2355) | Acc: (91.70%) (9507/10368)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 90 |  Loss: (0.2334) | Acc: (91.76%) (10688/11648)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 100 |  Loss: (0.2351) | Acc: (91.72%) (11857/12928)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 110 |  Loss: (0.2353) | Acc: (91.69%) (13027/14208)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 120 |  Loss: (0.2354) | Acc: (91.69%) (14201/15488)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 130 |  Loss: (0.2343) | Acc: (91.74%) (15383/16768)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 140 |  Loss: (0.2351) | Acc: (91.73%) (16555/18048)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 150 |  Loss: (0.2360) | Acc: (91.74%) (17732/19328)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 160 |  Loss: (0.2372) | Acc: (91.70%) (18897/20608)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 170 |  Loss: (0.2388) | Acc: (91.61%) (20052/21888)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 180 |  Loss: (0.2399) | Acc: (91.57%) (21215/23168)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 190 |  Loss: (0.2396) | Acc: (91.59%) (22391/24448)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 200 |  Loss: (0.2413) | Acc: (91.54%) (23552/25728)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 210 |  Loss: (0.2420) | Acc: (91.52%) (24718/27008)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 220 |  Loss: (0.2433) | Acc: (91.51%) (25886/28288)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 230 |  Loss: (0.2421) | Acc: (91.59%) (27082/29568)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 240 |  Loss: (0.2417) | Acc: (91.60%) (28257/30848)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 250 |  Loss: (0.2412) | Acc: (91.60%) (29429/32128)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 260 |  Loss: (0.2414) | Acc: (91.60%) (30602/33408)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 270 |  Loss: (0.2409) | Acc: (91.61%) (31777/34688)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 280 |  Loss: (0.2403) | Acc: (91.61%) (32949/35968)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 290 |  Loss: (0.2401) | Acc: (91.61%) (34124/37248)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 300 |  Loss: (0.2397) | Acc: (91.63%) (35304/38528)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 310 |  Loss: (0.2400) | Acc: (91.64%) (36482/39808)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 320 |  Loss: (0.2402) | Acc: (91.64%) (37653/41088)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 330 |  Loss: (0.2405) | Acc: (91.60%) (38809/42368)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 340 |  Loss: (0.2400) | Acc: (91.62%) (39991/43648)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 350 |  Loss: (0.2397) | Acc: (91.63%) (41166/44928)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 360 |  Loss: (0.2394) | Acc: (91.65%) (42348/46208)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 370 |  Loss: (0.2406) | Acc: (91.62%) (43508/47488)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 380 |  Loss: (0.2404) | Acc: (91.63%) (44686/48768)\n",
      "lr: 0.001\n",
      "Epoch: 47 | Batch_idx: 390 |  Loss: (0.2406) | Acc: (91.62%) (45810/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3202) | Acc: (32.60%) (3260/10000)\n",
      "Epoch: 48 | Batch_idx: 0 |  Loss: (0.2520) | Acc: (93.75%) (120/128)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 10 |  Loss: (0.2366) | Acc: (92.12%) (1297/1408)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 20 |  Loss: (0.2285) | Acc: (92.11%) (2476/2688)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 30 |  Loss: (0.2315) | Acc: (92.04%) (3652/3968)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 40 |  Loss: (0.2227) | Acc: (92.28%) (4843/5248)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 50 |  Loss: (0.2267) | Acc: (91.90%) (5999/6528)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 60 |  Loss: (0.2236) | Acc: (92.09%) (7190/7808)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 70 |  Loss: (0.2272) | Acc: (91.97%) (8358/9088)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 80 |  Loss: (0.2318) | Acc: (91.78%) (9516/10368)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 90 |  Loss: (0.2321) | Acc: (91.82%) (10695/11648)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 100 |  Loss: (0.2300) | Acc: (91.96%) (11889/12928)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 110 |  Loss: (0.2286) | Acc: (92.03%) (13075/14208)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 120 |  Loss: (0.2283) | Acc: (92.06%) (14258/15488)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 130 |  Loss: (0.2289) | Acc: (92.07%) (15439/16768)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 140 |  Loss: (0.2299) | Acc: (92.07%) (16616/18048)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 150 |  Loss: (0.2280) | Acc: (92.10%) (17802/19328)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 160 |  Loss: (0.2281) | Acc: (92.11%) (18983/20608)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 170 |  Loss: (0.2310) | Acc: (91.99%) (20135/21888)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 180 |  Loss: (0.2317) | Acc: (92.03%) (21321/23168)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 190 |  Loss: (0.2306) | Acc: (92.11%) (22519/24448)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 200 |  Loss: (0.2313) | Acc: (92.11%) (23698/25728)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 210 |  Loss: (0.2319) | Acc: (92.08%) (24869/27008)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 220 |  Loss: (0.2339) | Acc: (92.01%) (26028/28288)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 230 |  Loss: (0.2331) | Acc: (92.02%) (27208/29568)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 240 |  Loss: (0.2327) | Acc: (92.02%) (28387/30848)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 250 |  Loss: (0.2341) | Acc: (91.99%) (29554/32128)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 260 |  Loss: (0.2351) | Acc: (91.95%) (30718/33408)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 270 |  Loss: (0.2337) | Acc: (92.01%) (31916/34688)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 280 |  Loss: (0.2339) | Acc: (92.03%) (33103/35968)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 290 |  Loss: (0.2351) | Acc: (91.98%) (34260/37248)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 300 |  Loss: (0.2354) | Acc: (91.92%) (35415/38528)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 310 |  Loss: (0.2351) | Acc: (91.93%) (36595/39808)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 320 |  Loss: (0.2347) | Acc: (91.92%) (37770/41088)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 330 |  Loss: (0.2354) | Acc: (91.89%) (38933/42368)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 340 |  Loss: (0.2345) | Acc: (91.93%) (40127/43648)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 350 |  Loss: (0.2341) | Acc: (91.94%) (41307/44928)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 360 |  Loss: (0.2343) | Acc: (91.94%) (42482/46208)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 370 |  Loss: (0.2349) | Acc: (91.92%) (43651/47488)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 380 |  Loss: (0.2352) | Acc: (91.93%) (44831/48768)\n",
      "lr: 0.001\n",
      "Epoch: 48 | Batch_idx: 390 |  Loss: (0.2348) | Acc: (91.94%) (45968/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.0519) | Acc: (38.80%) (3880/10000)\n",
      "Epoch: 49 | Batch_idx: 0 |  Loss: (0.1939) | Acc: (94.53%) (121/128)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 10 |  Loss: (0.2137) | Acc: (93.04%) (1310/1408)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 20 |  Loss: (0.2153) | Acc: (92.71%) (2492/2688)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 30 |  Loss: (0.2204) | Acc: (92.57%) (3673/3968)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 40 |  Loss: (0.2201) | Acc: (92.55%) (4857/5248)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 50 |  Loss: (0.2174) | Acc: (92.51%) (6039/6528)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 60 |  Loss: (0.2149) | Acc: (92.74%) (7241/7808)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 70 |  Loss: (0.2155) | Acc: (92.63%) (8418/9088)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 80 |  Loss: (0.2146) | Acc: (92.74%) (9615/10368)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 90 |  Loss: (0.2157) | Acc: (92.71%) (10799/11648)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 100 |  Loss: (0.2144) | Acc: (92.73%) (11988/12928)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 110 |  Loss: (0.2186) | Acc: (92.59%) (13155/14208)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 120 |  Loss: (0.2182) | Acc: (92.61%) (14343/15488)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 130 |  Loss: (0.2160) | Acc: (92.65%) (15535/16768)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 140 |  Loss: (0.2173) | Acc: (92.58%) (16709/18048)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 150 |  Loss: (0.2177) | Acc: (92.57%) (17891/19328)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 160 |  Loss: (0.2180) | Acc: (92.55%) (19072/20608)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 170 |  Loss: (0.2198) | Acc: (92.46%) (20237/21888)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 180 |  Loss: (0.2200) | Acc: (92.41%) (21409/23168)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 190 |  Loss: (0.2201) | Acc: (92.38%) (22585/24448)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 200 |  Loss: (0.2202) | Acc: (92.36%) (23763/25728)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 210 |  Loss: (0.2205) | Acc: (92.35%) (24941/27008)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 220 |  Loss: (0.2217) | Acc: (92.28%) (26104/28288)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 230 |  Loss: (0.2225) | Acc: (92.22%) (27268/29568)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 240 |  Loss: (0.2240) | Acc: (92.19%) (28439/30848)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 250 |  Loss: (0.2246) | Acc: (92.19%) (29619/32128)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 260 |  Loss: (0.2255) | Acc: (92.18%) (30796/33408)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 270 |  Loss: (0.2257) | Acc: (92.17%) (31973/34688)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 280 |  Loss: (0.2246) | Acc: (92.19%) (33158/35968)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 290 |  Loss: (0.2258) | Acc: (92.16%) (34327/37248)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 300 |  Loss: (0.2267) | Acc: (92.13%) (35494/38528)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 310 |  Loss: (0.2266) | Acc: (92.11%) (36669/39808)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 320 |  Loss: (0.2260) | Acc: (92.15%) (37862/41088)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 330 |  Loss: (0.2271) | Acc: (92.12%) (39029/42368)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 340 |  Loss: (0.2278) | Acc: (92.10%) (40198/43648)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 350 |  Loss: (0.2277) | Acc: (92.10%) (41380/44928)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 360 |  Loss: (0.2285) | Acc: (92.05%) (42534/46208)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 370 |  Loss: (0.2287) | Acc: (92.04%) (43706/47488)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 380 |  Loss: (0.2288) | Acc: (92.03%) (44883/48768)\n",
      "lr: 0.001\n",
      "Epoch: 49 | Batch_idx: 390 |  Loss: (0.2283) | Acc: (92.04%) (46018/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.7394) | Acc: (45.13%) (4513/10000)\n",
      "Epoch: 50 | Batch_idx: 0 |  Loss: (0.2425) | Acc: (89.84%) (115/128)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 10 |  Loss: (0.2178) | Acc: (91.62%) (1290/1408)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 20 |  Loss: (0.2196) | Acc: (91.63%) (2463/2688)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 30 |  Loss: (0.2218) | Acc: (91.53%) (3632/3968)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 40 |  Loss: (0.2240) | Acc: (91.60%) (4807/5248)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 50 |  Loss: (0.2283) | Acc: (91.54%) (5976/6528)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 60 |  Loss: (0.2260) | Acc: (91.79%) (7167/7808)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 70 |  Loss: (0.2246) | Acc: (91.92%) (8354/9088)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 80 |  Loss: (0.2223) | Acc: (92.09%) (9548/10368)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 90 |  Loss: (0.2208) | Acc: (92.15%) (10734/11648)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 100 |  Loss: (0.2204) | Acc: (92.16%) (11915/12928)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 110 |  Loss: (0.2221) | Acc: (92.20%) (13100/14208)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 120 |  Loss: (0.2221) | Acc: (92.19%) (14279/15488)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 130 |  Loss: (0.2217) | Acc: (92.21%) (15462/16768)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 140 |  Loss: (0.2224) | Acc: (92.21%) (16642/18048)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 150 |  Loss: (0.2235) | Acc: (92.15%) (17810/19328)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 160 |  Loss: (0.2236) | Acc: (92.16%) (18993/20608)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 170 |  Loss: (0.2242) | Acc: (92.14%) (20168/21888)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 180 |  Loss: (0.2236) | Acc: (92.15%) (21349/23168)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 190 |  Loss: (0.2234) | Acc: (92.14%) (22527/24448)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 200 |  Loss: (0.2243) | Acc: (92.10%) (23696/25728)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 210 |  Loss: (0.2250) | Acc: (92.11%) (24878/27008)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 220 |  Loss: (0.2235) | Acc: (92.19%) (26078/28288)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 230 |  Loss: (0.2225) | Acc: (92.25%) (27277/29568)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 240 |  Loss: (0.2223) | Acc: (92.25%) (28458/30848)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 250 |  Loss: (0.2231) | Acc: (92.22%) (29629/32128)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 260 |  Loss: (0.2223) | Acc: (92.27%) (30827/33408)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 270 |  Loss: (0.2214) | Acc: (92.27%) (32007/34688)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 280 |  Loss: (0.2202) | Acc: (92.30%) (33197/35968)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 290 |  Loss: (0.2211) | Acc: (92.29%) (34378/37248)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 300 |  Loss: (0.2215) | Acc: (92.28%) (35555/38528)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 310 |  Loss: (0.2217) | Acc: (92.26%) (36728/39808)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 320 |  Loss: (0.2217) | Acc: (92.27%) (37912/41088)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 330 |  Loss: (0.2222) | Acc: (92.27%) (39093/42368)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 340 |  Loss: (0.2233) | Acc: (92.22%) (40254/43648)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 350 |  Loss: (0.2233) | Acc: (92.21%) (41429/44928)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 360 |  Loss: (0.2240) | Acc: (92.19%) (42598/46208)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 370 |  Loss: (0.2245) | Acc: (92.18%) (43773/47488)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 380 |  Loss: (0.2245) | Acc: (92.18%) (44952/48768)\n",
      "lr: 0.001\n",
      "Epoch: 50 | Batch_idx: 390 |  Loss: (0.2245) | Acc: (92.18%) (46090/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.9271) | Acc: (40.57%) (4057/10000)\n",
      "Epoch: 51 | Batch_idx: 0 |  Loss: (0.1790) | Acc: (93.75%) (120/128)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 10 |  Loss: (0.2196) | Acc: (92.61%) (1304/1408)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 20 |  Loss: (0.2116) | Acc: (92.60%) (2489/2688)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 30 |  Loss: (0.2140) | Acc: (92.57%) (3673/3968)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 40 |  Loss: (0.2142) | Acc: (92.78%) (4869/5248)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 50 |  Loss: (0.2112) | Acc: (92.78%) (6057/6528)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 60 |  Loss: (0.2188) | Acc: (92.60%) (7230/7808)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 70 |  Loss: (0.2180) | Acc: (92.55%) (8411/9088)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 80 |  Loss: (0.2190) | Acc: (92.48%) (9588/10368)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 90 |  Loss: (0.2214) | Acc: (92.35%) (10757/11648)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 100 |  Loss: (0.2219) | Acc: (92.28%) (11930/12928)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 110 |  Loss: (0.2207) | Acc: (92.36%) (13123/14208)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 120 |  Loss: (0.2209) | Acc: (92.35%) (14303/15488)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 130 |  Loss: (0.2213) | Acc: (92.30%) (15477/16768)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 140 |  Loss: (0.2209) | Acc: (92.30%) (16659/18048)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 150 |  Loss: (0.2212) | Acc: (92.36%) (17851/19328)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 160 |  Loss: (0.2222) | Acc: (92.34%) (19030/20608)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 170 |  Loss: (0.2222) | Acc: (92.34%) (20212/21888)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 180 |  Loss: (0.2219) | Acc: (92.33%) (21391/23168)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 190 |  Loss: (0.2217) | Acc: (92.33%) (22574/24448)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 200 |  Loss: (0.2208) | Acc: (92.37%) (23764/25728)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 210 |  Loss: (0.2210) | Acc: (92.37%) (24946/27008)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 220 |  Loss: (0.2210) | Acc: (92.36%) (26126/28288)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 230 |  Loss: (0.2214) | Acc: (92.33%) (27299/29568)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 240 |  Loss: (0.2224) | Acc: (92.28%) (28467/30848)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 250 |  Loss: (0.2225) | Acc: (92.30%) (29653/32128)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 260 |  Loss: (0.2225) | Acc: (92.27%) (30826/33408)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 270 |  Loss: (0.2217) | Acc: (92.30%) (32016/34688)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 280 |  Loss: (0.2223) | Acc: (92.29%) (33196/35968)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 290 |  Loss: (0.2227) | Acc: (92.27%) (34370/37248)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 300 |  Loss: (0.2221) | Acc: (92.27%) (35551/38528)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 310 |  Loss: (0.2224) | Acc: (92.27%) (36730/39808)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 320 |  Loss: (0.2220) | Acc: (92.28%) (37916/41088)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 330 |  Loss: (0.2215) | Acc: (92.31%) (39111/42368)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 340 |  Loss: (0.2209) | Acc: (92.35%) (40308/43648)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 350 |  Loss: (0.2209) | Acc: (92.33%) (41481/44928)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 360 |  Loss: (0.2206) | Acc: (92.34%) (42667/46208)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 370 |  Loss: (0.2201) | Acc: (92.37%) (43863/47488)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 380 |  Loss: (0.2208) | Acc: (92.32%) (45025/48768)\n",
      "lr: 0.001\n",
      "Epoch: 51 | Batch_idx: 390 |  Loss: (0.2213) | Acc: (92.32%) (46161/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.6504) | Acc: (38.23%) (3823/10000)\n",
      "Epoch: 52 | Batch_idx: 0 |  Loss: (0.2612) | Acc: (89.06%) (114/128)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 10 |  Loss: (0.2246) | Acc: (91.90%) (1294/1408)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 20 |  Loss: (0.2248) | Acc: (92.15%) (2477/2688)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 30 |  Loss: (0.2130) | Acc: (92.49%) (3670/3968)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 40 |  Loss: (0.2132) | Acc: (92.61%) (4860/5248)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 50 |  Loss: (0.2226) | Acc: (92.40%) (6032/6528)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 60 |  Loss: (0.2232) | Acc: (92.37%) (7212/7808)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 70 |  Loss: (0.2239) | Acc: (92.34%) (8392/9088)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 80 |  Loss: (0.2261) | Acc: (92.25%) (9564/10368)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 90 |  Loss: (0.2309) | Acc: (91.98%) (10714/11648)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 100 |  Loss: (0.2288) | Acc: (92.00%) (11894/12928)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 110 |  Loss: (0.2276) | Acc: (92.00%) (13072/14208)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 120 |  Loss: (0.2263) | Acc: (92.11%) (14266/15488)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 130 |  Loss: (0.2247) | Acc: (92.12%) (15447/16768)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 140 |  Loss: (0.2236) | Acc: (92.17%) (16635/18048)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 150 |  Loss: (0.2223) | Acc: (92.23%) (17827/19328)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 160 |  Loss: (0.2225) | Acc: (92.24%) (19008/20608)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 170 |  Loss: (0.2213) | Acc: (92.25%) (20192/21888)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 180 |  Loss: (0.2205) | Acc: (92.31%) (21386/23168)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 190 |  Loss: (0.2196) | Acc: (92.33%) (22574/24448)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 200 |  Loss: (0.2190) | Acc: (92.36%) (23763/25728)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 210 |  Loss: (0.2181) | Acc: (92.42%) (24960/27008)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 220 |  Loss: (0.2168) | Acc: (92.50%) (26165/28288)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 230 |  Loss: (0.2147) | Acc: (92.54%) (27361/29568)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 240 |  Loss: (0.2158) | Acc: (92.54%) (28546/30848)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 250 |  Loss: (0.2174) | Acc: (92.44%) (29700/32128)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 260 |  Loss: (0.2183) | Acc: (92.41%) (30873/33408)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 270 |  Loss: (0.2167) | Acc: (92.46%) (32071/34688)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 280 |  Loss: (0.2169) | Acc: (92.44%) (33249/35968)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 290 |  Loss: (0.2169) | Acc: (92.42%) (34425/37248)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 300 |  Loss: (0.2176) | Acc: (92.41%) (35602/38528)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 310 |  Loss: (0.2183) | Acc: (92.37%) (36770/39808)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 320 |  Loss: (0.2174) | Acc: (92.39%) (37960/41088)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 330 |  Loss: (0.2173) | Acc: (92.41%) (39152/42368)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 340 |  Loss: (0.2172) | Acc: (92.42%) (40340/43648)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 350 |  Loss: (0.2178) | Acc: (92.39%) (41511/44928)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 360 |  Loss: (0.2183) | Acc: (92.39%) (42693/46208)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 370 |  Loss: (0.2185) | Acc: (92.39%) (43874/47488)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 380 |  Loss: (0.2182) | Acc: (92.40%) (45060/48768)\n",
      "lr: 0.001\n",
      "Epoch: 52 | Batch_idx: 390 |  Loss: (0.2181) | Acc: (92.38%) (46192/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.0042) | Acc: (44.68%) (4468/10000)\n",
      "Epoch: 53 | Batch_idx: 0 |  Loss: (0.2169) | Acc: (93.75%) (120/128)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 10 |  Loss: (0.2071) | Acc: (92.61%) (1304/1408)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 20 |  Loss: (0.2005) | Acc: (93.01%) (2500/2688)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 30 |  Loss: (0.2155) | Acc: (92.31%) (3663/3968)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 40 |  Loss: (0.2179) | Acc: (92.13%) (4835/5248)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 50 |  Loss: (0.2162) | Acc: (92.23%) (6021/6528)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 60 |  Loss: (0.2158) | Acc: (92.26%) (7204/7808)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 70 |  Loss: (0.2170) | Acc: (92.24%) (8383/9088)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 80 |  Loss: (0.2165) | Acc: (92.27%) (9567/10368)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 90 |  Loss: (0.2138) | Acc: (92.40%) (10763/11648)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 100 |  Loss: (0.2175) | Acc: (92.29%) (11931/12928)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 110 |  Loss: (0.2141) | Acc: (92.39%) (13127/14208)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 120 |  Loss: (0.2157) | Acc: (92.32%) (14299/15488)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 130 |  Loss: (0.2147) | Acc: (92.31%) (15478/16768)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 140 |  Loss: (0.2172) | Acc: (92.25%) (16649/18048)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 150 |  Loss: (0.2171) | Acc: (92.27%) (17833/19328)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 160 |  Loss: (0.2184) | Acc: (92.16%) (18993/20608)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 170 |  Loss: (0.2185) | Acc: (92.24%) (20190/21888)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 180 |  Loss: (0.2173) | Acc: (92.27%) (21378/23168)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 190 |  Loss: (0.2180) | Acc: (92.29%) (22563/24448)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 200 |  Loss: (0.2189) | Acc: (92.27%) (23740/25728)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 210 |  Loss: (0.2186) | Acc: (92.27%) (24919/27008)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 220 |  Loss: (0.2177) | Acc: (92.29%) (26107/28288)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 230 |  Loss: (0.2189) | Acc: (92.27%) (27281/29568)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 240 |  Loss: (0.2196) | Acc: (92.25%) (28458/30848)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 250 |  Loss: (0.2197) | Acc: (92.26%) (29640/32128)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 260 |  Loss: (0.2184) | Acc: (92.29%) (30832/33408)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 270 |  Loss: (0.2184) | Acc: (92.29%) (32015/34688)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 280 |  Loss: (0.2177) | Acc: (92.34%) (33212/35968)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 290 |  Loss: (0.2172) | Acc: (92.35%) (34400/37248)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 300 |  Loss: (0.2178) | Acc: (92.32%) (35569/38528)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 310 |  Loss: (0.2167) | Acc: (92.35%) (36761/39808)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 320 |  Loss: (0.2172) | Acc: (92.33%) (37937/41088)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 330 |  Loss: (0.2179) | Acc: (92.30%) (39106/42368)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 340 |  Loss: (0.2179) | Acc: (92.31%) (40290/43648)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 350 |  Loss: (0.2178) | Acc: (92.28%) (41458/44928)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 360 |  Loss: (0.2175) | Acc: (92.27%) (42637/46208)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 370 |  Loss: (0.2172) | Acc: (92.29%) (43825/47488)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 380 |  Loss: (0.2170) | Acc: (92.29%) (45008/48768)\n",
      "lr: 0.001\n",
      "Epoch: 53 | Batch_idx: 390 |  Loss: (0.2164) | Acc: (92.28%) (46142/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.5573) | Acc: (37.47%) (3747/10000)\n",
      "Epoch: 54 | Batch_idx: 0 |  Loss: (0.1905) | Acc: (93.75%) (120/128)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 10 |  Loss: (0.2302) | Acc: (92.12%) (1297/1408)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 20 |  Loss: (0.2233) | Acc: (92.22%) (2479/2688)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 30 |  Loss: (0.2192) | Acc: (92.36%) (3665/3968)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 40 |  Loss: (0.2255) | Acc: (92.17%) (4837/5248)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 50 |  Loss: (0.2220) | Acc: (92.11%) (6013/6528)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 60 |  Loss: (0.2197) | Acc: (92.23%) (7201/7808)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 70 |  Loss: (0.2168) | Acc: (92.42%) (8399/9088)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 80 |  Loss: (0.2169) | Acc: (92.44%) (9584/10368)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 90 |  Loss: (0.2146) | Acc: (92.48%) (10772/11648)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 100 |  Loss: (0.2151) | Acc: (92.47%) (11955/12928)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 110 |  Loss: (0.2165) | Acc: (92.48%) (13140/14208)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 120 |  Loss: (0.2174) | Acc: (92.45%) (14319/15488)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 130 |  Loss: (0.2178) | Acc: (92.47%) (15505/16768)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 140 |  Loss: (0.2150) | Acc: (92.61%) (16714/18048)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 150 |  Loss: (0.2137) | Acc: (92.62%) (17901/19328)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 160 |  Loss: (0.2133) | Acc: (92.68%) (19099/20608)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 170 |  Loss: (0.2117) | Acc: (92.70%) (20291/21888)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 180 |  Loss: (0.2114) | Acc: (92.71%) (21478/23168)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 190 |  Loss: (0.2124) | Acc: (92.65%) (22650/24448)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 200 |  Loss: (0.2128) | Acc: (92.62%) (23830/25728)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 210 |  Loss: (0.2135) | Acc: (92.61%) (25012/27008)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 220 |  Loss: (0.2140) | Acc: (92.59%) (26193/28288)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 230 |  Loss: (0.2122) | Acc: (92.67%) (27402/29568)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 240 |  Loss: (0.2124) | Acc: (92.68%) (28589/30848)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 250 |  Loss: (0.2114) | Acc: (92.72%) (29788/32128)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 260 |  Loss: (0.2104) | Acc: (92.75%) (30986/33408)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 270 |  Loss: (0.2101) | Acc: (92.76%) (32176/34688)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 280 |  Loss: (0.2105) | Acc: (92.74%) (33358/35968)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 290 |  Loss: (0.2109) | Acc: (92.74%) (34542/37248)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 300 |  Loss: (0.2114) | Acc: (92.70%) (35716/38528)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 310 |  Loss: (0.2110) | Acc: (92.72%) (36910/39808)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 320 |  Loss: (0.2107) | Acc: (92.72%) (38098/41088)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 330 |  Loss: (0.2106) | Acc: (92.71%) (39281/42368)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 340 |  Loss: (0.2101) | Acc: (92.73%) (40474/43648)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 350 |  Loss: (0.2096) | Acc: (92.74%) (41668/44928)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 360 |  Loss: (0.2098) | Acc: (92.72%) (42844/46208)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 370 |  Loss: (0.2093) | Acc: (92.73%) (44037/47488)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 380 |  Loss: (0.2087) | Acc: (92.74%) (45228/48768)\n",
      "lr: 0.001\n",
      "Epoch: 54 | Batch_idx: 390 |  Loss: (0.2093) | Acc: (92.74%) (46368/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.0019) | Acc: (34.10%) (3410/10000)\n",
      "Epoch: 55 | Batch_idx: 0 |  Loss: (0.2192) | Acc: (93.75%) (120/128)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 10 |  Loss: (0.2199) | Acc: (92.05%) (1296/1408)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 20 |  Loss: (0.2119) | Acc: (92.37%) (2483/2688)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 30 |  Loss: (0.2192) | Acc: (91.99%) (3650/3968)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 40 |  Loss: (0.2141) | Acc: (92.23%) (4840/5248)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 50 |  Loss: (0.2129) | Acc: (92.39%) (6031/6528)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 60 |  Loss: (0.2109) | Acc: (92.60%) (7230/7808)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 70 |  Loss: (0.2135) | Acc: (92.42%) (8399/9088)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 80 |  Loss: (0.2132) | Acc: (92.37%) (9577/10368)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 90 |  Loss: (0.2130) | Acc: (92.38%) (10761/11648)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 100 |  Loss: (0.2116) | Acc: (92.49%) (11957/12928)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 110 |  Loss: (0.2105) | Acc: (92.53%) (13147/14208)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 120 |  Loss: (0.2094) | Acc: (92.54%) (14333/15488)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 130 |  Loss: (0.2094) | Acc: (92.59%) (15525/16768)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 140 |  Loss: (0.2119) | Acc: (92.59%) (16711/18048)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 150 |  Loss: (0.2115) | Acc: (92.63%) (17903/19328)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 160 |  Loss: (0.2130) | Acc: (92.54%) (19070/20608)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 170 |  Loss: (0.2119) | Acc: (92.58%) (20263/21888)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 180 |  Loss: (0.2121) | Acc: (92.55%) (21441/23168)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 190 |  Loss: (0.2107) | Acc: (92.60%) (22640/24448)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 200 |  Loss: (0.2119) | Acc: (92.56%) (23813/25728)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 210 |  Loss: (0.2126) | Acc: (92.51%) (24986/27008)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 220 |  Loss: (0.2117) | Acc: (92.55%) (26181/28288)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 230 |  Loss: (0.2113) | Acc: (92.56%) (27368/29568)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 240 |  Loss: (0.2123) | Acc: (92.52%) (28541/30848)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 250 |  Loss: (0.2128) | Acc: (92.52%) (29726/32128)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 260 |  Loss: (0.2138) | Acc: (92.47%) (30891/33408)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 270 |  Loss: (0.2133) | Acc: (92.46%) (32073/34688)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 280 |  Loss: (0.2130) | Acc: (92.46%) (33255/35968)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 290 |  Loss: (0.2134) | Acc: (92.46%) (34438/37248)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 300 |  Loss: (0.2126) | Acc: (92.50%) (35638/38528)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 310 |  Loss: (0.2122) | Acc: (92.53%) (36833/39808)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 320 |  Loss: (0.2121) | Acc: (92.55%) (38025/41088)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 330 |  Loss: (0.2122) | Acc: (92.55%) (39211/42368)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 340 |  Loss: (0.2118) | Acc: (92.57%) (40404/43648)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 350 |  Loss: (0.2119) | Acc: (92.53%) (41571/44928)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 360 |  Loss: (0.2117) | Acc: (92.53%) (42757/46208)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 370 |  Loss: (0.2116) | Acc: (92.54%) (43944/47488)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 380 |  Loss: (0.2118) | Acc: (92.53%) (45125/48768)\n",
      "lr: 0.001\n",
      "Epoch: 55 | Batch_idx: 390 |  Loss: (0.2117) | Acc: (92.52%) (46261/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.8226) | Acc: (46.79%) (4679/10000)\n",
      "Epoch: 56 | Batch_idx: 0 |  Loss: (0.1786) | Acc: (94.53%) (121/128)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 10 |  Loss: (0.2225) | Acc: (92.90%) (1308/1408)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 20 |  Loss: (0.2070) | Acc: (93.01%) (2500/2688)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 30 |  Loss: (0.2013) | Acc: (93.12%) (3695/3968)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 40 |  Loss: (0.1949) | Acc: (93.50%) (4907/5248)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 50 |  Loss: (0.1896) | Acc: (93.64%) (6113/6528)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 60 |  Loss: (0.1984) | Acc: (93.33%) (7287/7808)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 70 |  Loss: (0.1992) | Acc: (93.36%) (8485/9088)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 80 |  Loss: (0.1988) | Acc: (93.34%) (9678/10368)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 90 |  Loss: (0.1986) | Acc: (93.44%) (10884/11648)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 100 |  Loss: (0.1978) | Acc: (93.43%) (12079/12928)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 110 |  Loss: (0.1983) | Acc: (93.38%) (13268/14208)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 120 |  Loss: (0.1991) | Acc: (93.32%) (14453/15488)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 130 |  Loss: (0.2000) | Acc: (93.31%) (15646/16768)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 140 |  Loss: (0.2001) | Acc: (93.27%) (16833/18048)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 150 |  Loss: (0.2004) | Acc: (93.26%) (18026/19328)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 160 |  Loss: (0.2001) | Acc: (93.24%) (19215/20608)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 170 |  Loss: (0.2009) | Acc: (93.17%) (20394/21888)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 180 |  Loss: (0.2025) | Acc: (93.13%) (21576/23168)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 190 |  Loss: (0.2013) | Acc: (93.13%) (22768/24448)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 200 |  Loss: (0.2009) | Acc: (93.12%) (23958/25728)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 210 |  Loss: (0.2024) | Acc: (93.06%) (25134/27008)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 220 |  Loss: (0.2025) | Acc: (93.07%) (26327/28288)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 230 |  Loss: (0.2038) | Acc: (93.05%) (27514/29568)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 240 |  Loss: (0.2032) | Acc: (93.09%) (28715/30848)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 250 |  Loss: (0.2036) | Acc: (93.04%) (29891/32128)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 260 |  Loss: (0.2036) | Acc: (93.05%) (31085/33408)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 270 |  Loss: (0.2054) | Acc: (92.97%) (32249/34688)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 280 |  Loss: (0.2067) | Acc: (92.91%) (33417/35968)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 290 |  Loss: (0.2065) | Acc: (92.91%) (34607/37248)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 300 |  Loss: (0.2077) | Acc: (92.87%) (35782/38528)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 310 |  Loss: (0.2087) | Acc: (92.83%) (36953/39808)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 320 |  Loss: (0.2085) | Acc: (92.84%) (38147/41088)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 330 |  Loss: (0.2084) | Acc: (92.84%) (39335/42368)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 340 |  Loss: (0.2080) | Acc: (92.84%) (40524/43648)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 350 |  Loss: (0.2075) | Acc: (92.87%) (41723/44928)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 360 |  Loss: (0.2076) | Acc: (92.85%) (42904/46208)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 370 |  Loss: (0.2068) | Acc: (92.88%) (44106/47488)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 380 |  Loss: (0.2072) | Acc: (92.87%) (45292/48768)\n",
      "lr: 0.001\n",
      "Epoch: 56 | Batch_idx: 390 |  Loss: (0.2075) | Acc: (92.87%) (46434/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3112) | Acc: (35.47%) (3547/10000)\n",
      "Epoch: 57 | Batch_idx: 0 |  Loss: (0.2467) | Acc: (92.19%) (118/128)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 10 |  Loss: (0.2070) | Acc: (93.54%) (1317/1408)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 20 |  Loss: (0.1945) | Acc: (93.56%) (2515/2688)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 30 |  Loss: (0.1855) | Acc: (93.78%) (3721/3968)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 40 |  Loss: (0.1921) | Acc: (93.64%) (4914/5248)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 50 |  Loss: (0.1903) | Acc: (93.66%) (6114/6528)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 60 |  Loss: (0.1940) | Acc: (93.57%) (7306/7808)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 70 |  Loss: (0.1965) | Acc: (93.40%) (8488/9088)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 80 |  Loss: (0.1946) | Acc: (93.44%) (9688/10368)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 90 |  Loss: (0.1989) | Acc: (93.17%) (10852/11648)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 100 |  Loss: (0.1998) | Acc: (93.03%) (12027/12928)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 110 |  Loss: (0.2006) | Acc: (93.03%) (13217/14208)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 120 |  Loss: (0.2030) | Acc: (92.97%) (14399/15488)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 130 |  Loss: (0.2016) | Acc: (92.99%) (15593/16768)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 140 |  Loss: (0.2017) | Acc: (92.98%) (16781/18048)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 150 |  Loss: (0.2021) | Acc: (92.94%) (17964/19328)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 160 |  Loss: (0.2013) | Acc: (93.01%) (19167/20608)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 170 |  Loss: (0.2019) | Acc: (93.01%) (20358/21888)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 180 |  Loss: (0.2050) | Acc: (92.96%) (21536/23168)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 190 |  Loss: (0.2045) | Acc: (92.95%) (22725/24448)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 200 |  Loss: (0.2055) | Acc: (92.91%) (23904/25728)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 210 |  Loss: (0.2049) | Acc: (92.91%) (25094/27008)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 220 |  Loss: (0.2055) | Acc: (92.86%) (26269/28288)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 230 |  Loss: (0.2056) | Acc: (92.86%) (27457/29568)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 240 |  Loss: (0.2044) | Acc: (92.90%) (28659/30848)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 250 |  Loss: (0.2047) | Acc: (92.88%) (29839/32128)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 260 |  Loss: (0.2050) | Acc: (92.86%) (31023/33408)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 270 |  Loss: (0.2043) | Acc: (92.85%) (32207/34688)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 280 |  Loss: (0.2040) | Acc: (92.87%) (33402/35968)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 290 |  Loss: (0.2046) | Acc: (92.86%) (34589/37248)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 300 |  Loss: (0.2032) | Acc: (92.91%) (35796/38528)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 310 |  Loss: (0.2037) | Acc: (92.88%) (36974/39808)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 320 |  Loss: (0.2037) | Acc: (92.90%) (38169/41088)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 330 |  Loss: (0.2037) | Acc: (92.86%) (39345/42368)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 340 |  Loss: (0.2040) | Acc: (92.86%) (40533/43648)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 350 |  Loss: (0.2037) | Acc: (92.88%) (41727/44928)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 360 |  Loss: (0.2040) | Acc: (92.86%) (42910/46208)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 370 |  Loss: (0.2038) | Acc: (92.87%) (44103/47488)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 380 |  Loss: (0.2040) | Acc: (92.86%) (45286/48768)\n",
      "lr: 0.001\n",
      "Epoch: 57 | Batch_idx: 390 |  Loss: (0.2045) | Acc: (92.84%) (46418/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.0482) | Acc: (37.66%) (3766/10000)\n",
      "Epoch: 58 | Batch_idx: 0 |  Loss: (0.2524) | Acc: (90.62%) (116/128)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 10 |  Loss: (0.1747) | Acc: (94.53%) (1331/1408)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 20 |  Loss: (0.1871) | Acc: (93.71%) (2519/2688)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 30 |  Loss: (0.2011) | Acc: (93.22%) (3699/3968)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 40 |  Loss: (0.2066) | Acc: (93.03%) (4882/5248)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 50 |  Loss: (0.2042) | Acc: (93.11%) (6078/6528)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 60 |  Loss: (0.2074) | Acc: (93.03%) (7264/7808)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 70 |  Loss: (0.2024) | Acc: (93.21%) (8471/9088)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 80 |  Loss: (0.2048) | Acc: (93.09%) (9652/10368)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 90 |  Loss: (0.2045) | Acc: (93.13%) (10848/11648)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 100 |  Loss: (0.2071) | Acc: (93.09%) (12035/12928)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 110 |  Loss: (0.2101) | Acc: (92.95%) (13207/14208)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 120 |  Loss: (0.2083) | Acc: (92.98%) (14401/15488)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 130 |  Loss: (0.2081) | Acc: (92.93%) (15583/16768)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 140 |  Loss: (0.2073) | Acc: (92.88%) (16763/18048)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 150 |  Loss: (0.2090) | Acc: (92.78%) (17933/19328)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 160 |  Loss: (0.2089) | Acc: (92.77%) (19118/20608)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 170 |  Loss: (0.2085) | Acc: (92.81%) (20314/21888)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 180 |  Loss: (0.2078) | Acc: (92.83%) (21506/23168)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 190 |  Loss: (0.2075) | Acc: (92.83%) (22694/24448)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 200 |  Loss: (0.2082) | Acc: (92.81%) (23879/25728)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 210 |  Loss: (0.2074) | Acc: (92.86%) (25079/27008)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 220 |  Loss: (0.2081) | Acc: (92.85%) (26266/28288)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 230 |  Loss: (0.2086) | Acc: (92.85%) (27454/29568)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 240 |  Loss: (0.2075) | Acc: (92.84%) (28640/30848)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 250 |  Loss: (0.2079) | Acc: (92.84%) (29827/32128)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 260 |  Loss: (0.2080) | Acc: (92.84%) (31016/33408)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 270 |  Loss: (0.2076) | Acc: (92.88%) (32217/34688)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 280 |  Loss: (0.2076) | Acc: (92.88%) (33408/35968)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 290 |  Loss: (0.2071) | Acc: (92.88%) (34597/37248)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 300 |  Loss: (0.2061) | Acc: (92.92%) (35800/38528)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 310 |  Loss: (0.2062) | Acc: (92.90%) (36982/39808)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 320 |  Loss: (0.2055) | Acc: (92.93%) (38183/41088)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 330 |  Loss: (0.2061) | Acc: (92.90%) (39360/42368)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 340 |  Loss: (0.2057) | Acc: (92.90%) (40551/43648)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 350 |  Loss: (0.2051) | Acc: (92.93%) (41752/44928)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 360 |  Loss: (0.2055) | Acc: (92.92%) (42935/46208)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 370 |  Loss: (0.2048) | Acc: (92.95%) (44138/47488)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 380 |  Loss: (0.2044) | Acc: (92.97%) (45339/48768)\n",
      "lr: 0.001\n",
      "Epoch: 58 | Batch_idx: 390 |  Loss: (0.2049) | Acc: (92.96%) (46481/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.6859) | Acc: (37.16%) (3716/10000)\n",
      "Epoch: 59 | Batch_idx: 0 |  Loss: (0.1909) | Acc: (90.62%) (116/128)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 10 |  Loss: (0.1994) | Acc: (92.26%) (1299/1408)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 20 |  Loss: (0.1895) | Acc: (93.01%) (2500/2688)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 30 |  Loss: (0.1922) | Acc: (92.94%) (3688/3968)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 40 |  Loss: (0.1898) | Acc: (93.27%) (4895/5248)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 50 |  Loss: (0.1913) | Acc: (93.31%) (6091/6528)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 60 |  Loss: (0.1907) | Acc: (93.26%) (7282/7808)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 70 |  Loss: (0.1905) | Acc: (93.33%) (8482/9088)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 80 |  Loss: (0.1900) | Acc: (93.33%) (9676/10368)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 90 |  Loss: (0.1896) | Acc: (93.37%) (10876/11648)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 100 |  Loss: (0.1924) | Acc: (93.30%) (12062/12928)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 110 |  Loss: (0.1914) | Acc: (93.26%) (13250/14208)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 120 |  Loss: (0.1934) | Acc: (93.15%) (14427/15488)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 130 |  Loss: (0.1950) | Acc: (93.11%) (15612/16768)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 140 |  Loss: (0.1975) | Acc: (93.05%) (16794/18048)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 150 |  Loss: (0.1985) | Acc: (93.05%) (17984/19328)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 160 |  Loss: (0.1983) | Acc: (93.04%) (19174/20608)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 170 |  Loss: (0.1976) | Acc: (93.10%) (20378/21888)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 180 |  Loss: (0.1999) | Acc: (93.06%) (21560/23168)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 190 |  Loss: (0.1985) | Acc: (93.11%) (22764/24448)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 200 |  Loss: (0.1987) | Acc: (93.11%) (23955/25728)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 210 |  Loss: (0.2007) | Acc: (93.03%) (25125/27008)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 220 |  Loss: (0.2014) | Acc: (92.98%) (26302/28288)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 230 |  Loss: (0.2013) | Acc: (92.96%) (27486/29568)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 240 |  Loss: (0.2019) | Acc: (92.94%) (28669/30848)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 250 |  Loss: (0.2021) | Acc: (92.91%) (29851/32128)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 260 |  Loss: (0.2027) | Acc: (92.89%) (31032/33408)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 270 |  Loss: (0.2015) | Acc: (92.94%) (32238/34688)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 280 |  Loss: (0.2017) | Acc: (92.92%) (33423/35968)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 290 |  Loss: (0.2020) | Acc: (92.91%) (34608/37248)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 300 |  Loss: (0.2018) | Acc: (92.93%) (35803/38528)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 310 |  Loss: (0.2016) | Acc: (92.93%) (36995/39808)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 320 |  Loss: (0.2014) | Acc: (92.93%) (38185/41088)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 330 |  Loss: (0.2020) | Acc: (92.91%) (39363/42368)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 340 |  Loss: (0.2020) | Acc: (92.92%) (40556/43648)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 350 |  Loss: (0.2026) | Acc: (92.88%) (41731/44928)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 360 |  Loss: (0.2028) | Acc: (92.87%) (42912/46208)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 370 |  Loss: (0.2026) | Acc: (92.89%) (44110/47488)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 380 |  Loss: (0.2029) | Acc: (92.87%) (45289/48768)\n",
      "lr: 0.001\n",
      "Epoch: 59 | Batch_idx: 390 |  Loss: (0.2025) | Acc: (92.87%) (46434/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4429) | Acc: (39.24%) (3924/10000)\n",
      "Epoch: 60 | Batch_idx: 0 |  Loss: (0.1252) | Acc: (94.53%) (121/128)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 10 |  Loss: (0.1827) | Acc: (94.39%) (1329/1408)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 20 |  Loss: (0.1947) | Acc: (94.12%) (2530/2688)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 30 |  Loss: (0.1983) | Acc: (93.70%) (3718/3968)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 40 |  Loss: (0.1895) | Acc: (93.86%) (4926/5248)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 50 |  Loss: (0.1900) | Acc: (93.73%) (6119/6528)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 60 |  Loss: (0.1907) | Acc: (93.74%) (7319/7808)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 70 |  Loss: (0.1972) | Acc: (93.54%) (8501/9088)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 80 |  Loss: (0.1952) | Acc: (93.58%) (9702/10368)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 90 |  Loss: (0.1960) | Acc: (93.52%) (10893/11648)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 100 |  Loss: (0.1959) | Acc: (93.51%) (12089/12928)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 110 |  Loss: (0.1958) | Acc: (93.50%) (13284/14208)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 120 |  Loss: (0.1946) | Acc: (93.53%) (14486/15488)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 130 |  Loss: (0.1939) | Acc: (93.54%) (15685/16768)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 140 |  Loss: (0.1948) | Acc: (93.47%) (16870/18048)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 150 |  Loss: (0.1933) | Acc: (93.50%) (18071/19328)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 160 |  Loss: (0.1959) | Acc: (93.37%) (19242/20608)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 170 |  Loss: (0.1975) | Acc: (93.27%) (20416/21888)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 180 |  Loss: (0.1971) | Acc: (93.31%) (21617/23168)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 190 |  Loss: (0.1977) | Acc: (93.29%) (22808/24448)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 200 |  Loss: (0.1982) | Acc: (93.26%) (23994/25728)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 210 |  Loss: (0.1986) | Acc: (93.26%) (25188/27008)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 220 |  Loss: (0.1992) | Acc: (93.24%) (26376/28288)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 230 |  Loss: (0.1990) | Acc: (93.25%) (27571/29568)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 240 |  Loss: (0.1994) | Acc: (93.22%) (28755/30848)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 250 |  Loss: (0.1988) | Acc: (93.25%) (29958/32128)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 260 |  Loss: (0.1986) | Acc: (93.26%) (31156/33408)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 270 |  Loss: (0.1986) | Acc: (93.25%) (32346/34688)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 280 |  Loss: (0.1988) | Acc: (93.24%) (33538/35968)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 290 |  Loss: (0.1989) | Acc: (93.23%) (34728/37248)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 300 |  Loss: (0.1988) | Acc: (93.26%) (35932/38528)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 310 |  Loss: (0.1994) | Acc: (93.22%) (37108/39808)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 320 |  Loss: (0.1988) | Acc: (93.25%) (38314/41088)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 330 |  Loss: (0.1991) | Acc: (93.24%) (39503/42368)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 340 |  Loss: (0.1988) | Acc: (93.26%) (40705/43648)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 350 |  Loss: (0.1979) | Acc: (93.27%) (41905/44928)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 360 |  Loss: (0.1978) | Acc: (93.27%) (43098/46208)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 370 |  Loss: (0.1978) | Acc: (93.26%) (44285/47488)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 380 |  Loss: (0.1984) | Acc: (93.23%) (45468/48768)\n",
      "lr: 0.001\n",
      "Epoch: 60 | Batch_idx: 390 |  Loss: (0.1989) | Acc: (93.22%) (46612/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.6019) | Acc: (39.30%) (3930/10000)\n",
      "Epoch: 61 | Batch_idx: 0 |  Loss: (0.2577) | Acc: (91.41%) (117/128)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 10 |  Loss: (0.2121) | Acc: (92.54%) (1303/1408)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 20 |  Loss: (0.1987) | Acc: (93.23%) (2506/2688)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 30 |  Loss: (0.1935) | Acc: (93.35%) (3704/3968)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 40 |  Loss: (0.1976) | Acc: (93.22%) (4892/5248)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 50 |  Loss: (0.1947) | Acc: (93.37%) (6095/6528)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 60 |  Loss: (0.1946) | Acc: (93.39%) (7292/7808)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 70 |  Loss: (0.1929) | Acc: (93.42%) (8490/9088)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 80 |  Loss: (0.1965) | Acc: (93.26%) (9669/10368)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 90 |  Loss: (0.1962) | Acc: (93.27%) (10864/11648)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 100 |  Loss: (0.1954) | Acc: (93.37%) (12071/12928)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 110 |  Loss: (0.1971) | Acc: (93.31%) (13258/14208)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 120 |  Loss: (0.1965) | Acc: (93.30%) (14451/15488)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 130 |  Loss: (0.1974) | Acc: (93.25%) (15636/16768)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 140 |  Loss: (0.1972) | Acc: (93.23%) (16827/18048)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 150 |  Loss: (0.1966) | Acc: (93.25%) (18024/19328)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 160 |  Loss: (0.1983) | Acc: (93.18%) (19202/20608)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 170 |  Loss: (0.2009) | Acc: (93.13%) (20384/21888)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 180 |  Loss: (0.2023) | Acc: (93.05%) (21558/23168)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 190 |  Loss: (0.2026) | Acc: (93.01%) (22739/24448)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 200 |  Loss: (0.2032) | Acc: (93.01%) (23929/25728)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 210 |  Loss: (0.2021) | Acc: (93.05%) (25132/27008)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 220 |  Loss: (0.2016) | Acc: (93.07%) (26328/28288)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 230 |  Loss: (0.2007) | Acc: (93.12%) (27533/29568)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 240 |  Loss: (0.1996) | Acc: (93.14%) (28733/30848)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 250 |  Loss: (0.1997) | Acc: (93.14%) (29924/32128)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 260 |  Loss: (0.2007) | Acc: (93.11%) (31106/33408)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 270 |  Loss: (0.2001) | Acc: (93.12%) (32301/34688)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 280 |  Loss: (0.1998) | Acc: (93.14%) (33500/35968)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 290 |  Loss: (0.1998) | Acc: (93.14%) (34694/37248)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 300 |  Loss: (0.1995) | Acc: (93.14%) (35884/38528)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 310 |  Loss: (0.1993) | Acc: (93.14%) (37076/39808)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 320 |  Loss: (0.1997) | Acc: (93.15%) (38273/41088)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 330 |  Loss: (0.1997) | Acc: (93.15%) (39467/42368)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 340 |  Loss: (0.1995) | Acc: (93.16%) (40661/43648)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 350 |  Loss: (0.1995) | Acc: (93.14%) (41848/44928)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 360 |  Loss: (0.1997) | Acc: (93.13%) (43034/46208)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 370 |  Loss: (0.1997) | Acc: (93.12%) (44220/47488)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 380 |  Loss: (0.2002) | Acc: (93.09%) (45397/48768)\n",
      "lr: 0.001\n",
      "Epoch: 61 | Batch_idx: 390 |  Loss: (0.2006) | Acc: (93.06%) (46528/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.3087) | Acc: (35.99%) (3599/10000)\n",
      "Epoch: 62 | Batch_idx: 0 |  Loss: (0.1938) | Acc: (92.97%) (119/128)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 10 |  Loss: (0.1915) | Acc: (93.25%) (1313/1408)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 20 |  Loss: (0.1819) | Acc: (93.64%) (2517/2688)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 30 |  Loss: (0.1741) | Acc: (94.03%) (3731/3968)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 40 |  Loss: (0.1690) | Acc: (94.11%) (4939/5248)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 50 |  Loss: (0.1761) | Acc: (93.90%) (6130/6528)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 60 |  Loss: (0.1766) | Acc: (93.92%) (7333/7808)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 70 |  Loss: (0.1820) | Acc: (93.72%) (8517/9088)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 80 |  Loss: (0.1811) | Acc: (93.78%) (9723/10368)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 90 |  Loss: (0.1796) | Acc: (93.75%) (10920/11648)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 100 |  Loss: (0.1779) | Acc: (93.83%) (12130/12928)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 110 |  Loss: (0.1791) | Acc: (93.83%) (13332/14208)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 120 |  Loss: (0.1802) | Acc: (93.74%) (14518/15488)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 130 |  Loss: (0.1799) | Acc: (93.76%) (15722/16768)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 140 |  Loss: (0.1817) | Acc: (93.71%) (16913/18048)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 150 |  Loss: (0.1853) | Acc: (93.60%) (18091/19328)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 160 |  Loss: (0.1848) | Acc: (93.61%) (19292/20608)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 170 |  Loss: (0.1844) | Acc: (93.61%) (20489/21888)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 180 |  Loss: (0.1828) | Acc: (93.66%) (21700/23168)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 190 |  Loss: (0.1823) | Acc: (93.67%) (22900/24448)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 200 |  Loss: (0.1814) | Acc: (93.70%) (24107/25728)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 210 |  Loss: (0.1817) | Acc: (93.71%) (25310/27008)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 220 |  Loss: (0.1823) | Acc: (93.70%) (26505/28288)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 230 |  Loss: (0.1834) | Acc: (93.67%) (27696/29568)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 240 |  Loss: (0.1851) | Acc: (93.61%) (28877/30848)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 250 |  Loss: (0.1850) | Acc: (93.61%) (30074/32128)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 260 |  Loss: (0.1858) | Acc: (93.61%) (31274/33408)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 270 |  Loss: (0.1859) | Acc: (93.59%) (32465/34688)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 280 |  Loss: (0.1872) | Acc: (93.54%) (33643/35968)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 290 |  Loss: (0.1873) | Acc: (93.53%) (34838/37248)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 300 |  Loss: (0.1876) | Acc: (93.51%) (36029/38528)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 310 |  Loss: (0.1881) | Acc: (93.48%) (37213/39808)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 320 |  Loss: (0.1881) | Acc: (93.49%) (38412/41088)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 330 |  Loss: (0.1877) | Acc: (93.50%) (39614/42368)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 340 |  Loss: (0.1877) | Acc: (93.49%) (40808/43648)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 350 |  Loss: (0.1886) | Acc: (93.48%) (41997/44928)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 360 |  Loss: (0.1889) | Acc: (93.46%) (43186/46208)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 370 |  Loss: (0.1902) | Acc: (93.40%) (44354/47488)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 380 |  Loss: (0.1904) | Acc: (93.41%) (45553/48768)\n",
      "lr: 0.001\n",
      "Epoch: 62 | Batch_idx: 390 |  Loss: (0.1901) | Acc: (93.41%) (46705/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.1087) | Acc: (34.17%) (3417/10000)\n",
      "Epoch: 63 | Batch_idx: 0 |  Loss: (0.1459) | Acc: (92.97%) (119/128)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 10 |  Loss: (0.1892) | Acc: (93.32%) (1314/1408)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 20 |  Loss: (0.1790) | Acc: (93.71%) (2519/2688)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 30 |  Loss: (0.1880) | Acc: (93.42%) (3707/3968)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 40 |  Loss: (0.1905) | Acc: (93.29%) (4896/5248)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 50 |  Loss: (0.1902) | Acc: (93.38%) (6096/6528)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 60 |  Loss: (0.1911) | Acc: (93.34%) (7288/7808)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 70 |  Loss: (0.1898) | Acc: (93.41%) (8489/9088)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 80 |  Loss: (0.1885) | Acc: (93.40%) (9684/10368)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 90 |  Loss: (0.1873) | Acc: (93.42%) (10881/11648)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 100 |  Loss: (0.1871) | Acc: (93.44%) (12080/12928)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 110 |  Loss: (0.1858) | Acc: (93.53%) (13289/14208)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 120 |  Loss: (0.1835) | Acc: (93.64%) (14503/15488)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 130 |  Loss: (0.1830) | Acc: (93.67%) (15707/16768)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 140 |  Loss: (0.1852) | Acc: (93.59%) (16891/18048)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 150 |  Loss: (0.1858) | Acc: (93.57%) (18086/19328)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 160 |  Loss: (0.1870) | Acc: (93.54%) (19277/20608)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 170 |  Loss: (0.1868) | Acc: (93.58%) (20482/21888)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 180 |  Loss: (0.1885) | Acc: (93.52%) (21667/23168)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 190 |  Loss: (0.1891) | Acc: (93.52%) (22863/24448)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 200 |  Loss: (0.1899) | Acc: (93.50%) (24056/25728)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 210 |  Loss: (0.1886) | Acc: (93.55%) (25267/27008)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 220 |  Loss: (0.1881) | Acc: (93.56%) (26465/28288)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 230 |  Loss: (0.1890) | Acc: (93.53%) (27655/29568)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 240 |  Loss: (0.1885) | Acc: (93.54%) (28856/30848)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 250 |  Loss: (0.1893) | Acc: (93.53%) (30049/32128)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 260 |  Loss: (0.1902) | Acc: (93.52%) (31243/33408)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 270 |  Loss: (0.1903) | Acc: (93.52%) (32439/34688)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 280 |  Loss: (0.1895) | Acc: (93.54%) (33646/35968)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 290 |  Loss: (0.1909) | Acc: (93.48%) (34820/37248)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 300 |  Loss: (0.1904) | Acc: (93.50%) (36023/38528)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 310 |  Loss: (0.1911) | Acc: (93.46%) (37205/39808)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 320 |  Loss: (0.1914) | Acc: (93.46%) (38401/41088)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 330 |  Loss: (0.1907) | Acc: (93.49%) (39610/42368)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 340 |  Loss: (0.1913) | Acc: (93.47%) (40796/43648)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 350 |  Loss: (0.1900) | Acc: (93.50%) (42009/44928)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 360 |  Loss: (0.1897) | Acc: (93.52%) (43215/46208)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 370 |  Loss: (0.1897) | Acc: (93.51%) (44406/47488)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 380 |  Loss: (0.1904) | Acc: (93.50%) (45599/48768)\n",
      "lr: 0.001\n",
      "Epoch: 63 | Batch_idx: 390 |  Loss: (0.1899) | Acc: (93.50%) (46748/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.9718) | Acc: (45.18%) (4518/10000)\n",
      "Epoch: 64 | Batch_idx: 0 |  Loss: (0.1789) | Acc: (91.41%) (117/128)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 10 |  Loss: (0.1843) | Acc: (93.75%) (1320/1408)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 20 |  Loss: (0.1915) | Acc: (93.56%) (2515/2688)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 30 |  Loss: (0.1821) | Acc: (93.80%) (3722/3968)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 40 |  Loss: (0.1779) | Acc: (93.88%) (4927/5248)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 50 |  Loss: (0.1830) | Acc: (93.75%) (6120/6528)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 60 |  Loss: (0.1841) | Acc: (93.75%) (7320/7808)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 70 |  Loss: (0.1827) | Acc: (93.85%) (8529/9088)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 80 |  Loss: (0.1847) | Acc: (93.73%) (9718/10368)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 90 |  Loss: (0.1867) | Acc: (93.65%) (10908/11648)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 100 |  Loss: (0.1870) | Acc: (93.63%) (12105/12928)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 110 |  Loss: (0.1878) | Acc: (93.55%) (13291/14208)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 120 |  Loss: (0.1913) | Acc: (93.41%) (14467/15488)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 130 |  Loss: (0.1930) | Acc: (93.38%) (15658/16768)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 140 |  Loss: (0.1925) | Acc: (93.38%) (16854/18048)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 150 |  Loss: (0.1908) | Acc: (93.42%) (18057/19328)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 160 |  Loss: (0.1896) | Acc: (93.42%) (19253/20608)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 170 |  Loss: (0.1897) | Acc: (93.42%) (20448/21888)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 180 |  Loss: (0.1899) | Acc: (93.41%) (21641/23168)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 190 |  Loss: (0.1890) | Acc: (93.42%) (22839/24448)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 200 |  Loss: (0.1882) | Acc: (93.46%) (24045/25728)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 210 |  Loss: (0.1884) | Acc: (93.44%) (25237/27008)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 220 |  Loss: (0.1885) | Acc: (93.44%) (26433/28288)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 230 |  Loss: (0.1883) | Acc: (93.45%) (27631/29568)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 240 |  Loss: (0.1880) | Acc: (93.46%) (28830/30848)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 250 |  Loss: (0.1882) | Acc: (93.45%) (30025/32128)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 260 |  Loss: (0.1883) | Acc: (93.45%) (31221/33408)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 270 |  Loss: (0.1890) | Acc: (93.42%) (32405/34688)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 280 |  Loss: (0.1890) | Acc: (93.41%) (33599/35968)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 290 |  Loss: (0.1888) | Acc: (93.43%) (34800/37248)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 300 |  Loss: (0.1886) | Acc: (93.42%) (35994/38528)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 310 |  Loss: (0.1885) | Acc: (93.43%) (37191/39808)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 320 |  Loss: (0.1893) | Acc: (93.41%) (38379/41088)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 330 |  Loss: (0.1899) | Acc: (93.37%) (39557/42368)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 340 |  Loss: (0.1897) | Acc: (93.36%) (40749/43648)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 350 |  Loss: (0.1898) | Acc: (93.34%) (41938/44928)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 360 |  Loss: (0.1894) | Acc: (93.36%) (43139/46208)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 370 |  Loss: (0.1898) | Acc: (93.33%) (44320/47488)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 380 |  Loss: (0.1892) | Acc: (93.37%) (45533/48768)\n",
      "lr: 0.001\n",
      "Epoch: 64 | Batch_idx: 390 |  Loss: (0.1890) | Acc: (93.38%) (46690/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.1935) | Acc: (41.39%) (4139/10000)\n",
      "Epoch: 65 | Batch_idx: 0 |  Loss: (0.2765) | Acc: (90.62%) (116/128)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 10 |  Loss: (0.1859) | Acc: (93.18%) (1312/1408)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 20 |  Loss: (0.1679) | Acc: (93.90%) (2524/2688)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 30 |  Loss: (0.1714) | Acc: (93.85%) (3724/3968)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 40 |  Loss: (0.1695) | Acc: (94.07%) (4937/5248)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 50 |  Loss: (0.1786) | Acc: (93.86%) (6127/6528)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 60 |  Loss: (0.1796) | Acc: (93.81%) (7325/7808)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 70 |  Loss: (0.1793) | Acc: (93.74%) (8519/9088)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 80 |  Loss: (0.1805) | Acc: (93.68%) (9713/10368)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 90 |  Loss: (0.1809) | Acc: (93.66%) (10910/11648)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 100 |  Loss: (0.1805) | Acc: (93.70%) (12114/12928)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 110 |  Loss: (0.1794) | Acc: (93.74%) (13319/14208)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 120 |  Loss: (0.1806) | Acc: (93.69%) (14511/15488)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 130 |  Loss: (0.1792) | Acc: (93.74%) (15718/16768)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 140 |  Loss: (0.1809) | Acc: (93.73%) (16916/18048)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 150 |  Loss: (0.1791) | Acc: (93.79%) (18127/19328)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 160 |  Loss: (0.1803) | Acc: (93.75%) (19321/20608)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 170 |  Loss: (0.1820) | Acc: (93.65%) (20498/21888)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 180 |  Loss: (0.1830) | Acc: (93.60%) (21686/23168)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 190 |  Loss: (0.1843) | Acc: (93.53%) (22866/24448)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 200 |  Loss: (0.1834) | Acc: (93.58%) (24075/25728)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 210 |  Loss: (0.1821) | Acc: (93.64%) (25290/27008)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 220 |  Loss: (0.1822) | Acc: (93.62%) (26483/28288)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 230 |  Loss: (0.1830) | Acc: (93.59%) (27672/29568)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 240 |  Loss: (0.1822) | Acc: (93.62%) (28880/30848)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 250 |  Loss: (0.1831) | Acc: (93.59%) (30068/32128)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 260 |  Loss: (0.1840) | Acc: (93.54%) (31251/33408)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 270 |  Loss: (0.1845) | Acc: (93.53%) (32442/34688)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 280 |  Loss: (0.1841) | Acc: (93.55%) (33647/35968)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 290 |  Loss: (0.1846) | Acc: (93.54%) (34840/37248)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 300 |  Loss: (0.1849) | Acc: (93.54%) (36041/38528)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 310 |  Loss: (0.1847) | Acc: (93.55%) (37242/39808)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 320 |  Loss: (0.1842) | Acc: (93.58%) (38452/41088)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 330 |  Loss: (0.1844) | Acc: (93.57%) (39642/42368)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 340 |  Loss: (0.1850) | Acc: (93.53%) (40826/43648)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 350 |  Loss: (0.1854) | Acc: (93.55%) (42029/44928)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 360 |  Loss: (0.1860) | Acc: (93.52%) (43216/46208)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 370 |  Loss: (0.1857) | Acc: (93.55%) (44424/47488)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 380 |  Loss: (0.1867) | Acc: (93.52%) (45609/48768)\n",
      "lr: 0.001\n",
      "Epoch: 65 | Batch_idx: 390 |  Loss: (0.1870) | Acc: (93.51%) (46753/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.2091) | Acc: (42.16%) (4216/10000)\n",
      "Epoch: 66 | Batch_idx: 0 |  Loss: (0.1678) | Acc: (92.19%) (118/128)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 10 |  Loss: (0.1599) | Acc: (93.89%) (1322/1408)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 20 |  Loss: (0.1780) | Acc: (93.75%) (2520/2688)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 30 |  Loss: (0.1803) | Acc: (93.52%) (3711/3968)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 40 |  Loss: (0.1877) | Acc: (93.37%) (4900/5248)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 50 |  Loss: (0.1883) | Acc: (93.49%) (6103/6528)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 60 |  Loss: (0.1926) | Acc: (93.38%) (7291/7808)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 70 |  Loss: (0.1929) | Acc: (93.35%) (8484/9088)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 80 |  Loss: (0.1922) | Acc: (93.34%) (9677/10368)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 90 |  Loss: (0.1911) | Acc: (93.31%) (10869/11648)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 100 |  Loss: (0.1900) | Acc: (93.32%) (12064/12928)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 110 |  Loss: (0.1896) | Acc: (93.35%) (13263/14208)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 120 |  Loss: (0.1893) | Acc: (93.36%) (14460/15488)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 130 |  Loss: (0.1888) | Acc: (93.43%) (15667/16768)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 140 |  Loss: (0.1895) | Acc: (93.43%) (16862/18048)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 150 |  Loss: (0.1890) | Acc: (93.47%) (18065/19328)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 160 |  Loss: (0.1883) | Acc: (93.52%) (19273/20608)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 170 |  Loss: (0.1873) | Acc: (93.54%) (20474/21888)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 180 |  Loss: (0.1875) | Acc: (93.53%) (21669/23168)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 190 |  Loss: (0.1870) | Acc: (93.55%) (22871/24448)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 200 |  Loss: (0.1861) | Acc: (93.59%) (24080/25728)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 210 |  Loss: (0.1858) | Acc: (93.63%) (25288/27008)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 220 |  Loss: (0.1856) | Acc: (93.62%) (26484/28288)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 230 |  Loss: (0.1858) | Acc: (93.61%) (27679/29568)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 240 |  Loss: (0.1861) | Acc: (93.58%) (28868/30848)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 250 |  Loss: (0.1856) | Acc: (93.59%) (30070/32128)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 260 |  Loss: (0.1865) | Acc: (93.56%) (31255/33408)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 270 |  Loss: (0.1876) | Acc: (93.50%) (32435/34688)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 280 |  Loss: (0.1881) | Acc: (93.46%) (33615/35968)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 290 |  Loss: (0.1879) | Acc: (93.48%) (34821/37248)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 300 |  Loss: (0.1870) | Acc: (93.55%) (36042/38528)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 310 |  Loss: (0.1863) | Acc: (93.57%) (37249/39808)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 320 |  Loss: (0.1872) | Acc: (93.57%) (38445/41088)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 330 |  Loss: (0.1874) | Acc: (93.55%) (39636/42368)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 340 |  Loss: (0.1875) | Acc: (93.54%) (40830/43648)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 350 |  Loss: (0.1874) | Acc: (93.55%) (42032/44928)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 360 |  Loss: (0.1878) | Acc: (93.52%) (43215/46208)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 370 |  Loss: (0.1873) | Acc: (93.54%) (44422/47488)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 380 |  Loss: (0.1870) | Acc: (93.54%) (45618/48768)\n",
      "lr: 0.001\n",
      "Epoch: 66 | Batch_idx: 390 |  Loss: (0.1865) | Acc: (93.56%) (46781/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.1369) | Acc: (41.23%) (4123/10000)\n",
      "Epoch: 67 | Batch_idx: 0 |  Loss: (0.1716) | Acc: (92.97%) (119/128)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 10 |  Loss: (0.1977) | Acc: (93.47%) (1316/1408)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 20 |  Loss: (0.1886) | Acc: (93.42%) (2511/2688)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 30 |  Loss: (0.1897) | Acc: (93.35%) (3704/3968)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 40 |  Loss: (0.1866) | Acc: (93.50%) (4907/5248)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 50 |  Loss: (0.1838) | Acc: (93.43%) (6099/6528)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 60 |  Loss: (0.1853) | Acc: (93.39%) (7292/7808)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 70 |  Loss: (0.1828) | Acc: (93.45%) (8493/9088)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 80 |  Loss: (0.1830) | Acc: (93.46%) (9690/10368)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 90 |  Loss: (0.1904) | Acc: (93.24%) (10861/11648)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 100 |  Loss: (0.1915) | Acc: (93.19%) (12047/12928)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 110 |  Loss: (0.1900) | Acc: (93.27%) (13252/14208)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 120 |  Loss: (0.1885) | Acc: (93.33%) (14455/15488)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 130 |  Loss: (0.1883) | Acc: (93.37%) (15656/16768)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 140 |  Loss: (0.1851) | Acc: (93.50%) (16874/18048)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 150 |  Loss: (0.1861) | Acc: (93.48%) (18067/19328)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 160 |  Loss: (0.1859) | Acc: (93.48%) (19265/20608)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 170 |  Loss: (0.1857) | Acc: (93.48%) (20460/21888)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 180 |  Loss: (0.1862) | Acc: (93.45%) (21651/23168)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 190 |  Loss: (0.1862) | Acc: (93.45%) (22846/24448)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 200 |  Loss: (0.1856) | Acc: (93.44%) (24041/25728)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 210 |  Loss: (0.1861) | Acc: (93.46%) (25242/27008)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 220 |  Loss: (0.1855) | Acc: (93.51%) (26451/28288)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 230 |  Loss: (0.1859) | Acc: (93.49%) (27644/29568)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 240 |  Loss: (0.1863) | Acc: (93.47%) (28834/30848)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 250 |  Loss: (0.1856) | Acc: (93.52%) (30047/32128)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 260 |  Loss: (0.1856) | Acc: (93.54%) (31250/33408)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 270 |  Loss: (0.1870) | Acc: (93.52%) (32439/34688)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 280 |  Loss: (0.1861) | Acc: (93.54%) (33643/35968)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 290 |  Loss: (0.1860) | Acc: (93.55%) (34845/37248)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 300 |  Loss: (0.1854) | Acc: (93.57%) (36050/38528)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 310 |  Loss: (0.1858) | Acc: (93.56%) (37246/39808)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 320 |  Loss: (0.1855) | Acc: (93.55%) (38438/41088)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 330 |  Loss: (0.1862) | Acc: (93.52%) (39622/42368)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 340 |  Loss: (0.1858) | Acc: (93.54%) (40830/43648)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 350 |  Loss: (0.1854) | Acc: (93.57%) (42037/44928)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 360 |  Loss: (0.1862) | Acc: (93.55%) (43227/46208)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 370 |  Loss: (0.1869) | Acc: (93.52%) (44413/47488)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 380 |  Loss: (0.1875) | Acc: (93.52%) (45607/48768)\n",
      "lr: 0.001\n",
      "Epoch: 67 | Batch_idx: 390 |  Loss: (0.1879) | Acc: (93.52%) (46759/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.9525) | Acc: (42.22%) (4222/10000)\n",
      "Epoch: 68 | Batch_idx: 0 |  Loss: (0.2390) | Acc: (91.41%) (117/128)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 10 |  Loss: (0.1973) | Acc: (93.32%) (1314/1408)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 20 |  Loss: (0.1905) | Acc: (93.53%) (2514/2688)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 30 |  Loss: (0.1816) | Acc: (93.67%) (3717/3968)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 40 |  Loss: (0.1808) | Acc: (93.77%) (4921/5248)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 50 |  Loss: (0.1732) | Acc: (94.07%) (6141/6528)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 60 |  Loss: (0.1748) | Acc: (94.04%) (7343/7808)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 70 |  Loss: (0.1769) | Acc: (93.95%) (8538/9088)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 80 |  Loss: (0.1784) | Acc: (93.86%) (9731/10368)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 90 |  Loss: (0.1802) | Acc: (93.84%) (10931/11648)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 100 |  Loss: (0.1797) | Acc: (93.83%) (12130/12928)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 110 |  Loss: (0.1806) | Acc: (93.77%) (13323/14208)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 120 |  Loss: (0.1790) | Acc: (93.81%) (14529/15488)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 130 |  Loss: (0.1782) | Acc: (93.82%) (15732/16768)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 140 |  Loss: (0.1788) | Acc: (93.78%) (16925/18048)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 150 |  Loss: (0.1801) | Acc: (93.72%) (18114/19328)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 160 |  Loss: (0.1792) | Acc: (93.71%) (19312/20608)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 170 |  Loss: (0.1795) | Acc: (93.67%) (20503/21888)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 180 |  Loss: (0.1792) | Acc: (93.69%) (21705/23168)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 190 |  Loss: (0.1798) | Acc: (93.69%) (22905/24448)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 200 |  Loss: (0.1787) | Acc: (93.74%) (24118/25728)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 210 |  Loss: (0.1775) | Acc: (93.80%) (25333/27008)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 220 |  Loss: (0.1778) | Acc: (93.78%) (26529/28288)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 230 |  Loss: (0.1793) | Acc: (93.74%) (27717/29568)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 240 |  Loss: (0.1795) | Acc: (93.73%) (28913/30848)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 250 |  Loss: (0.1801) | Acc: (93.69%) (30100/32128)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 260 |  Loss: (0.1805) | Acc: (93.68%) (31295/33408)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 270 |  Loss: (0.1801) | Acc: (93.67%) (32493/34688)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 280 |  Loss: (0.1801) | Acc: (93.67%) (33693/35968)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 290 |  Loss: (0.1800) | Acc: (93.68%) (34893/37248)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 300 |  Loss: (0.1807) | Acc: (93.65%) (36082/38528)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 310 |  Loss: (0.1802) | Acc: (93.67%) (37288/39808)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 320 |  Loss: (0.1797) | Acc: (93.68%) (38491/41088)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 330 |  Loss: (0.1793) | Acc: (93.67%) (39687/42368)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 340 |  Loss: (0.1796) | Acc: (93.64%) (40873/43648)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 350 |  Loss: (0.1795) | Acc: (93.65%) (42077/44928)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 360 |  Loss: (0.1800) | Acc: (93.64%) (43270/46208)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 370 |  Loss: (0.1804) | Acc: (93.62%) (44460/47488)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 380 |  Loss: (0.1802) | Acc: (93.64%) (45666/48768)\n",
      "lr: 0.001\n",
      "Epoch: 68 | Batch_idx: 390 |  Loss: (0.1801) | Acc: (93.66%) (46828/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.1955) | Acc: (37.62%) (3762/10000)\n",
      "Epoch: 69 | Batch_idx: 0 |  Loss: (0.1742) | Acc: (93.75%) (120/128)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 10 |  Loss: (0.1766) | Acc: (94.74%) (1334/1408)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 20 |  Loss: (0.1704) | Acc: (94.35%) (2536/2688)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 30 |  Loss: (0.1725) | Acc: (94.23%) (3739/3968)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 40 |  Loss: (0.1827) | Acc: (93.64%) (4914/5248)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 50 |  Loss: (0.1795) | Acc: (93.81%) (6124/6528)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 60 |  Loss: (0.1780) | Acc: (93.93%) (7334/7808)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 70 |  Loss: (0.1794) | Acc: (93.86%) (8530/9088)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 80 |  Loss: (0.1784) | Acc: (93.83%) (9728/10368)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 90 |  Loss: (0.1791) | Acc: (93.82%) (10928/11648)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 100 |  Loss: (0.1841) | Acc: (93.70%) (12113/12928)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 110 |  Loss: (0.1848) | Acc: (93.66%) (13307/14208)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 120 |  Loss: (0.1844) | Acc: (93.66%) (14506/15488)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 130 |  Loss: (0.1859) | Acc: (93.67%) (15707/16768)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 140 |  Loss: (0.1848) | Acc: (93.67%) (16906/18048)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 150 |  Loss: (0.1847) | Acc: (93.69%) (18109/19328)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 160 |  Loss: (0.1833) | Acc: (93.76%) (19322/20608)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 170 |  Loss: (0.1819) | Acc: (93.79%) (20529/21888)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 180 |  Loss: (0.1811) | Acc: (93.85%) (21743/23168)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 190 |  Loss: (0.1812) | Acc: (93.83%) (22940/24448)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 200 |  Loss: (0.1800) | Acc: (93.89%) (24157/25728)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 210 |  Loss: (0.1798) | Acc: (93.90%) (25361/27008)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 220 |  Loss: (0.1817) | Acc: (93.82%) (26540/28288)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 230 |  Loss: (0.1807) | Acc: (93.84%) (27748/29568)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 240 |  Loss: (0.1804) | Acc: (93.87%) (28957/30848)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 250 |  Loss: (0.1802) | Acc: (93.86%) (30154/32128)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 260 |  Loss: (0.1803) | Acc: (93.84%) (31350/33408)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 270 |  Loss: (0.1808) | Acc: (93.80%) (32539/34688)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 280 |  Loss: (0.1802) | Acc: (93.82%) (33745/35968)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 290 |  Loss: (0.1794) | Acc: (93.83%) (34949/37248)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 300 |  Loss: (0.1793) | Acc: (93.83%) (36152/38528)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 310 |  Loss: (0.1795) | Acc: (93.82%) (37347/39808)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 320 |  Loss: (0.1802) | Acc: (93.79%) (38538/41088)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 330 |  Loss: (0.1801) | Acc: (93.79%) (39735/42368)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 340 |  Loss: (0.1792) | Acc: (93.82%) (40952/43648)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 350 |  Loss: (0.1799) | Acc: (93.77%) (42131/44928)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 360 |  Loss: (0.1807) | Acc: (93.74%) (43314/46208)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 370 |  Loss: (0.1807) | Acc: (93.74%) (44516/47488)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 380 |  Loss: (0.1808) | Acc: (93.73%) (45710/48768)\n",
      "lr: 0.001\n",
      "Epoch: 69 | Batch_idx: 390 |  Loss: (0.1808) | Acc: (93.73%) (46864/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.0102) | Acc: (44.83%) (4483/10000)\n",
      "Epoch: 70 | Batch_idx: 0 |  Loss: (0.1722) | Acc: (92.97%) (119/128)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 10 |  Loss: (0.1530) | Acc: (94.60%) (1332/1408)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 20 |  Loss: (0.1623) | Acc: (94.27%) (2534/2688)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 30 |  Loss: (0.1571) | Acc: (94.15%) (3736/3968)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 40 |  Loss: (0.1611) | Acc: (94.11%) (4939/5248)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 50 |  Loss: (0.1628) | Acc: (94.10%) (6143/6528)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 60 |  Loss: (0.1647) | Acc: (94.04%) (7343/7808)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 70 |  Loss: (0.1680) | Acc: (93.95%) (8538/9088)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 80 |  Loss: (0.1703) | Acc: (93.93%) (9739/10368)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 90 |  Loss: (0.1705) | Acc: (93.93%) (10941/11648)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 100 |  Loss: (0.1721) | Acc: (93.94%) (12144/12928)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 110 |  Loss: (0.1749) | Acc: (93.94%) (13347/14208)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 120 |  Loss: (0.1720) | Acc: (94.03%) (14564/15488)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 130 |  Loss: (0.1714) | Acc: (94.03%) (15767/16768)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 140 |  Loss: (0.1719) | Acc: (94.02%) (16968/18048)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 150 |  Loss: (0.1712) | Acc: (94.02%) (18173/19328)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 160 |  Loss: (0.1719) | Acc: (94.03%) (19378/20608)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 170 |  Loss: (0.1716) | Acc: (94.01%) (20576/21888)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 180 |  Loss: (0.1710) | Acc: (94.02%) (21783/23168)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 190 |  Loss: (0.1712) | Acc: (94.04%) (22991/24448)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 200 |  Loss: (0.1714) | Acc: (94.02%) (24190/25728)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 210 |  Loss: (0.1714) | Acc: (94.02%) (25394/27008)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 220 |  Loss: (0.1710) | Acc: (94.05%) (26606/28288)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 230 |  Loss: (0.1707) | Acc: (94.04%) (27805/29568)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 240 |  Loss: (0.1709) | Acc: (94.02%) (29004/30848)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 250 |  Loss: (0.1722) | Acc: (93.98%) (30195/32128)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 260 |  Loss: (0.1729) | Acc: (93.98%) (31396/33408)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 270 |  Loss: (0.1725) | Acc: (93.98%) (32600/34688)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 280 |  Loss: (0.1737) | Acc: (93.94%) (33788/35968)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 290 |  Loss: (0.1748) | Acc: (93.90%) (34977/37248)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 300 |  Loss: (0.1745) | Acc: (93.90%) (36178/38528)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 310 |  Loss: (0.1738) | Acc: (93.92%) (37389/39808)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 320 |  Loss: (0.1741) | Acc: (93.92%) (38589/41088)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 330 |  Loss: (0.1743) | Acc: (93.90%) (39784/42368)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 340 |  Loss: (0.1748) | Acc: (93.90%) (40984/43648)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 350 |  Loss: (0.1745) | Acc: (93.90%) (42189/44928)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 360 |  Loss: (0.1743) | Acc: (93.92%) (43398/46208)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 370 |  Loss: (0.1748) | Acc: (93.91%) (44594/47488)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 380 |  Loss: (0.1758) | Acc: (93.86%) (45774/48768)\n",
      "lr: 0.001\n",
      "Epoch: 70 | Batch_idx: 390 |  Loss: (0.1751) | Acc: (93.88%) (46939/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3661) | Acc: (42.55%) (4255/10000)\n",
      "Epoch: 71 | Batch_idx: 0 |  Loss: (0.1495) | Acc: (94.53%) (121/128)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 10 |  Loss: (0.1776) | Acc: (93.89%) (1322/1408)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 20 |  Loss: (0.1842) | Acc: (93.45%) (2512/2688)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 30 |  Loss: (0.1796) | Acc: (93.78%) (3721/3968)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 40 |  Loss: (0.1779) | Acc: (93.83%) (4924/5248)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 50 |  Loss: (0.1774) | Acc: (93.75%) (6120/6528)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 60 |  Loss: (0.1741) | Acc: (93.85%) (7328/7808)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 70 |  Loss: (0.1750) | Acc: (93.88%) (8532/9088)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 80 |  Loss: (0.1723) | Acc: (94.06%) (9752/10368)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 90 |  Loss: (0.1718) | Acc: (94.10%) (10961/11648)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 100 |  Loss: (0.1718) | Acc: (94.02%) (12155/12928)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 110 |  Loss: (0.1701) | Acc: (94.09%) (13369/14208)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 120 |  Loss: (0.1710) | Acc: (94.05%) (14567/15488)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 130 |  Loss: (0.1709) | Acc: (94.06%) (15772/16768)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 140 |  Loss: (0.1702) | Acc: (94.09%) (16981/18048)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 150 |  Loss: (0.1711) | Acc: (94.04%) (18176/19328)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 160 |  Loss: (0.1707) | Acc: (94.08%) (19388/20608)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 170 |  Loss: (0.1705) | Acc: (94.07%) (20591/21888)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 180 |  Loss: (0.1721) | Acc: (94.01%) (21781/23168)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 190 |  Loss: (0.1726) | Acc: (93.98%) (22976/24448)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 200 |  Loss: (0.1726) | Acc: (93.98%) (24179/25728)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 210 |  Loss: (0.1730) | Acc: (93.96%) (25376/27008)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 220 |  Loss: (0.1735) | Acc: (93.95%) (26576/28288)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 230 |  Loss: (0.1743) | Acc: (93.91%) (27768/29568)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 240 |  Loss: (0.1746) | Acc: (93.91%) (28970/30848)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 250 |  Loss: (0.1752) | Acc: (93.90%) (30169/32128)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 260 |  Loss: (0.1746) | Acc: (93.93%) (31380/33408)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 270 |  Loss: (0.1746) | Acc: (93.94%) (32585/34688)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 280 |  Loss: (0.1763) | Acc: (93.89%) (33771/35968)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 290 |  Loss: (0.1757) | Acc: (93.92%) (34985/37248)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 300 |  Loss: (0.1756) | Acc: (93.93%) (36190/38528)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 310 |  Loss: (0.1760) | Acc: (93.90%) (37380/39808)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 320 |  Loss: (0.1761) | Acc: (93.89%) (38577/41088)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 330 |  Loss: (0.1755) | Acc: (93.91%) (39786/42368)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 340 |  Loss: (0.1755) | Acc: (93.91%) (40991/43648)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 350 |  Loss: (0.1751) | Acc: (93.91%) (42194/44928)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 360 |  Loss: (0.1757) | Acc: (93.88%) (43379/46208)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 370 |  Loss: (0.1762) | Acc: (93.85%) (44569/47488)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 380 |  Loss: (0.1759) | Acc: (93.86%) (45775/48768)\n",
      "lr: 0.001\n",
      "Epoch: 71 | Batch_idx: 390 |  Loss: (0.1757) | Acc: (93.89%) (46945/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (3.5340) | Acc: (36.55%) (3655/10000)\n",
      "Epoch: 72 | Batch_idx: 0 |  Loss: (0.2610) | Acc: (89.06%) (114/128)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 10 |  Loss: (0.1686) | Acc: (94.25%) (1327/1408)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 20 |  Loss: (0.1710) | Acc: (94.01%) (2527/2688)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 30 |  Loss: (0.1638) | Acc: (94.41%) (3746/3968)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 40 |  Loss: (0.1718) | Acc: (94.07%) (4937/5248)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 50 |  Loss: (0.1707) | Acc: (94.10%) (6143/6528)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 60 |  Loss: (0.1716) | Acc: (94.04%) (7343/7808)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 70 |  Loss: (0.1774) | Acc: (93.75%) (8520/9088)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 80 |  Loss: (0.1795) | Acc: (93.67%) (9712/10368)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 90 |  Loss: (0.1802) | Acc: (93.73%) (10918/11648)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 100 |  Loss: (0.1783) | Acc: (93.78%) (12124/12928)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 110 |  Loss: (0.1797) | Acc: (93.79%) (13326/14208)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 120 |  Loss: (0.1789) | Acc: (93.80%) (14528/15488)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 130 |  Loss: (0.1816) | Acc: (93.66%) (15705/16768)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 140 |  Loss: (0.1805) | Acc: (93.68%) (16907/18048)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 150 |  Loss: (0.1812) | Acc: (93.65%) (18100/19328)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 160 |  Loss: (0.1809) | Acc: (93.70%) (19310/20608)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 170 |  Loss: (0.1802) | Acc: (93.75%) (20519/21888)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 180 |  Loss: (0.1794) | Acc: (93.78%) (21728/23168)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 190 |  Loss: (0.1798) | Acc: (93.77%) (22926/24448)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 200 |  Loss: (0.1795) | Acc: (93.76%) (24123/25728)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 210 |  Loss: (0.1807) | Acc: (93.74%) (25316/27008)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 220 |  Loss: (0.1800) | Acc: (93.77%) (26527/28288)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 230 |  Loss: (0.1803) | Acc: (93.77%) (27725/29568)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 240 |  Loss: (0.1797) | Acc: (93.80%) (28935/30848)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 250 |  Loss: (0.1803) | Acc: (93.74%) (30118/32128)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 260 |  Loss: (0.1797) | Acc: (93.78%) (31329/33408)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 270 |  Loss: (0.1813) | Acc: (93.73%) (32513/34688)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 280 |  Loss: (0.1807) | Acc: (93.73%) (33713/35968)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 290 |  Loss: (0.1807) | Acc: (93.74%) (34915/37248)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 300 |  Loss: (0.1811) | Acc: (93.70%) (36099/38528)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 310 |  Loss: (0.1808) | Acc: (93.72%) (37307/39808)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 320 |  Loss: (0.1812) | Acc: (93.72%) (38507/41088)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 330 |  Loss: (0.1808) | Acc: (93.75%) (39722/42368)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 340 |  Loss: (0.1813) | Acc: (93.73%) (40911/43648)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 350 |  Loss: (0.1816) | Acc: (93.72%) (42108/44928)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 360 |  Loss: (0.1817) | Acc: (93.73%) (43311/46208)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 370 |  Loss: (0.1817) | Acc: (93.74%) (44513/47488)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 380 |  Loss: (0.1822) | Acc: (93.70%) (45695/48768)\n",
      "lr: 0.001\n",
      "Epoch: 72 | Batch_idx: 390 |  Loss: (0.1813) | Acc: (93.72%) (46860/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3083) | Acc: (38.20%) (3820/10000)\n",
      "Epoch: 73 | Batch_idx: 0 |  Loss: (0.1498) | Acc: (92.97%) (119/128)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 10 |  Loss: (0.1628) | Acc: (93.89%) (1322/1408)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 20 |  Loss: (0.1706) | Acc: (93.68%) (2518/2688)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 30 |  Loss: (0.1750) | Acc: (93.70%) (3718/3968)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 40 |  Loss: (0.1753) | Acc: (93.81%) (4923/5248)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 50 |  Loss: (0.1733) | Acc: (93.87%) (6128/6528)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 60 |  Loss: (0.1711) | Acc: (93.95%) (7336/7808)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 70 |  Loss: (0.1720) | Acc: (94.00%) (8543/9088)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 80 |  Loss: (0.1720) | Acc: (93.99%) (9745/10368)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 90 |  Loss: (0.1717) | Acc: (94.01%) (10950/11648)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 100 |  Loss: (0.1754) | Acc: (93.85%) (12133/12928)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 110 |  Loss: (0.1753) | Acc: (93.90%) (13342/14208)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 120 |  Loss: (0.1754) | Acc: (93.85%) (14535/15488)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 130 |  Loss: (0.1756) | Acc: (93.85%) (15737/16768)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 140 |  Loss: (0.1740) | Acc: (93.85%) (16938/18048)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 150 |  Loss: (0.1747) | Acc: (93.81%) (18132/19328)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 160 |  Loss: (0.1738) | Acc: (93.87%) (19344/20608)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 170 |  Loss: (0.1731) | Acc: (93.91%) (20554/21888)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 180 |  Loss: (0.1742) | Acc: (93.86%) (21745/23168)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 190 |  Loss: (0.1739) | Acc: (93.86%) (22948/24448)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 200 |  Loss: (0.1757) | Acc: (93.80%) (24133/25728)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 210 |  Loss: (0.1764) | Acc: (93.77%) (25326/27008)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 220 |  Loss: (0.1760) | Acc: (93.81%) (26536/28288)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 230 |  Loss: (0.1760) | Acc: (93.80%) (27736/29568)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 240 |  Loss: (0.1768) | Acc: (93.76%) (28923/30848)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 250 |  Loss: (0.1762) | Acc: (93.77%) (30128/32128)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 260 |  Loss: (0.1754) | Acc: (93.81%) (31339/33408)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 270 |  Loss: (0.1743) | Acc: (93.85%) (32553/34688)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 280 |  Loss: (0.1747) | Acc: (93.84%) (33754/35968)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 290 |  Loss: (0.1752) | Acc: (93.83%) (34948/37248)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 300 |  Loss: (0.1753) | Acc: (93.81%) (36143/38528)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 310 |  Loss: (0.1756) | Acc: (93.81%) (37344/39808)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 320 |  Loss: (0.1762) | Acc: (93.80%) (38539/41088)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 330 |  Loss: (0.1759) | Acc: (93.81%) (39744/42368)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 340 |  Loss: (0.1756) | Acc: (93.80%) (40944/43648)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 350 |  Loss: (0.1760) | Acc: (93.79%) (42137/44928)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 360 |  Loss: (0.1760) | Acc: (93.79%) (43337/46208)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 370 |  Loss: (0.1766) | Acc: (93.76%) (44527/47488)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 380 |  Loss: (0.1765) | Acc: (93.77%) (45729/48768)\n",
      "lr: 0.001\n",
      "Epoch: 73 | Batch_idx: 390 |  Loss: (0.1757) | Acc: (93.79%) (46893/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.2775) | Acc: (38.81%) (3881/10000)\n",
      "Epoch: 74 | Batch_idx: 0 |  Loss: (0.1850) | Acc: (93.75%) (120/128)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 10 |  Loss: (0.1873) | Acc: (93.96%) (1323/1408)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 20 |  Loss: (0.1934) | Acc: (93.49%) (2513/2688)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 30 |  Loss: (0.1927) | Acc: (93.25%) (3700/3968)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 40 |  Loss: (0.1815) | Acc: (93.73%) (4919/5248)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 50 |  Loss: (0.1820) | Acc: (93.69%) (6116/6528)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 60 |  Loss: (0.1797) | Acc: (93.79%) (7323/7808)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 70 |  Loss: (0.1765) | Acc: (93.90%) (8534/9088)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 80 |  Loss: (0.1733) | Acc: (94.00%) (9746/10368)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 90 |  Loss: (0.1720) | Acc: (94.02%) (10952/11648)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 100 |  Loss: (0.1685) | Acc: (94.14%) (12170/12928)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 110 |  Loss: (0.1674) | Acc: (94.17%) (13379/14208)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 120 |  Loss: (0.1676) | Acc: (94.15%) (14582/15488)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 130 |  Loss: (0.1678) | Acc: (94.13%) (15784/16768)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 140 |  Loss: (0.1674) | Acc: (94.10%) (16983/18048)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 150 |  Loss: (0.1675) | Acc: (94.10%) (18188/19328)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 160 |  Loss: (0.1683) | Acc: (94.08%) (19389/20608)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 170 |  Loss: (0.1689) | Acc: (94.06%) (20588/21888)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 180 |  Loss: (0.1701) | Acc: (94.02%) (21782/23168)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 190 |  Loss: (0.1698) | Acc: (94.02%) (22987/24448)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 200 |  Loss: (0.1697) | Acc: (94.04%) (24194/25728)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 210 |  Loss: (0.1698) | Acc: (94.02%) (25394/27008)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 220 |  Loss: (0.1708) | Acc: (94.02%) (26595/28288)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 230 |  Loss: (0.1704) | Acc: (94.02%) (27801/29568)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 240 |  Loss: (0.1692) | Acc: (94.07%) (29019/30848)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 250 |  Loss: (0.1685) | Acc: (94.12%) (30238/32128)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 260 |  Loss: (0.1694) | Acc: (94.11%) (31439/33408)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 270 |  Loss: (0.1699) | Acc: (94.08%) (32634/34688)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 280 |  Loss: (0.1687) | Acc: (94.11%) (33851/35968)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 290 |  Loss: (0.1680) | Acc: (94.12%) (35058/37248)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 300 |  Loss: (0.1685) | Acc: (94.11%) (36257/38528)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 310 |  Loss: (0.1692) | Acc: (94.07%) (37448/39808)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 320 |  Loss: (0.1685) | Acc: (94.10%) (38664/41088)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 330 |  Loss: (0.1686) | Acc: (94.09%) (39865/42368)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 340 |  Loss: (0.1679) | Acc: (94.11%) (41076/43648)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 350 |  Loss: (0.1683) | Acc: (94.10%) (42279/44928)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 360 |  Loss: (0.1686) | Acc: (94.11%) (43486/46208)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 370 |  Loss: (0.1689) | Acc: (94.11%) (44690/47488)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 380 |  Loss: (0.1692) | Acc: (94.08%) (45881/48768)\n",
      "lr: 0.001\n",
      "Epoch: 74 | Batch_idx: 390 |  Loss: (0.1683) | Acc: (94.12%) (47059/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.2377) | Acc: (38.93%) (3893/10000)\n",
      "Epoch: 75 | Batch_idx: 0 |  Loss: (0.1590) | Acc: (92.97%) (119/128)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 10 |  Loss: (0.2053) | Acc: (92.90%) (1308/1408)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 20 |  Loss: (0.1925) | Acc: (93.60%) (2516/2688)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 30 |  Loss: (0.1841) | Acc: (93.80%) (3722/3968)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 40 |  Loss: (0.1793) | Acc: (93.79%) (4922/5248)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 50 |  Loss: (0.1807) | Acc: (93.58%) (6109/6528)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 60 |  Loss: (0.1798) | Acc: (93.66%) (7313/7808)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 70 |  Loss: (0.1770) | Acc: (93.77%) (8522/9088)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 80 |  Loss: (0.1744) | Acc: (93.90%) (9736/10368)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 90 |  Loss: (0.1746) | Acc: (93.87%) (10934/11648)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 100 |  Loss: (0.1756) | Acc: (93.80%) (12126/12928)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 110 |  Loss: (0.1754) | Acc: (93.86%) (13335/14208)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 120 |  Loss: (0.1745) | Acc: (93.83%) (14533/15488)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 130 |  Loss: (0.1738) | Acc: (93.77%) (15723/16768)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 140 |  Loss: (0.1723) | Acc: (93.83%) (16934/18048)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 150 |  Loss: (0.1729) | Acc: (93.85%) (18140/19328)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 160 |  Loss: (0.1733) | Acc: (93.88%) (19346/20608)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 170 |  Loss: (0.1728) | Acc: (93.90%) (20553/21888)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 180 |  Loss: (0.1722) | Acc: (93.93%) (21761/23168)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 190 |  Loss: (0.1713) | Acc: (93.97%) (22974/24448)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 200 |  Loss: (0.1716) | Acc: (93.95%) (24171/25728)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 210 |  Loss: (0.1722) | Acc: (93.95%) (25373/27008)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 220 |  Loss: (0.1726) | Acc: (93.93%) (26570/28288)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 230 |  Loss: (0.1732) | Acc: (93.93%) (27773/29568)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 240 |  Loss: (0.1725) | Acc: (93.96%) (28985/30848)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 250 |  Loss: (0.1726) | Acc: (93.95%) (30184/32128)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 260 |  Loss: (0.1731) | Acc: (93.92%) (31377/33408)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 270 |  Loss: (0.1724) | Acc: (93.97%) (32596/34688)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 280 |  Loss: (0.1733) | Acc: (93.94%) (33788/35968)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 290 |  Loss: (0.1730) | Acc: (93.95%) (34993/37248)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 300 |  Loss: (0.1727) | Acc: (93.94%) (36194/38528)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 310 |  Loss: (0.1719) | Acc: (93.97%) (37408/39808)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 320 |  Loss: (0.1715) | Acc: (93.99%) (38618/41088)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 330 |  Loss: (0.1715) | Acc: (93.98%) (39816/42368)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 340 |  Loss: (0.1719) | Acc: (93.96%) (41012/43648)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 350 |  Loss: (0.1721) | Acc: (93.95%) (42209/44928)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 360 |  Loss: (0.1723) | Acc: (93.94%) (43409/46208)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 370 |  Loss: (0.1722) | Acc: (93.94%) (44612/47488)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 380 |  Loss: (0.1719) | Acc: (93.97%) (45825/48768)\n",
      "lr: 0.001\n",
      "Epoch: 75 | Batch_idx: 390 |  Loss: (0.1708) | Acc: (93.99%) (46997/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.1737) | Acc: (40.56%) (4056/10000)\n",
      "Epoch: 76 | Batch_idx: 0 |  Loss: (0.1668) | Acc: (92.97%) (119/128)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 10 |  Loss: (0.1636) | Acc: (93.89%) (1322/1408)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 20 |  Loss: (0.1777) | Acc: (93.15%) (2504/2688)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 30 |  Loss: (0.1652) | Acc: (93.72%) (3719/3968)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 40 |  Loss: (0.1721) | Acc: (93.71%) (4918/5248)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 50 |  Loss: (0.1697) | Acc: (93.77%) (6121/6528)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 60 |  Loss: (0.1713) | Acc: (93.80%) (7324/7808)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 70 |  Loss: (0.1686) | Acc: (93.89%) (8533/9088)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 80 |  Loss: (0.1708) | Acc: (93.86%) (9731/10368)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 90 |  Loss: (0.1702) | Acc: (93.87%) (10934/11648)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 100 |  Loss: (0.1667) | Acc: (93.97%) (12148/12928)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 110 |  Loss: (0.1689) | Acc: (93.85%) (13334/14208)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 120 |  Loss: (0.1685) | Acc: (93.83%) (14533/15488)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 130 |  Loss: (0.1649) | Acc: (93.96%) (15756/16768)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 140 |  Loss: (0.1663) | Acc: (93.90%) (16947/18048)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 150 |  Loss: (0.1676) | Acc: (93.88%) (18145/19328)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 160 |  Loss: (0.1669) | Acc: (93.90%) (19350/20608)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 170 |  Loss: (0.1677) | Acc: (93.86%) (20545/21888)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 180 |  Loss: (0.1693) | Acc: (93.86%) (21745/23168)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 190 |  Loss: (0.1689) | Acc: (93.84%) (22941/24448)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 200 |  Loss: (0.1676) | Acc: (93.86%) (24149/25728)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 210 |  Loss: (0.1665) | Acc: (93.88%) (25355/27008)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 220 |  Loss: (0.1682) | Acc: (93.86%) (26551/28288)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 230 |  Loss: (0.1670) | Acc: (93.90%) (27764/29568)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 240 |  Loss: (0.1673) | Acc: (93.90%) (28967/30848)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 250 |  Loss: (0.1679) | Acc: (93.89%) (30165/32128)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 260 |  Loss: (0.1690) | Acc: (93.89%) (31366/33408)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 270 |  Loss: (0.1694) | Acc: (93.86%) (32559/34688)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 280 |  Loss: (0.1693) | Acc: (93.88%) (33765/35968)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 290 |  Loss: (0.1688) | Acc: (93.91%) (34981/37248)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 300 |  Loss: (0.1684) | Acc: (93.94%) (36192/38528)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 310 |  Loss: (0.1689) | Acc: (93.90%) (37378/39808)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 320 |  Loss: (0.1695) | Acc: (93.89%) (38579/41088)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 330 |  Loss: (0.1697) | Acc: (93.89%) (39779/42368)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 340 |  Loss: (0.1700) | Acc: (93.89%) (40979/43648)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 350 |  Loss: (0.1696) | Acc: (93.91%) (42191/44928)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 360 |  Loss: (0.1689) | Acc: (93.93%) (43404/46208)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 370 |  Loss: (0.1692) | Acc: (93.93%) (44607/47488)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 380 |  Loss: (0.1696) | Acc: (93.93%) (45808/48768)\n",
      "lr: 0.001\n",
      "Epoch: 76 | Batch_idx: 390 |  Loss: (0.1698) | Acc: (93.92%) (46961/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.0831) | Acc: (39.53%) (3953/10000)\n",
      "Epoch: 77 | Batch_idx: 0 |  Loss: (0.1239) | Acc: (96.88%) (124/128)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 10 |  Loss: (0.1443) | Acc: (95.10%) (1339/1408)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 20 |  Loss: (0.1451) | Acc: (95.01%) (2554/2688)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 30 |  Loss: (0.1393) | Acc: (95.26%) (3780/3968)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 40 |  Loss: (0.1410) | Acc: (95.20%) (4996/5248)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 50 |  Loss: (0.1391) | Acc: (95.21%) (6215/6528)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 60 |  Loss: (0.1448) | Acc: (95.11%) (7426/7808)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 70 |  Loss: (0.1477) | Acc: (95.03%) (8636/9088)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 80 |  Loss: (0.1526) | Acc: (94.89%) (9838/10368)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 90 |  Loss: (0.1552) | Acc: (94.78%) (11040/11648)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 100 |  Loss: (0.1543) | Acc: (94.77%) (12252/12928)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 110 |  Loss: (0.1566) | Acc: (94.62%) (13443/14208)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 120 |  Loss: (0.1592) | Acc: (94.54%) (14642/15488)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 130 |  Loss: (0.1607) | Acc: (94.45%) (15837/16768)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 140 |  Loss: (0.1624) | Acc: (94.37%) (17031/18048)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 150 |  Loss: (0.1637) | Acc: (94.32%) (18231/19328)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 160 |  Loss: (0.1625) | Acc: (94.36%) (19446/20608)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 170 |  Loss: (0.1625) | Acc: (94.35%) (20651/21888)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 180 |  Loss: (0.1621) | Acc: (94.38%) (21866/23168)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 190 |  Loss: (0.1620) | Acc: (94.42%) (23083/24448)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 200 |  Loss: (0.1637) | Acc: (94.38%) (24281/25728)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 210 |  Loss: (0.1644) | Acc: (94.32%) (25473/27008)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 220 |  Loss: (0.1652) | Acc: (94.29%) (26672/28288)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 230 |  Loss: (0.1645) | Acc: (94.32%) (27889/29568)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 240 |  Loss: (0.1642) | Acc: (94.32%) (29096/30848)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 250 |  Loss: (0.1658) | Acc: (94.30%) (30296/32128)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 260 |  Loss: (0.1654) | Acc: (94.31%) (31507/33408)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 270 |  Loss: (0.1653) | Acc: (94.29%) (32709/34688)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 280 |  Loss: (0.1661) | Acc: (94.28%) (33911/35968)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 290 |  Loss: (0.1668) | Acc: (94.25%) (35108/37248)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 300 |  Loss: (0.1671) | Acc: (94.24%) (36309/38528)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 310 |  Loss: (0.1678) | Acc: (94.20%) (37500/39808)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 320 |  Loss: (0.1673) | Acc: (94.24%) (38720/41088)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 330 |  Loss: (0.1673) | Acc: (94.24%) (39927/42368)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 340 |  Loss: (0.1675) | Acc: (94.24%) (41133/43648)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 350 |  Loss: (0.1669) | Acc: (94.25%) (42344/44928)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 360 |  Loss: (0.1667) | Acc: (94.26%) (43557/46208)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 370 |  Loss: (0.1665) | Acc: (94.26%) (44761/47488)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 380 |  Loss: (0.1663) | Acc: (94.26%) (45971/48768)\n",
      "lr: 0.001\n",
      "Epoch: 77 | Batch_idx: 390 |  Loss: (0.1657) | Acc: (94.29%) (47143/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.1724) | Acc: (36.70%) (3670/10000)\n",
      "Epoch: 78 | Batch_idx: 0 |  Loss: (0.1478) | Acc: (95.31%) (122/128)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 10 |  Loss: (0.1755) | Acc: (93.25%) (1313/1408)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 20 |  Loss: (0.1672) | Acc: (93.68%) (2518/2688)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 30 |  Loss: (0.1643) | Acc: (93.95%) (3728/3968)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 40 |  Loss: (0.1678) | Acc: (93.88%) (4927/5248)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 50 |  Loss: (0.1706) | Acc: (93.81%) (6124/6528)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 60 |  Loss: (0.1669) | Acc: (94.07%) (7345/7808)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 70 |  Loss: (0.1683) | Acc: (93.99%) (8542/9088)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 80 |  Loss: (0.1652) | Acc: (94.12%) (9758/10368)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 90 |  Loss: (0.1664) | Acc: (94.06%) (10956/11648)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 100 |  Loss: (0.1646) | Acc: (94.07%) (12162/12928)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 110 |  Loss: (0.1646) | Acc: (94.09%) (13369/14208)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 120 |  Loss: (0.1631) | Acc: (94.14%) (14581/15488)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 130 |  Loss: (0.1609) | Acc: (94.27%) (15808/16768)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 140 |  Loss: (0.1634) | Acc: (94.28%) (17015/18048)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 150 |  Loss: (0.1640) | Acc: (94.25%) (18216/19328)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 160 |  Loss: (0.1640) | Acc: (94.24%) (19421/20608)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 170 |  Loss: (0.1637) | Acc: (94.26%) (20632/21888)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 180 |  Loss: (0.1642) | Acc: (94.28%) (21843/23168)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 190 |  Loss: (0.1652) | Acc: (94.24%) (23039/24448)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 200 |  Loss: (0.1649) | Acc: (94.26%) (24251/25728)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 210 |  Loss: (0.1654) | Acc: (94.25%) (25455/27008)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 220 |  Loss: (0.1656) | Acc: (94.26%) (26664/28288)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 230 |  Loss: (0.1657) | Acc: (94.21%) (27857/29568)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 240 |  Loss: (0.1655) | Acc: (94.21%) (29063/30848)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 250 |  Loss: (0.1662) | Acc: (94.20%) (30263/32128)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 260 |  Loss: (0.1663) | Acc: (94.20%) (31472/33408)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 270 |  Loss: (0.1672) | Acc: (94.19%) (32672/34688)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 280 |  Loss: (0.1666) | Acc: (94.21%) (33887/35968)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 290 |  Loss: (0.1670) | Acc: (94.19%) (35084/37248)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 300 |  Loss: (0.1669) | Acc: (94.19%) (36291/38528)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 310 |  Loss: (0.1670) | Acc: (94.20%) (37499/39808)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 320 |  Loss: (0.1677) | Acc: (94.17%) (38693/41088)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 330 |  Loss: (0.1680) | Acc: (94.17%) (39900/42368)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 340 |  Loss: (0.1678) | Acc: (94.18%) (41107/43648)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 350 |  Loss: (0.1675) | Acc: (94.19%) (42317/44928)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 360 |  Loss: (0.1674) | Acc: (94.20%) (43527/46208)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 370 |  Loss: (0.1682) | Acc: (94.17%) (44721/47488)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 380 |  Loss: (0.1682) | Acc: (94.17%) (45925/48768)\n",
      "lr: 0.001\n",
      "Epoch: 78 | Batch_idx: 390 |  Loss: (0.1685) | Acc: (94.15%) (47074/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.6126) | Acc: (35.27%) (3527/10000)\n",
      "Epoch: 79 | Batch_idx: 0 |  Loss: (0.1751) | Acc: (93.75%) (120/128)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 10 |  Loss: (0.1818) | Acc: (93.39%) (1315/1408)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 20 |  Loss: (0.1753) | Acc: (93.71%) (2519/2688)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 30 |  Loss: (0.1720) | Acc: (94.00%) (3730/3968)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 40 |  Loss: (0.1732) | Acc: (94.02%) (4934/5248)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 50 |  Loss: (0.1765) | Acc: (93.93%) (6132/6528)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 60 |  Loss: (0.1748) | Acc: (94.04%) (7343/7808)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 70 |  Loss: (0.1727) | Acc: (94.12%) (8554/9088)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 80 |  Loss: (0.1711) | Acc: (94.17%) (9764/10368)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 90 |  Loss: (0.1725) | Acc: (94.12%) (10963/11648)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 100 |  Loss: (0.1714) | Acc: (94.14%) (12171/12928)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 110 |  Loss: (0.1715) | Acc: (94.09%) (13368/14208)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 120 |  Loss: (0.1718) | Acc: (94.08%) (14571/15488)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 130 |  Loss: (0.1704) | Acc: (94.19%) (15793/16768)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 140 |  Loss: (0.1707) | Acc: (94.18%) (16998/18048)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 150 |  Loss: (0.1690) | Acc: (94.27%) (18220/19328)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 160 |  Loss: (0.1695) | Acc: (94.29%) (19432/20608)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 170 |  Loss: (0.1695) | Acc: (94.28%) (20635/21888)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 180 |  Loss: (0.1697) | Acc: (94.24%) (21834/23168)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 190 |  Loss: (0.1686) | Acc: (94.27%) (23047/24448)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 200 |  Loss: (0.1690) | Acc: (94.24%) (24247/25728)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 210 |  Loss: (0.1691) | Acc: (94.23%) (25449/27008)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 220 |  Loss: (0.1706) | Acc: (94.15%) (26634/28288)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 230 |  Loss: (0.1704) | Acc: (94.15%) (27837/29568)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 240 |  Loss: (0.1706) | Acc: (94.15%) (29044/30848)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 250 |  Loss: (0.1710) | Acc: (94.12%) (30239/32128)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 260 |  Loss: (0.1707) | Acc: (94.13%) (31446/33408)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 270 |  Loss: (0.1706) | Acc: (94.11%) (32646/34688)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 280 |  Loss: (0.1701) | Acc: (94.14%) (33859/35968)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 290 |  Loss: (0.1707) | Acc: (94.13%) (35063/37248)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 300 |  Loss: (0.1705) | Acc: (94.13%) (36265/38528)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 310 |  Loss: (0.1700) | Acc: (94.14%) (37474/39808)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 320 |  Loss: (0.1702) | Acc: (94.12%) (38671/41088)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 330 |  Loss: (0.1693) | Acc: (94.15%) (39890/42368)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 340 |  Loss: (0.1696) | Acc: (94.14%) (41090/43648)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 350 |  Loss: (0.1695) | Acc: (94.16%) (42305/44928)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 360 |  Loss: (0.1696) | Acc: (94.16%) (43511/46208)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 370 |  Loss: (0.1695) | Acc: (94.16%) (44717/47488)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 380 |  Loss: (0.1702) | Acc: (94.13%) (45904/48768)\n",
      "lr: 0.001\n",
      "Epoch: 79 | Batch_idx: 390 |  Loss: (0.1694) | Acc: (94.16%) (47078/50000)\n",
      "lr: 0.001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4107) | Acc: (38.82%) (3882/10000)\n",
      "Epoch: 80 | Batch_idx: 0 |  Loss: (0.1010) | Acc: (96.09%) (123/128)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 10 |  Loss: (0.1740) | Acc: (93.61%) (1318/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 20 |  Loss: (0.1771) | Acc: (93.60%) (2516/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 30 |  Loss: (0.1764) | Acc: (93.93%) (3727/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 40 |  Loss: (0.1743) | Acc: (94.04%) (4935/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 50 |  Loss: (0.1686) | Acc: (94.27%) (6154/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 60 |  Loss: (0.1678) | Acc: (94.28%) (7361/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 70 |  Loss: (0.1629) | Acc: (94.47%) (8585/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 80 |  Loss: (0.1618) | Acc: (94.50%) (9798/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 90 |  Loss: (0.1595) | Acc: (94.60%) (11019/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 100 |  Loss: (0.1552) | Acc: (94.73%) (12247/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 110 |  Loss: (0.1545) | Acc: (94.76%) (13463/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 120 |  Loss: (0.1519) | Acc: (94.84%) (14689/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 130 |  Loss: (0.1513) | Acc: (94.83%) (15901/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 140 |  Loss: (0.1484) | Acc: (94.98%) (17142/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 150 |  Loss: (0.1489) | Acc: (94.93%) (18348/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 160 |  Loss: (0.1472) | Acc: (95.01%) (19579/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 170 |  Loss: (0.1468) | Acc: (95.04%) (20802/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 180 |  Loss: (0.1465) | Acc: (95.00%) (22009/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 190 |  Loss: (0.1463) | Acc: (94.99%) (23224/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 200 |  Loss: (0.1459) | Acc: (94.97%) (24433/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 210 |  Loss: (0.1454) | Acc: (95.01%) (25659/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 220 |  Loss: (0.1443) | Acc: (95.03%) (26882/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 230 |  Loss: (0.1443) | Acc: (95.05%) (28103/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 240 |  Loss: (0.1434) | Acc: (95.08%) (29330/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 250 |  Loss: (0.1432) | Acc: (95.09%) (30550/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 260 |  Loss: (0.1430) | Acc: (95.09%) (31767/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 270 |  Loss: (0.1431) | Acc: (95.07%) (32979/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 280 |  Loss: (0.1432) | Acc: (95.06%) (34190/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 290 |  Loss: (0.1434) | Acc: (95.06%) (35408/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 300 |  Loss: (0.1435) | Acc: (95.07%) (36627/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 310 |  Loss: (0.1432) | Acc: (95.06%) (37840/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 320 |  Loss: (0.1427) | Acc: (95.08%) (39068/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 330 |  Loss: (0.1422) | Acc: (95.09%) (40288/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 340 |  Loss: (0.1416) | Acc: (95.10%) (41508/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 350 |  Loss: (0.1421) | Acc: (95.09%) (42721/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 360 |  Loss: (0.1421) | Acc: (95.09%) (43938/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 370 |  Loss: (0.1418) | Acc: (95.10%) (45161/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 380 |  Loss: (0.1416) | Acc: (95.11%) (46385/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 80 | Batch_idx: 390 |  Loss: (0.1415) | Acc: (95.13%) (47564/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3755) | Acc: (38.78%) (3878/10000)\n",
      "Epoch: 81 | Batch_idx: 0 |  Loss: (0.1286) | Acc: (96.09%) (123/128)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 10 |  Loss: (0.1204) | Acc: (95.60%) (1346/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 20 |  Loss: (0.1305) | Acc: (95.24%) (2560/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 30 |  Loss: (0.1376) | Acc: (95.06%) (3772/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 40 |  Loss: (0.1366) | Acc: (95.16%) (4994/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 50 |  Loss: (0.1368) | Acc: (95.21%) (6215/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 60 |  Loss: (0.1351) | Acc: (95.27%) (7439/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 70 |  Loss: (0.1318) | Acc: (95.41%) (8671/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 80 |  Loss: (0.1315) | Acc: (95.44%) (9895/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 90 |  Loss: (0.1297) | Acc: (95.52%) (11126/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 100 |  Loss: (0.1290) | Acc: (95.56%) (12354/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 110 |  Loss: (0.1301) | Acc: (95.53%) (13573/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 120 |  Loss: (0.1291) | Acc: (95.58%) (14803/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 130 |  Loss: (0.1277) | Acc: (95.62%) (16033/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 140 |  Loss: (0.1280) | Acc: (95.58%) (17250/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 150 |  Loss: (0.1294) | Acc: (95.53%) (18464/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 160 |  Loss: (0.1300) | Acc: (95.52%) (19685/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 170 |  Loss: (0.1297) | Acc: (95.54%) (20911/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 180 |  Loss: (0.1306) | Acc: (95.52%) (22129/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 190 |  Loss: (0.1303) | Acc: (95.53%) (23356/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 200 |  Loss: (0.1296) | Acc: (95.54%) (24581/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 210 |  Loss: (0.1298) | Acc: (95.56%) (25808/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 220 |  Loss: (0.1290) | Acc: (95.57%) (27034/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 230 |  Loss: (0.1284) | Acc: (95.62%) (28274/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 240 |  Loss: (0.1284) | Acc: (95.64%) (29503/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 250 |  Loss: (0.1290) | Acc: (95.60%) (30715/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 260 |  Loss: (0.1293) | Acc: (95.59%) (31936/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 270 |  Loss: (0.1295) | Acc: (95.60%) (33160/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 280 |  Loss: (0.1292) | Acc: (95.60%) (34387/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 290 |  Loss: (0.1289) | Acc: (95.61%) (35614/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 300 |  Loss: (0.1284) | Acc: (95.63%) (36845/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 310 |  Loss: (0.1284) | Acc: (95.63%) (38068/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 320 |  Loss: (0.1281) | Acc: (95.64%) (39295/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 330 |  Loss: (0.1280) | Acc: (95.65%) (40523/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 340 |  Loss: (0.1286) | Acc: (95.62%) (41738/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 350 |  Loss: (0.1284) | Acc: (95.63%) (42966/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 360 |  Loss: (0.1287) | Acc: (95.63%) (44188/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 370 |  Loss: (0.1293) | Acc: (95.60%) (45399/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 380 |  Loss: (0.1287) | Acc: (95.62%) (46631/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 81 | Batch_idx: 390 |  Loss: (0.1280) | Acc: (95.65%) (47824/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3589) | Acc: (39.07%) (3907/10000)\n",
      "Epoch: 82 | Batch_idx: 0 |  Loss: (0.1777) | Acc: (94.53%) (121/128)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 10 |  Loss: (0.1341) | Acc: (95.03%) (1338/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 20 |  Loss: (0.1247) | Acc: (95.80%) (2575/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 30 |  Loss: (0.1204) | Acc: (95.97%) (3808/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 40 |  Loss: (0.1176) | Acc: (96.15%) (5046/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 50 |  Loss: (0.1208) | Acc: (96.02%) (6268/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 60 |  Loss: (0.1185) | Acc: (96.08%) (7502/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 70 |  Loss: (0.1196) | Acc: (95.97%) (8722/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 80 |  Loss: (0.1218) | Acc: (95.94%) (9947/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 90 |  Loss: (0.1223) | Acc: (95.91%) (11172/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 100 |  Loss: (0.1225) | Acc: (95.86%) (12393/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 110 |  Loss: (0.1229) | Acc: (95.88%) (13623/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 120 |  Loss: (0.1233) | Acc: (95.84%) (14843/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 130 |  Loss: (0.1221) | Acc: (95.87%) (16076/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 140 |  Loss: (0.1215) | Acc: (95.90%) (17308/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 150 |  Loss: (0.1218) | Acc: (95.90%) (18536/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 160 |  Loss: (0.1233) | Acc: (95.87%) (19756/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 170 |  Loss: (0.1239) | Acc: (95.85%) (20980/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 180 |  Loss: (0.1241) | Acc: (95.84%) (22205/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 190 |  Loss: (0.1240) | Acc: (95.86%) (23437/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 200 |  Loss: (0.1241) | Acc: (95.86%) (24664/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 210 |  Loss: (0.1238) | Acc: (95.88%) (25895/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 220 |  Loss: (0.1232) | Acc: (95.89%) (27126/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 230 |  Loss: (0.1235) | Acc: (95.87%) (28347/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 240 |  Loss: (0.1236) | Acc: (95.87%) (29574/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 250 |  Loss: (0.1237) | Acc: (95.86%) (30797/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 260 |  Loss: (0.1234) | Acc: (95.85%) (32022/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 270 |  Loss: (0.1238) | Acc: (95.84%) (33244/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 280 |  Loss: (0.1239) | Acc: (95.82%) (34465/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 290 |  Loss: (0.1242) | Acc: (95.82%) (35690/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 300 |  Loss: (0.1255) | Acc: (95.75%) (36891/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 310 |  Loss: (0.1259) | Acc: (95.76%) (38120/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 320 |  Loss: (0.1263) | Acc: (95.75%) (39340/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 330 |  Loss: (0.1261) | Acc: (95.75%) (40566/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 340 |  Loss: (0.1265) | Acc: (95.72%) (41782/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 350 |  Loss: (0.1263) | Acc: (95.74%) (43012/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 360 |  Loss: (0.1267) | Acc: (95.72%) (44228/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 370 |  Loss: (0.1265) | Acc: (95.72%) (45454/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 380 |  Loss: (0.1273) | Acc: (95.70%) (46669/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 82 | Batch_idx: 390 |  Loss: (0.1268) | Acc: (95.70%) (47850/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4191) | Acc: (38.95%) (3895/10000)\n",
      "Epoch: 83 | Batch_idx: 0 |  Loss: (0.0791) | Acc: (97.66%) (125/128)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 10 |  Loss: (0.1181) | Acc: (95.81%) (1349/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 20 |  Loss: (0.1130) | Acc: (96.02%) (2581/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 30 |  Loss: (0.1202) | Acc: (95.59%) (3793/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 40 |  Loss: (0.1191) | Acc: (95.69%) (5022/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 50 |  Loss: (0.1151) | Acc: (95.82%) (6255/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 60 |  Loss: (0.1185) | Acc: (95.66%) (7469/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 70 |  Loss: (0.1211) | Acc: (95.65%) (8693/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 80 |  Loss: (0.1204) | Acc: (95.68%) (9920/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 90 |  Loss: (0.1212) | Acc: (95.70%) (11147/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 100 |  Loss: (0.1208) | Acc: (95.74%) (12377/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 110 |  Loss: (0.1189) | Acc: (95.80%) (13611/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 120 |  Loss: (0.1192) | Acc: (95.83%) (14842/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 130 |  Loss: (0.1184) | Acc: (95.89%) (16079/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 140 |  Loss: (0.1186) | Acc: (95.86%) (17301/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 150 |  Loss: (0.1191) | Acc: (95.85%) (18526/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 160 |  Loss: (0.1189) | Acc: (95.84%) (19750/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 170 |  Loss: (0.1186) | Acc: (95.84%) (20978/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 180 |  Loss: (0.1194) | Acc: (95.79%) (22192/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 190 |  Loss: (0.1214) | Acc: (95.72%) (23401/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 200 |  Loss: (0.1206) | Acc: (95.73%) (24630/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 210 |  Loss: (0.1208) | Acc: (95.72%) (25853/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 220 |  Loss: (0.1207) | Acc: (95.73%) (27081/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 230 |  Loss: (0.1202) | Acc: (95.81%) (28328/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 240 |  Loss: (0.1209) | Acc: (95.81%) (29557/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 250 |  Loss: (0.1205) | Acc: (95.84%) (30792/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 260 |  Loss: (0.1213) | Acc: (95.84%) (32018/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 270 |  Loss: (0.1216) | Acc: (95.83%) (33243/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 280 |  Loss: (0.1214) | Acc: (95.84%) (34470/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 290 |  Loss: (0.1205) | Acc: (95.87%) (35711/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 300 |  Loss: (0.1219) | Acc: (95.84%) (36927/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 310 |  Loss: (0.1214) | Acc: (95.84%) (38151/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 320 |  Loss: (0.1216) | Acc: (95.84%) (39379/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 330 |  Loss: (0.1214) | Acc: (95.85%) (40609/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 340 |  Loss: (0.1213) | Acc: (95.86%) (41839/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 350 |  Loss: (0.1209) | Acc: (95.89%) (43080/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 360 |  Loss: (0.1208) | Acc: (95.89%) (44310/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 370 |  Loss: (0.1219) | Acc: (95.86%) (45520/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 380 |  Loss: (0.1218) | Acc: (95.85%) (46745/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 83 | Batch_idx: 390 |  Loss: (0.1215) | Acc: (95.88%) (47938/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3491) | Acc: (39.10%) (3910/10000)\n",
      "Epoch: 84 | Batch_idx: 0 |  Loss: (0.1718) | Acc: (92.97%) (119/128)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 10 |  Loss: (0.1191) | Acc: (95.74%) (1348/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 20 |  Loss: (0.1086) | Acc: (96.13%) (2584/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 30 |  Loss: (0.1170) | Acc: (95.92%) (3806/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 40 |  Loss: (0.1217) | Acc: (95.67%) (5021/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 50 |  Loss: (0.1189) | Acc: (95.76%) (6251/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 60 |  Loss: (0.1189) | Acc: (95.79%) (7479/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 70 |  Loss: (0.1160) | Acc: (95.87%) (8713/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 80 |  Loss: (0.1173) | Acc: (95.83%) (9936/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 90 |  Loss: (0.1157) | Acc: (95.91%) (11172/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 100 |  Loss: (0.1141) | Acc: (95.98%) (12408/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 110 |  Loss: (0.1127) | Acc: (96.04%) (13646/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 120 |  Loss: (0.1146) | Acc: (95.99%) (14867/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 130 |  Loss: (0.1157) | Acc: (95.95%) (16089/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 140 |  Loss: (0.1169) | Acc: (95.97%) (17321/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 150 |  Loss: (0.1162) | Acc: (96.00%) (18555/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 160 |  Loss: (0.1169) | Acc: (95.98%) (19779/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 170 |  Loss: (0.1159) | Acc: (96.03%) (21018/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 180 |  Loss: (0.1150) | Acc: (96.04%) (22251/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 190 |  Loss: (0.1151) | Acc: (96.03%) (23478/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 200 |  Loss: (0.1154) | Acc: (96.00%) (24700/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 210 |  Loss: (0.1150) | Acc: (96.02%) (25933/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 220 |  Loss: (0.1161) | Acc: (95.99%) (27153/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 230 |  Loss: (0.1162) | Acc: (95.98%) (28380/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 240 |  Loss: (0.1166) | Acc: (95.97%) (29604/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 250 |  Loss: (0.1163) | Acc: (95.98%) (30838/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 260 |  Loss: (0.1161) | Acc: (95.99%) (32069/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 270 |  Loss: (0.1169) | Acc: (95.96%) (33288/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 280 |  Loss: (0.1166) | Acc: (95.99%) (34527/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 290 |  Loss: (0.1167) | Acc: (96.01%) (35763/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 300 |  Loss: (0.1167) | Acc: (96.01%) (36991/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 310 |  Loss: (0.1162) | Acc: (96.02%) (38224/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 320 |  Loss: (0.1166) | Acc: (95.99%) (39441/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 330 |  Loss: (0.1168) | Acc: (95.98%) (40663/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 340 |  Loss: (0.1168) | Acc: (95.97%) (41891/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 350 |  Loss: (0.1173) | Acc: (95.96%) (43114/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 360 |  Loss: (0.1177) | Acc: (95.94%) (44330/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 370 |  Loss: (0.1174) | Acc: (95.94%) (45559/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 380 |  Loss: (0.1173) | Acc: (95.94%) (46787/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 84 | Batch_idx: 390 |  Loss: (0.1177) | Acc: (95.93%) (47965/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4652) | Acc: (37.17%) (3717/10000)\n",
      "Epoch: 85 | Batch_idx: 0 |  Loss: (0.1440) | Acc: (95.31%) (122/128)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 10 |  Loss: (0.1102) | Acc: (95.74%) (1348/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 20 |  Loss: (0.1171) | Acc: (95.54%) (2568/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 30 |  Loss: (0.1118) | Acc: (95.99%) (3809/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 40 |  Loss: (0.1131) | Acc: (96.02%) (5039/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 50 |  Loss: (0.1125) | Acc: (95.88%) (6259/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 60 |  Loss: (0.1111) | Acc: (96.00%) (7496/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 70 |  Loss: (0.1139) | Acc: (95.88%) (8714/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 80 |  Loss: (0.1124) | Acc: (95.91%) (9944/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 90 |  Loss: (0.1130) | Acc: (95.93%) (11174/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 100 |  Loss: (0.1128) | Acc: (95.93%) (12402/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 110 |  Loss: (0.1128) | Acc: (95.92%) (13629/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 120 |  Loss: (0.1133) | Acc: (95.96%) (14863/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 130 |  Loss: (0.1128) | Acc: (95.98%) (16094/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 140 |  Loss: (0.1124) | Acc: (96.02%) (17330/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 150 |  Loss: (0.1116) | Acc: (96.05%) (18565/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 160 |  Loss: (0.1121) | Acc: (96.03%) (19789/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 170 |  Loss: (0.1125) | Acc: (96.02%) (21017/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 180 |  Loss: (0.1126) | Acc: (96.05%) (22253/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 190 |  Loss: (0.1127) | Acc: (96.06%) (23484/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 200 |  Loss: (0.1133) | Acc: (96.03%) (24707/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 210 |  Loss: (0.1124) | Acc: (96.08%) (25950/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 220 |  Loss: (0.1128) | Acc: (96.04%) (27169/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 230 |  Loss: (0.1128) | Acc: (96.04%) (28396/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 240 |  Loss: (0.1123) | Acc: (96.07%) (29635/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 250 |  Loss: (0.1131) | Acc: (96.01%) (30846/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 260 |  Loss: (0.1134) | Acc: (96.02%) (32077/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 270 |  Loss: (0.1135) | Acc: (96.01%) (33303/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 280 |  Loss: (0.1129) | Acc: (96.03%) (34541/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 290 |  Loss: (0.1127) | Acc: (96.05%) (35775/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 300 |  Loss: (0.1133) | Acc: (96.03%) (36998/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 310 |  Loss: (0.1134) | Acc: (96.03%) (38227/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 320 |  Loss: (0.1136) | Acc: (96.04%) (39460/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 330 |  Loss: (0.1137) | Acc: (96.04%) (40691/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 340 |  Loss: (0.1130) | Acc: (96.09%) (41943/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 350 |  Loss: (0.1141) | Acc: (96.06%) (43157/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 360 |  Loss: (0.1146) | Acc: (96.04%) (44376/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 370 |  Loss: (0.1141) | Acc: (96.06%) (45616/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 380 |  Loss: (0.1138) | Acc: (96.07%) (46852/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 85 | Batch_idx: 390 |  Loss: (0.1139) | Acc: (96.06%) (48031/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3653) | Acc: (39.06%) (3906/10000)\n",
      "Epoch: 86 | Batch_idx: 0 |  Loss: (0.1646) | Acc: (93.75%) (120/128)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 10 |  Loss: (0.1174) | Acc: (96.31%) (1356/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 20 |  Loss: (0.1193) | Acc: (96.02%) (2581/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 30 |  Loss: (0.1223) | Acc: (95.87%) (3804/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 40 |  Loss: (0.1185) | Acc: (95.96%) (5036/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 50 |  Loss: (0.1238) | Acc: (95.71%) (6248/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 60 |  Loss: (0.1242) | Acc: (95.81%) (7481/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 70 |  Loss: (0.1218) | Acc: (95.95%) (8720/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 80 |  Loss: (0.1210) | Acc: (96.03%) (9956/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 90 |  Loss: (0.1206) | Acc: (95.96%) (11177/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 100 |  Loss: (0.1182) | Acc: (96.10%) (12424/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 110 |  Loss: (0.1159) | Acc: (96.16%) (13662/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 120 |  Loss: (0.1142) | Acc: (96.24%) (14905/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 130 |  Loss: (0.1151) | Acc: (96.18%) (16128/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 140 |  Loss: (0.1147) | Acc: (96.19%) (17360/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 150 |  Loss: (0.1144) | Acc: (96.19%) (18592/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 160 |  Loss: (0.1141) | Acc: (96.23%) (19831/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 170 |  Loss: (0.1147) | Acc: (96.19%) (21055/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 180 |  Loss: (0.1147) | Acc: (96.19%) (22285/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 190 |  Loss: (0.1140) | Acc: (96.22%) (23524/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 200 |  Loss: (0.1148) | Acc: (96.20%) (24750/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 210 |  Loss: (0.1150) | Acc: (96.20%) (25983/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 220 |  Loss: (0.1154) | Acc: (96.19%) (27211/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 230 |  Loss: (0.1159) | Acc: (96.19%) (28441/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 240 |  Loss: (0.1156) | Acc: (96.19%) (29672/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 250 |  Loss: (0.1154) | Acc: (96.17%) (30899/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 260 |  Loss: (0.1155) | Acc: (96.16%) (32124/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 270 |  Loss: (0.1152) | Acc: (96.16%) (33355/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 280 |  Loss: (0.1155) | Acc: (96.14%) (34579/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 290 |  Loss: (0.1159) | Acc: (96.12%) (35804/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 300 |  Loss: (0.1157) | Acc: (96.11%) (37031/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 310 |  Loss: (0.1154) | Acc: (96.11%) (38259/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 320 |  Loss: (0.1156) | Acc: (96.09%) (39480/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 330 |  Loss: (0.1156) | Acc: (96.09%) (40712/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 340 |  Loss: (0.1150) | Acc: (96.12%) (41953/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 350 |  Loss: (0.1154) | Acc: (96.11%) (43181/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 360 |  Loss: (0.1154) | Acc: (96.12%) (44415/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 370 |  Loss: (0.1154) | Acc: (96.12%) (45644/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 380 |  Loss: (0.1150) | Acc: (96.14%) (46885/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 86 | Batch_idx: 390 |  Loss: (0.1157) | Acc: (96.11%) (48056/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4477) | Acc: (37.56%) (3756/10000)\n",
      "Epoch: 87 | Batch_idx: 0 |  Loss: (0.1141) | Acc: (95.31%) (122/128)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 10 |  Loss: (0.1056) | Acc: (96.45%) (1358/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 20 |  Loss: (0.1060) | Acc: (96.50%) (2594/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 30 |  Loss: (0.1143) | Acc: (96.14%) (3815/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 40 |  Loss: (0.1131) | Acc: (96.07%) (5042/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 50 |  Loss: (0.1113) | Acc: (96.02%) (6268/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 60 |  Loss: (0.1092) | Acc: (96.12%) (7505/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 70 |  Loss: (0.1114) | Acc: (96.07%) (8731/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 80 |  Loss: (0.1080) | Acc: (96.22%) (9976/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 90 |  Loss: (0.1101) | Acc: (96.10%) (11194/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 100 |  Loss: (0.1110) | Acc: (96.09%) (12422/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 110 |  Loss: (0.1105) | Acc: (96.09%) (13653/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 120 |  Loss: (0.1103) | Acc: (96.11%) (14885/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 130 |  Loss: (0.1097) | Acc: (96.17%) (16125/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 140 |  Loss: (0.1098) | Acc: (96.18%) (17359/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 150 |  Loss: (0.1090) | Acc: (96.21%) (18596/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 160 |  Loss: (0.1078) | Acc: (96.27%) (19840/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 170 |  Loss: (0.1075) | Acc: (96.27%) (21072/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 180 |  Loss: (0.1093) | Acc: (96.21%) (22289/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 190 |  Loss: (0.1092) | Acc: (96.22%) (23524/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 200 |  Loss: (0.1089) | Acc: (96.23%) (24759/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 210 |  Loss: (0.1089) | Acc: (96.22%) (25987/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 220 |  Loss: (0.1088) | Acc: (96.21%) (27215/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 230 |  Loss: (0.1084) | Acc: (96.23%) (28452/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 240 |  Loss: (0.1081) | Acc: (96.25%) (29692/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 250 |  Loss: (0.1087) | Acc: (96.23%) (30917/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 260 |  Loss: (0.1090) | Acc: (96.23%) (32147/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 270 |  Loss: (0.1093) | Acc: (96.24%) (33383/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 280 |  Loss: (0.1090) | Acc: (96.26%) (34622/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 290 |  Loss: (0.1090) | Acc: (96.26%) (35856/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 300 |  Loss: (0.1094) | Acc: (96.26%) (37086/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 310 |  Loss: (0.1095) | Acc: (96.26%) (38318/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 320 |  Loss: (0.1100) | Acc: (96.25%) (39547/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 330 |  Loss: (0.1102) | Acc: (96.23%) (40770/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 340 |  Loss: (0.1105) | Acc: (96.21%) (41993/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 350 |  Loss: (0.1105) | Acc: (96.21%) (43224/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 360 |  Loss: (0.1105) | Acc: (96.19%) (44446/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 370 |  Loss: (0.1106) | Acc: (96.19%) (45679/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 380 |  Loss: (0.1105) | Acc: (96.20%) (46913/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 87 | Batch_idx: 390 |  Loss: (0.1111) | Acc: (96.18%) (48090/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3952) | Acc: (39.34%) (3934/10000)\n",
      "Epoch: 88 | Batch_idx: 0 |  Loss: (0.1330) | Acc: (94.53%) (121/128)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 10 |  Loss: (0.1284) | Acc: (95.45%) (1344/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 20 |  Loss: (0.1241) | Acc: (95.80%) (2575/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 30 |  Loss: (0.1237) | Acc: (95.67%) (3796/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 40 |  Loss: (0.1209) | Acc: (95.88%) (5032/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 50 |  Loss: (0.1202) | Acc: (95.89%) (6260/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 60 |  Loss: (0.1197) | Acc: (95.84%) (7483/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 70 |  Loss: (0.1181) | Acc: (95.85%) (8711/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 80 |  Loss: (0.1184) | Acc: (95.90%) (9943/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 90 |  Loss: (0.1178) | Acc: (95.93%) (11174/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 100 |  Loss: (0.1157) | Acc: (96.02%) (12413/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 110 |  Loss: (0.1161) | Acc: (96.03%) (13644/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 120 |  Loss: (0.1162) | Acc: (96.02%) (14872/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 130 |  Loss: (0.1156) | Acc: (96.05%) (16106/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 140 |  Loss: (0.1163) | Acc: (96.04%) (17334/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 150 |  Loss: (0.1174) | Acc: (96.01%) (18556/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 160 |  Loss: (0.1168) | Acc: (96.04%) (19791/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 170 |  Loss: (0.1161) | Acc: (96.06%) (21025/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 180 |  Loss: (0.1165) | Acc: (96.09%) (22263/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 190 |  Loss: (0.1179) | Acc: (96.07%) (23486/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 200 |  Loss: (0.1176) | Acc: (96.08%) (24720/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 210 |  Loss: (0.1167) | Acc: (96.10%) (25956/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 220 |  Loss: (0.1164) | Acc: (96.10%) (27186/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 230 |  Loss: (0.1163) | Acc: (96.09%) (28413/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 240 |  Loss: (0.1153) | Acc: (96.11%) (29647/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 250 |  Loss: (0.1155) | Acc: (96.09%) (30872/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 260 |  Loss: (0.1150) | Acc: (96.11%) (32108/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 270 |  Loss: (0.1147) | Acc: (96.13%) (33344/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 280 |  Loss: (0.1148) | Acc: (96.12%) (34572/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 290 |  Loss: (0.1139) | Acc: (96.16%) (35818/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 300 |  Loss: (0.1137) | Acc: (96.16%) (37048/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 310 |  Loss: (0.1138) | Acc: (96.15%) (38276/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 320 |  Loss: (0.1133) | Acc: (96.17%) (39515/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 330 |  Loss: (0.1136) | Acc: (96.17%) (40744/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 340 |  Loss: (0.1134) | Acc: (96.19%) (41984/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 350 |  Loss: (0.1134) | Acc: (96.19%) (43217/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 360 |  Loss: (0.1132) | Acc: (96.19%) (44448/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 370 |  Loss: (0.1132) | Acc: (96.19%) (45681/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 380 |  Loss: (0.1134) | Acc: (96.19%) (46909/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 88 | Batch_idx: 390 |  Loss: (0.1129) | Acc: (96.21%) (48103/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3134) | Acc: (40.80%) (4080/10000)\n",
      "Epoch: 89 | Batch_idx: 0 |  Loss: (0.1164) | Acc: (97.66%) (125/128)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 10 |  Loss: (0.1136) | Acc: (96.45%) (1358/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 20 |  Loss: (0.1266) | Acc: (95.98%) (2580/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 30 |  Loss: (0.1211) | Acc: (96.09%) (3813/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 40 |  Loss: (0.1193) | Acc: (95.98%) (5037/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 50 |  Loss: (0.1181) | Acc: (96.03%) (6269/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 60 |  Loss: (0.1160) | Acc: (96.13%) (7506/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 70 |  Loss: (0.1132) | Acc: (96.27%) (8749/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 80 |  Loss: (0.1141) | Acc: (96.15%) (9969/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 90 |  Loss: (0.1125) | Acc: (96.21%) (11206/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 100 |  Loss: (0.1122) | Acc: (96.19%) (12435/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 110 |  Loss: (0.1125) | Acc: (96.18%) (13665/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 120 |  Loss: (0.1125) | Acc: (96.16%) (14894/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 130 |  Loss: (0.1120) | Acc: (96.18%) (16128/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 140 |  Loss: (0.1114) | Acc: (96.22%) (17366/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 150 |  Loss: (0.1135) | Acc: (96.15%) (18584/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 160 |  Loss: (0.1125) | Acc: (96.15%) (19814/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 170 |  Loss: (0.1120) | Acc: (96.18%) (21051/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 180 |  Loss: (0.1128) | Acc: (96.15%) (22277/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 190 |  Loss: (0.1127) | Acc: (96.18%) (23513/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 200 |  Loss: (0.1124) | Acc: (96.19%) (24747/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 210 |  Loss: (0.1137) | Acc: (96.14%) (25965/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 220 |  Loss: (0.1140) | Acc: (96.12%) (27191/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 230 |  Loss: (0.1134) | Acc: (96.14%) (28426/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 240 |  Loss: (0.1135) | Acc: (96.15%) (29661/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 250 |  Loss: (0.1132) | Acc: (96.16%) (30894/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 260 |  Loss: (0.1132) | Acc: (96.15%) (32121/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 270 |  Loss: (0.1126) | Acc: (96.19%) (33366/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 280 |  Loss: (0.1125) | Acc: (96.18%) (34595/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 290 |  Loss: (0.1122) | Acc: (96.19%) (35830/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 300 |  Loss: (0.1126) | Acc: (96.20%) (37063/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 310 |  Loss: (0.1126) | Acc: (96.18%) (38289/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 320 |  Loss: (0.1126) | Acc: (96.18%) (39520/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 330 |  Loss: (0.1124) | Acc: (96.20%) (40759/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 340 |  Loss: (0.1128) | Acc: (96.20%) (41988/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 350 |  Loss: (0.1123) | Acc: (96.21%) (43225/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 360 |  Loss: (0.1129) | Acc: (96.19%) (44446/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 370 |  Loss: (0.1129) | Acc: (96.18%) (45674/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 380 |  Loss: (0.1128) | Acc: (96.18%) (46905/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 89 | Batch_idx: 390 |  Loss: (0.1129) | Acc: (96.16%) (48082/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3447) | Acc: (40.12%) (4012/10000)\n",
      "Epoch: 90 | Batch_idx: 0 |  Loss: (0.0946) | Acc: (96.88%) (124/128)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 10 |  Loss: (0.1001) | Acc: (96.73%) (1362/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 20 |  Loss: (0.0953) | Acc: (96.69%) (2599/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 30 |  Loss: (0.0993) | Acc: (96.55%) (3831/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 40 |  Loss: (0.1015) | Acc: (96.49%) (5064/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 50 |  Loss: (0.1052) | Acc: (96.42%) (6294/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 60 |  Loss: (0.1061) | Acc: (96.43%) (7529/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 70 |  Loss: (0.1057) | Acc: (96.32%) (8754/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 80 |  Loss: (0.1072) | Acc: (96.24%) (9978/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 90 |  Loss: (0.1063) | Acc: (96.28%) (11215/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 100 |  Loss: (0.1062) | Acc: (96.28%) (12447/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 110 |  Loss: (0.1061) | Acc: (96.33%) (13686/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 120 |  Loss: (0.1076) | Acc: (96.31%) (14916/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 130 |  Loss: (0.1096) | Acc: (96.24%) (16137/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 140 |  Loss: (0.1108) | Acc: (96.18%) (17359/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 150 |  Loss: (0.1107) | Acc: (96.20%) (18593/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 160 |  Loss: (0.1091) | Acc: (96.24%) (19833/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 170 |  Loss: (0.1079) | Acc: (96.29%) (21075/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 180 |  Loss: (0.1082) | Acc: (96.26%) (22302/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 190 |  Loss: (0.1069) | Acc: (96.28%) (23539/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 200 |  Loss: (0.1070) | Acc: (96.29%) (24774/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 210 |  Loss: (0.1071) | Acc: (96.30%) (26010/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 220 |  Loss: (0.1069) | Acc: (96.31%) (27243/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 230 |  Loss: (0.1066) | Acc: (96.31%) (28478/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 240 |  Loss: (0.1064) | Acc: (96.32%) (29714/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 250 |  Loss: (0.1059) | Acc: (96.34%) (30952/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 260 |  Loss: (0.1061) | Acc: (96.33%) (32182/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 270 |  Loss: (0.1060) | Acc: (96.34%) (33418/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 280 |  Loss: (0.1061) | Acc: (96.34%) (34650/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 290 |  Loss: (0.1062) | Acc: (96.34%) (35885/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 300 |  Loss: (0.1063) | Acc: (96.33%) (37114/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 310 |  Loss: (0.1066) | Acc: (96.31%) (38338/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 320 |  Loss: (0.1068) | Acc: (96.29%) (39563/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 330 |  Loss: (0.1079) | Acc: (96.27%) (40786/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 340 |  Loss: (0.1083) | Acc: (96.28%) (42023/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 350 |  Loss: (0.1081) | Acc: (96.28%) (43258/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 360 |  Loss: (0.1089) | Acc: (96.27%) (44484/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 370 |  Loss: (0.1094) | Acc: (96.24%) (45702/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 380 |  Loss: (0.1091) | Acc: (96.26%) (46942/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 90 | Batch_idx: 390 |  Loss: (0.1090) | Acc: (96.26%) (48130/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3971) | Acc: (39.46%) (3946/10000)\n",
      "Epoch: 91 | Batch_idx: 0 |  Loss: (0.1729) | Acc: (92.97%) (119/128)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 10 |  Loss: (0.1161) | Acc: (95.81%) (1349/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 20 |  Loss: (0.1145) | Acc: (95.98%) (2580/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 30 |  Loss: (0.1150) | Acc: (96.12%) (3814/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 40 |  Loss: (0.1165) | Acc: (96.17%) (5047/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 50 |  Loss: (0.1176) | Acc: (96.16%) (6277/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 60 |  Loss: (0.1154) | Acc: (96.23%) (7514/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 70 |  Loss: (0.1140) | Acc: (96.19%) (8742/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 80 |  Loss: (0.1114) | Acc: (96.30%) (9984/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 90 |  Loss: (0.1120) | Acc: (96.21%) (11206/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 100 |  Loss: (0.1112) | Acc: (96.20%) (12437/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 110 |  Loss: (0.1107) | Acc: (96.19%) (13666/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 120 |  Loss: (0.1106) | Acc: (96.20%) (14899/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 130 |  Loss: (0.1106) | Acc: (96.22%) (16134/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 140 |  Loss: (0.1115) | Acc: (96.20%) (17362/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 150 |  Loss: (0.1122) | Acc: (96.18%) (18590/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 160 |  Loss: (0.1140) | Acc: (96.11%) (19807/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 170 |  Loss: (0.1139) | Acc: (96.08%) (21031/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 180 |  Loss: (0.1133) | Acc: (96.10%) (22264/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 190 |  Loss: (0.1127) | Acc: (96.11%) (23497/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 200 |  Loss: (0.1124) | Acc: (96.13%) (24732/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 210 |  Loss: (0.1119) | Acc: (96.16%) (25971/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 220 |  Loss: (0.1121) | Acc: (96.14%) (27196/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 230 |  Loss: (0.1129) | Acc: (96.11%) (28419/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 240 |  Loss: (0.1130) | Acc: (96.11%) (29648/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 250 |  Loss: (0.1122) | Acc: (96.14%) (30887/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 260 |  Loss: (0.1127) | Acc: (96.12%) (32112/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 270 |  Loss: (0.1129) | Acc: (96.11%) (33338/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 280 |  Loss: (0.1127) | Acc: (96.12%) (34572/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 290 |  Loss: (0.1123) | Acc: (96.13%) (35806/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 300 |  Loss: (0.1124) | Acc: (96.14%) (37039/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 310 |  Loss: (0.1122) | Acc: (96.15%) (38277/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 320 |  Loss: (0.1120) | Acc: (96.17%) (39513/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 330 |  Loss: (0.1119) | Acc: (96.19%) (40755/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 340 |  Loss: (0.1124) | Acc: (96.17%) (41976/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 350 |  Loss: (0.1125) | Acc: (96.17%) (43209/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 360 |  Loss: (0.1130) | Acc: (96.16%) (44435/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 370 |  Loss: (0.1125) | Acc: (96.18%) (45674/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 380 |  Loss: (0.1127) | Acc: (96.17%) (46900/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 91 | Batch_idx: 390 |  Loss: (0.1123) | Acc: (96.19%) (48096/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3543) | Acc: (39.58%) (3958/10000)\n",
      "Epoch: 92 | Batch_idx: 0 |  Loss: (0.1343) | Acc: (94.53%) (121/128)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 10 |  Loss: (0.0855) | Acc: (96.95%) (1365/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 20 |  Loss: (0.0905) | Acc: (96.84%) (2603/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 30 |  Loss: (0.0953) | Acc: (96.67%) (3836/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 40 |  Loss: (0.1037) | Acc: (96.49%) (5064/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 50 |  Loss: (0.1032) | Acc: (96.48%) (6298/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 60 |  Loss: (0.1037) | Acc: (96.44%) (7530/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 70 |  Loss: (0.1077) | Acc: (96.25%) (8747/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 80 |  Loss: (0.1036) | Acc: (96.40%) (9995/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 90 |  Loss: (0.1079) | Acc: (96.19%) (11204/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 100 |  Loss: (0.1099) | Acc: (96.13%) (12428/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 110 |  Loss: (0.1080) | Acc: (96.24%) (13674/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 120 |  Loss: (0.1067) | Acc: (96.31%) (14917/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 130 |  Loss: (0.1065) | Acc: (96.34%) (16155/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 140 |  Loss: (0.1071) | Acc: (96.37%) (17392/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 150 |  Loss: (0.1091) | Acc: (96.31%) (18614/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 160 |  Loss: (0.1075) | Acc: (96.36%) (19858/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 170 |  Loss: (0.1076) | Acc: (96.38%) (21096/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 180 |  Loss: (0.1092) | Acc: (96.36%) (22324/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 190 |  Loss: (0.1093) | Acc: (96.34%) (23554/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 200 |  Loss: (0.1090) | Acc: (96.32%) (24782/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 210 |  Loss: (0.1083) | Acc: (96.34%) (26019/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 220 |  Loss: (0.1079) | Acc: (96.34%) (27254/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 230 |  Loss: (0.1077) | Acc: (96.36%) (28491/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 240 |  Loss: (0.1076) | Acc: (96.37%) (29728/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 250 |  Loss: (0.1082) | Acc: (96.35%) (30955/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 260 |  Loss: (0.1084) | Acc: (96.36%) (32193/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 270 |  Loss: (0.1089) | Acc: (96.34%) (33417/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 280 |  Loss: (0.1094) | Acc: (96.32%) (34645/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 290 |  Loss: (0.1095) | Acc: (96.31%) (35875/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 300 |  Loss: (0.1101) | Acc: (96.28%) (37095/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 310 |  Loss: (0.1108) | Acc: (96.24%) (38312/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 320 |  Loss: (0.1108) | Acc: (96.24%) (39544/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 330 |  Loss: (0.1103) | Acc: (96.26%) (40784/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 340 |  Loss: (0.1105) | Acc: (96.26%) (42015/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 350 |  Loss: (0.1110) | Acc: (96.25%) (43241/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 360 |  Loss: (0.1102) | Acc: (96.27%) (44484/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 370 |  Loss: (0.1106) | Acc: (96.23%) (45700/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 380 |  Loss: (0.1108) | Acc: (96.23%) (46929/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 92 | Batch_idx: 390 |  Loss: (0.1113) | Acc: (96.23%) (48114/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3942) | Acc: (39.03%) (3903/10000)\n",
      "Epoch: 93 | Batch_idx: 0 |  Loss: (0.1498) | Acc: (96.09%) (123/128)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 10 |  Loss: (0.1052) | Acc: (96.59%) (1360/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 20 |  Loss: (0.0986) | Acc: (96.50%) (2594/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 30 |  Loss: (0.1006) | Acc: (96.32%) (3822/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 40 |  Loss: (0.1018) | Acc: (96.40%) (5059/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 50 |  Loss: (0.1003) | Acc: (96.48%) (6298/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 60 |  Loss: (0.0978) | Acc: (96.58%) (7541/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 70 |  Loss: (0.0990) | Acc: (96.58%) (8777/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 80 |  Loss: (0.1025) | Acc: (96.48%) (10003/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 90 |  Loss: (0.1043) | Acc: (96.42%) (11231/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 100 |  Loss: (0.1026) | Acc: (96.49%) (12474/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 110 |  Loss: (0.1043) | Acc: (96.44%) (13702/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 120 |  Loss: (0.1040) | Acc: (96.45%) (14938/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 130 |  Loss: (0.1039) | Acc: (96.48%) (16177/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 140 |  Loss: (0.1043) | Acc: (96.48%) (17413/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 150 |  Loss: (0.1055) | Acc: (96.42%) (18636/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 160 |  Loss: (0.1058) | Acc: (96.43%) (19872/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 170 |  Loss: (0.1054) | Acc: (96.44%) (21108/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 180 |  Loss: (0.1064) | Acc: (96.39%) (22331/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 190 |  Loss: (0.1064) | Acc: (96.40%) (23568/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 200 |  Loss: (0.1070) | Acc: (96.37%) (24793/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 210 |  Loss: (0.1065) | Acc: (96.40%) (26035/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 220 |  Loss: (0.1056) | Acc: (96.42%) (27274/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 230 |  Loss: (0.1056) | Acc: (96.42%) (28509/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 240 |  Loss: (0.1061) | Acc: (96.41%) (29740/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 250 |  Loss: (0.1064) | Acc: (96.40%) (30970/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 260 |  Loss: (0.1066) | Acc: (96.35%) (32189/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 270 |  Loss: (0.1061) | Acc: (96.36%) (33427/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 280 |  Loss: (0.1059) | Acc: (96.36%) (34657/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 290 |  Loss: (0.1050) | Acc: (96.40%) (35906/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 300 |  Loss: (0.1049) | Acc: (96.40%) (37141/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 310 |  Loss: (0.1053) | Acc: (96.39%) (38370/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 320 |  Loss: (0.1058) | Acc: (96.38%) (39599/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 330 |  Loss: (0.1057) | Acc: (96.38%) (40836/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 340 |  Loss: (0.1054) | Acc: (96.38%) (42070/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 350 |  Loss: (0.1052) | Acc: (96.39%) (43306/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 360 |  Loss: (0.1043) | Acc: (96.42%) (44555/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 370 |  Loss: (0.1041) | Acc: (96.42%) (45788/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 380 |  Loss: (0.1038) | Acc: (96.43%) (47027/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 93 | Batch_idx: 390 |  Loss: (0.1037) | Acc: (96.44%) (48219/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3651) | Acc: (39.43%) (3943/10000)\n",
      "Epoch: 94 | Batch_idx: 0 |  Loss: (0.1680) | Acc: (96.09%) (123/128)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 10 |  Loss: (0.1106) | Acc: (96.66%) (1361/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 20 |  Loss: (0.1158) | Acc: (96.28%) (2588/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 30 |  Loss: (0.1180) | Acc: (96.17%) (3816/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 40 |  Loss: (0.1171) | Acc: (96.21%) (5049/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 50 |  Loss: (0.1134) | Acc: (96.26%) (6284/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 60 |  Loss: (0.1120) | Acc: (96.25%) (7515/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 70 |  Loss: (0.1085) | Acc: (96.43%) (8764/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 80 |  Loss: (0.1087) | Acc: (96.39%) (9994/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 90 |  Loss: (0.1078) | Acc: (96.41%) (11230/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 100 |  Loss: (0.1072) | Acc: (96.45%) (12469/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 110 |  Loss: (0.1086) | Acc: (96.35%) (13690/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 120 |  Loss: (0.1076) | Acc: (96.40%) (14930/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 130 |  Loss: (0.1076) | Acc: (96.33%) (16153/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 140 |  Loss: (0.1073) | Acc: (96.33%) (17385/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 150 |  Loss: (0.1062) | Acc: (96.37%) (18627/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 160 |  Loss: (0.1067) | Acc: (96.35%) (19855/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 170 |  Loss: (0.1073) | Acc: (96.29%) (21076/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 180 |  Loss: (0.1068) | Acc: (96.34%) (22320/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 190 |  Loss: (0.1055) | Acc: (96.40%) (23567/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 200 |  Loss: (0.1054) | Acc: (96.41%) (24804/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 210 |  Loss: (0.1062) | Acc: (96.41%) (26038/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 220 |  Loss: (0.1057) | Acc: (96.42%) (27275/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 230 |  Loss: (0.1061) | Acc: (96.40%) (28505/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 240 |  Loss: (0.1066) | Acc: (96.39%) (29733/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 250 |  Loss: (0.1062) | Acc: (96.39%) (30968/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 260 |  Loss: (0.1053) | Acc: (96.43%) (32215/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 270 |  Loss: (0.1058) | Acc: (96.44%) (33453/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 280 |  Loss: (0.1058) | Acc: (96.46%) (34693/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 290 |  Loss: (0.1061) | Acc: (96.46%) (35930/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 300 |  Loss: (0.1061) | Acc: (96.46%) (37165/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 310 |  Loss: (0.1056) | Acc: (96.49%) (38412/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 320 |  Loss: (0.1062) | Acc: (96.46%) (39635/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 330 |  Loss: (0.1068) | Acc: (96.44%) (40858/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 340 |  Loss: (0.1073) | Acc: (96.41%) (42083/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 350 |  Loss: (0.1072) | Acc: (96.42%) (43321/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 360 |  Loss: (0.1074) | Acc: (96.42%) (44556/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 370 |  Loss: (0.1071) | Acc: (96.44%) (45797/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 380 |  Loss: (0.1068) | Acc: (96.45%) (47037/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 94 | Batch_idx: 390 |  Loss: (0.1066) | Acc: (96.46%) (48231/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4110) | Acc: (38.41%) (3841/10000)\n",
      "Epoch: 95 | Batch_idx: 0 |  Loss: (0.1007) | Acc: (96.88%) (124/128)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 10 |  Loss: (0.1142) | Acc: (96.16%) (1354/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 20 |  Loss: (0.1143) | Acc: (96.21%) (2586/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 30 |  Loss: (0.1141) | Acc: (96.24%) (3819/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 40 |  Loss: (0.1095) | Acc: (96.51%) (5065/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 50 |  Loss: (0.1066) | Acc: (96.49%) (6299/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 60 |  Loss: (0.1043) | Acc: (96.57%) (7540/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 70 |  Loss: (0.1018) | Acc: (96.63%) (8782/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 80 |  Loss: (0.1021) | Acc: (96.60%) (10015/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 90 |  Loss: (0.1004) | Acc: (96.62%) (11254/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 100 |  Loss: (0.1022) | Acc: (96.57%) (12485/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 110 |  Loss: (0.1035) | Acc: (96.57%) (13720/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 120 |  Loss: (0.1037) | Acc: (96.53%) (14950/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 130 |  Loss: (0.1030) | Acc: (96.52%) (16185/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 140 |  Loss: (0.1023) | Acc: (96.55%) (17426/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 150 |  Loss: (0.1037) | Acc: (96.50%) (18652/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 160 |  Loss: (0.1029) | Acc: (96.54%) (19895/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 170 |  Loss: (0.1037) | Acc: (96.55%) (21132/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 180 |  Loss: (0.1043) | Acc: (96.53%) (22363/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 190 |  Loss: (0.1050) | Acc: (96.48%) (23588/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 200 |  Loss: (0.1056) | Acc: (96.46%) (24817/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 210 |  Loss: (0.1057) | Acc: (96.46%) (26052/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 220 |  Loss: (0.1054) | Acc: (96.48%) (27291/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 230 |  Loss: (0.1058) | Acc: (96.46%) (28522/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 240 |  Loss: (0.1056) | Acc: (96.46%) (29756/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 250 |  Loss: (0.1052) | Acc: (96.49%) (30999/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 260 |  Loss: (0.1050) | Acc: (96.49%) (32237/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 270 |  Loss: (0.1050) | Acc: (96.51%) (33478/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 280 |  Loss: (0.1044) | Acc: (96.53%) (34721/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 290 |  Loss: (0.1044) | Acc: (96.53%) (35956/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 300 |  Loss: (0.1040) | Acc: (96.55%) (37200/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 310 |  Loss: (0.1044) | Acc: (96.55%) (38434/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 320 |  Loss: (0.1049) | Acc: (96.52%) (39658/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 330 |  Loss: (0.1051) | Acc: (96.50%) (40885/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 340 |  Loss: (0.1049) | Acc: (96.51%) (42123/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 350 |  Loss: (0.1050) | Acc: (96.51%) (43361/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 360 |  Loss: (0.1052) | Acc: (96.50%) (44592/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 370 |  Loss: (0.1052) | Acc: (96.51%) (45829/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 380 |  Loss: (0.1046) | Acc: (96.53%) (47075/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 95 | Batch_idx: 390 |  Loss: (0.1047) | Acc: (96.52%) (48262/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3811) | Acc: (39.34%) (3934/10000)\n",
      "Epoch: 96 | Batch_idx: 0 |  Loss: (0.0991) | Acc: (96.88%) (124/128)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 10 |  Loss: (0.0867) | Acc: (96.88%) (1364/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 20 |  Loss: (0.0871) | Acc: (96.91%) (2605/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 30 |  Loss: (0.0959) | Acc: (96.72%) (3838/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 40 |  Loss: (0.0939) | Acc: (96.72%) (5076/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 50 |  Loss: (0.0935) | Acc: (96.80%) (6319/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 60 |  Loss: (0.0966) | Acc: (96.73%) (7553/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 70 |  Loss: (0.0948) | Acc: (96.82%) (8799/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 80 |  Loss: (0.0957) | Acc: (96.79%) (10035/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 90 |  Loss: (0.0966) | Acc: (96.78%) (11273/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 100 |  Loss: (0.0967) | Acc: (96.76%) (12509/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 110 |  Loss: (0.0973) | Acc: (96.73%) (13744/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 120 |  Loss: (0.0982) | Acc: (96.71%) (14978/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 130 |  Loss: (0.0982) | Acc: (96.68%) (16212/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 140 |  Loss: (0.0983) | Acc: (96.68%) (17448/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 150 |  Loss: (0.0998) | Acc: (96.64%) (18678/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 160 |  Loss: (0.0996) | Acc: (96.65%) (19918/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 170 |  Loss: (0.0996) | Acc: (96.64%) (21153/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 180 |  Loss: (0.0993) | Acc: (96.69%) (22401/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 190 |  Loss: (0.0999) | Acc: (96.68%) (23637/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 200 |  Loss: (0.1015) | Acc: (96.64%) (24864/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 210 |  Loss: (0.1009) | Acc: (96.66%) (26105/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 220 |  Loss: (0.1018) | Acc: (96.63%) (27334/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 230 |  Loss: (0.1023) | Acc: (96.61%) (28566/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 240 |  Loss: (0.1024) | Acc: (96.60%) (29799/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 250 |  Loss: (0.1024) | Acc: (96.61%) (31039/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 260 |  Loss: (0.1026) | Acc: (96.61%) (32277/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 270 |  Loss: (0.1026) | Acc: (96.61%) (33511/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 280 |  Loss: (0.1029) | Acc: (96.59%) (34743/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 290 |  Loss: (0.1024) | Acc: (96.60%) (35981/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 300 |  Loss: (0.1033) | Acc: (96.57%) (37205/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 310 |  Loss: (0.1035) | Acc: (96.55%) (38436/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 320 |  Loss: (0.1044) | Acc: (96.53%) (39662/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 330 |  Loss: (0.1051) | Acc: (96.50%) (40887/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 340 |  Loss: (0.1044) | Acc: (96.52%) (42129/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 350 |  Loss: (0.1048) | Acc: (96.51%) (43358/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 360 |  Loss: (0.1048) | Acc: (96.50%) (44591/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 370 |  Loss: (0.1047) | Acc: (96.49%) (45821/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 380 |  Loss: (0.1050) | Acc: (96.48%) (47052/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 96 | Batch_idx: 390 |  Loss: (0.1058) | Acc: (96.45%) (48225/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.6454) | Acc: (37.32%) (3732/10000)\n",
      "Epoch: 97 | Batch_idx: 0 |  Loss: (0.0459) | Acc: (98.44%) (126/128)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 10 |  Loss: (0.0823) | Acc: (97.59%) (1374/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 20 |  Loss: (0.0844) | Acc: (97.32%) (2616/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 30 |  Loss: (0.0916) | Acc: (96.90%) (3845/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 40 |  Loss: (0.0861) | Acc: (97.12%) (5097/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 50 |  Loss: (0.0900) | Acc: (96.88%) (6324/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 60 |  Loss: (0.0941) | Acc: (96.77%) (7556/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 70 |  Loss: (0.0966) | Acc: (96.76%) (8794/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 80 |  Loss: (0.0962) | Acc: (96.80%) (10036/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 90 |  Loss: (0.0997) | Acc: (96.73%) (11267/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 100 |  Loss: (0.0991) | Acc: (96.72%) (12504/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 110 |  Loss: (0.0989) | Acc: (96.72%) (13742/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 120 |  Loss: (0.0983) | Acc: (96.71%) (14978/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 130 |  Loss: (0.0980) | Acc: (96.73%) (16220/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 140 |  Loss: (0.0991) | Acc: (96.71%) (17454/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 150 |  Loss: (0.0990) | Acc: (96.68%) (18686/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 160 |  Loss: (0.0977) | Acc: (96.72%) (19933/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 170 |  Loss: (0.0992) | Acc: (96.65%) (21154/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 180 |  Loss: (0.0985) | Acc: (96.68%) (22398/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 190 |  Loss: (0.0995) | Acc: (96.65%) (23630/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 200 |  Loss: (0.0990) | Acc: (96.67%) (24870/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 210 |  Loss: (0.0990) | Acc: (96.67%) (26108/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 220 |  Loss: (0.0994) | Acc: (96.65%) (27341/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 230 |  Loss: (0.0986) | Acc: (96.69%) (28588/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 240 |  Loss: (0.0983) | Acc: (96.69%) (29828/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 250 |  Loss: (0.0985) | Acc: (96.67%) (31057/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 260 |  Loss: (0.0980) | Acc: (96.69%) (32303/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 270 |  Loss: (0.0980) | Acc: (96.69%) (33540/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 280 |  Loss: (0.0982) | Acc: (96.68%) (34773/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 290 |  Loss: (0.0979) | Acc: (96.67%) (36007/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 300 |  Loss: (0.0977) | Acc: (96.67%) (37245/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 310 |  Loss: (0.0983) | Acc: (96.65%) (38474/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 320 |  Loss: (0.0988) | Acc: (96.63%) (39702/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 330 |  Loss: (0.0995) | Acc: (96.61%) (40930/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 340 |  Loss: (0.1000) | Acc: (96.60%) (42162/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 350 |  Loss: (0.0995) | Acc: (96.61%) (43403/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 360 |  Loss: (0.0991) | Acc: (96.61%) (44640/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 370 |  Loss: (0.0991) | Acc: (96.61%) (45878/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 380 |  Loss: (0.0988) | Acc: (96.62%) (47119/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 97 | Batch_idx: 390 |  Loss: (0.0990) | Acc: (96.61%) (48306/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.6006) | Acc: (37.53%) (3753/10000)\n",
      "Epoch: 98 | Batch_idx: 0 |  Loss: (0.1110) | Acc: (96.09%) (123/128)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 10 |  Loss: (0.0966) | Acc: (96.59%) (1360/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 20 |  Loss: (0.1021) | Acc: (96.47%) (2593/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 30 |  Loss: (0.1026) | Acc: (96.35%) (3823/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 40 |  Loss: (0.0987) | Acc: (96.46%) (5062/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 50 |  Loss: (0.1004) | Acc: (96.46%) (6297/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 60 |  Loss: (0.1020) | Acc: (96.44%) (7530/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 70 |  Loss: (0.1018) | Acc: (96.46%) (8766/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 80 |  Loss: (0.1040) | Acc: (96.39%) (9994/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 90 |  Loss: (0.1032) | Acc: (96.41%) (11230/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 100 |  Loss: (0.1037) | Acc: (96.39%) (12461/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 110 |  Loss: (0.1042) | Acc: (96.35%) (13689/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 120 |  Loss: (0.1029) | Acc: (96.41%) (14932/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 130 |  Loss: (0.1029) | Acc: (96.39%) (16163/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 140 |  Loss: (0.1038) | Acc: (96.38%) (17394/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 150 |  Loss: (0.1033) | Acc: (96.43%) (18638/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 160 |  Loss: (0.1027) | Acc: (96.45%) (19877/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 170 |  Loss: (0.1038) | Acc: (96.42%) (21104/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 180 |  Loss: (0.1033) | Acc: (96.43%) (22341/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 190 |  Loss: (0.1035) | Acc: (96.40%) (23569/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 200 |  Loss: (0.1036) | Acc: (96.43%) (24809/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 210 |  Loss: (0.1031) | Acc: (96.46%) (26051/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 220 |  Loss: (0.1032) | Acc: (96.45%) (27284/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 230 |  Loss: (0.1029) | Acc: (96.48%) (28526/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 240 |  Loss: (0.1028) | Acc: (96.48%) (29763/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 250 |  Loss: (0.1023) | Acc: (96.52%) (31011/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 260 |  Loss: (0.1020) | Acc: (96.51%) (32242/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 270 |  Loss: (0.1022) | Acc: (96.51%) (33476/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 280 |  Loss: (0.1026) | Acc: (96.48%) (34701/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 290 |  Loss: (0.1026) | Acc: (96.47%) (35932/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 300 |  Loss: (0.1026) | Acc: (96.50%) (37178/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 310 |  Loss: (0.1027) | Acc: (96.48%) (38406/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 320 |  Loss: (0.1020) | Acc: (96.51%) (39653/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 330 |  Loss: (0.1021) | Acc: (96.52%) (40893/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 340 |  Loss: (0.1021) | Acc: (96.51%) (42125/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 350 |  Loss: (0.1021) | Acc: (96.52%) (43364/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 360 |  Loss: (0.1022) | Acc: (96.51%) (44594/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 370 |  Loss: (0.1025) | Acc: (96.50%) (45827/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 380 |  Loss: (0.1019) | Acc: (96.53%) (47076/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 98 | Batch_idx: 390 |  Loss: (0.1018) | Acc: (96.53%) (48266/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4508) | Acc: (38.51%) (3851/10000)\n",
      "Epoch: 99 | Batch_idx: 0 |  Loss: (0.1228) | Acc: (96.09%) (123/128)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 10 |  Loss: (0.0898) | Acc: (96.95%) (1365/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 20 |  Loss: (0.0897) | Acc: (97.10%) (2610/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 30 |  Loss: (0.0938) | Acc: (96.95%) (3847/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 40 |  Loss: (0.1011) | Acc: (96.74%) (5077/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 50 |  Loss: (0.1001) | Acc: (96.77%) (6317/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 60 |  Loss: (0.1009) | Acc: (96.70%) (7550/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 70 |  Loss: (0.1000) | Acc: (96.68%) (8786/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 80 |  Loss: (0.1009) | Acc: (96.59%) (10014/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 90 |  Loss: (0.1030) | Acc: (96.50%) (11240/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 100 |  Loss: (0.1007) | Acc: (96.57%) (12484/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 110 |  Loss: (0.1036) | Acc: (96.50%) (13711/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 120 |  Loss: (0.1039) | Acc: (96.48%) (14943/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 130 |  Loss: (0.1049) | Acc: (96.46%) (16175/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 140 |  Loss: (0.1042) | Acc: (96.48%) (17413/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 150 |  Loss: (0.1034) | Acc: (96.53%) (18657/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 160 |  Loss: (0.1024) | Acc: (96.60%) (19908/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 170 |  Loss: (0.1020) | Acc: (96.60%) (21144/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 180 |  Loss: (0.1014) | Acc: (96.63%) (22387/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 190 |  Loss: (0.1004) | Acc: (96.66%) (23631/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 200 |  Loss: (0.1017) | Acc: (96.61%) (24856/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 210 |  Loss: (0.1012) | Acc: (96.62%) (26094/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 220 |  Loss: (0.1016) | Acc: (96.61%) (27328/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 230 |  Loss: (0.1015) | Acc: (96.61%) (28566/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 240 |  Loss: (0.1026) | Acc: (96.57%) (29791/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 250 |  Loss: (0.1027) | Acc: (96.56%) (31022/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 260 |  Loss: (0.1024) | Acc: (96.57%) (32262/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 270 |  Loss: (0.1025) | Acc: (96.56%) (33496/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 280 |  Loss: (0.1031) | Acc: (96.54%) (34724/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 290 |  Loss: (0.1045) | Acc: (96.48%) (35936/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 300 |  Loss: (0.1044) | Acc: (96.49%) (37174/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 310 |  Loss: (0.1045) | Acc: (96.46%) (38400/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 320 |  Loss: (0.1047) | Acc: (96.45%) (39629/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 330 |  Loss: (0.1042) | Acc: (96.47%) (40873/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 340 |  Loss: (0.1039) | Acc: (96.50%) (42120/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 350 |  Loss: (0.1041) | Acc: (96.49%) (43350/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 360 |  Loss: (0.1039) | Acc: (96.49%) (44585/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 370 |  Loss: (0.1037) | Acc: (96.49%) (45821/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 380 |  Loss: (0.1037) | Acc: (96.49%) (47056/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 99 | Batch_idx: 390 |  Loss: (0.1036) | Acc: (96.49%) (48245/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.5141) | Acc: (38.94%) (3894/10000)\n",
      "Epoch: 100 | Batch_idx: 0 |  Loss: (0.1135) | Acc: (97.66%) (125/128)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 10 |  Loss: (0.0925) | Acc: (97.09%) (1367/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 20 |  Loss: (0.0950) | Acc: (97.06%) (2609/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 30 |  Loss: (0.0975) | Acc: (96.98%) (3848/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 40 |  Loss: (0.0980) | Acc: (96.93%) (5087/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 50 |  Loss: (0.0980) | Acc: (96.86%) (6323/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 60 |  Loss: (0.0980) | Acc: (96.80%) (7558/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 70 |  Loss: (0.0996) | Acc: (96.83%) (8800/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 80 |  Loss: (0.0991) | Acc: (96.86%) (10042/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 90 |  Loss: (0.0988) | Acc: (96.88%) (11284/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 100 |  Loss: (0.1015) | Acc: (96.82%) (12517/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 110 |  Loss: (0.1018) | Acc: (96.81%) (13755/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 120 |  Loss: (0.1016) | Acc: (96.79%) (14991/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 130 |  Loss: (0.1016) | Acc: (96.76%) (16225/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 140 |  Loss: (0.1014) | Acc: (96.75%) (17462/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 150 |  Loss: (0.1028) | Acc: (96.70%) (18690/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 160 |  Loss: (0.1018) | Acc: (96.71%) (19931/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 170 |  Loss: (0.1019) | Acc: (96.69%) (21164/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 180 |  Loss: (0.1020) | Acc: (96.69%) (22400/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 190 |  Loss: (0.1020) | Acc: (96.68%) (23636/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 200 |  Loss: (0.1031) | Acc: (96.63%) (24860/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 210 |  Loss: (0.1030) | Acc: (96.63%) (26097/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 220 |  Loss: (0.1025) | Acc: (96.66%) (27342/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 230 |  Loss: (0.1024) | Acc: (96.67%) (28582/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 240 |  Loss: (0.1021) | Acc: (96.69%) (29828/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 250 |  Loss: (0.1027) | Acc: (96.68%) (31060/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 260 |  Loss: (0.1019) | Acc: (96.69%) (32302/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 270 |  Loss: (0.1015) | Acc: (96.68%) (33538/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 280 |  Loss: (0.1022) | Acc: (96.66%) (34767/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 290 |  Loss: (0.1017) | Acc: (96.68%) (36013/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 300 |  Loss: (0.1013) | Acc: (96.69%) (37251/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 310 |  Loss: (0.1017) | Acc: (96.66%) (38480/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 320 |  Loss: (0.1016) | Acc: (96.66%) (39717/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 330 |  Loss: (0.1016) | Acc: (96.65%) (40950/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 340 |  Loss: (0.1017) | Acc: (96.64%) (42181/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 350 |  Loss: (0.1018) | Acc: (96.63%) (43413/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 360 |  Loss: (0.1025) | Acc: (96.60%) (44639/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 370 |  Loss: (0.1023) | Acc: (96.60%) (45875/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 380 |  Loss: (0.1026) | Acc: (96.57%) (47097/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 100 | Batch_idx: 390 |  Loss: (0.1030) | Acc: (96.56%) (48279/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4718) | Acc: (39.06%) (3906/10000)\n",
      "Epoch: 101 | Batch_idx: 0 |  Loss: (0.0883) | Acc: (96.09%) (123/128)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 10 |  Loss: (0.0981) | Acc: (96.16%) (1354/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 20 |  Loss: (0.0922) | Acc: (96.80%) (2602/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 30 |  Loss: (0.0964) | Acc: (96.52%) (3830/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 40 |  Loss: (0.0965) | Acc: (96.51%) (5065/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 50 |  Loss: (0.1013) | Acc: (96.37%) (6291/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 60 |  Loss: (0.1009) | Acc: (96.44%) (7530/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 70 |  Loss: (0.0995) | Acc: (96.48%) (8768/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 80 |  Loss: (0.1029) | Acc: (96.45%) (10000/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 90 |  Loss: (0.1020) | Acc: (96.54%) (11245/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 100 |  Loss: (0.1011) | Acc: (96.58%) (12486/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 110 |  Loss: (0.1028) | Acc: (96.56%) (13719/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 120 |  Loss: (0.1046) | Acc: (96.47%) (14942/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 130 |  Loss: (0.1033) | Acc: (96.52%) (16184/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 140 |  Loss: (0.1021) | Acc: (96.59%) (17433/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 150 |  Loss: (0.1027) | Acc: (96.53%) (18658/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 160 |  Loss: (0.1040) | Acc: (96.50%) (19887/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 170 |  Loss: (0.1028) | Acc: (96.56%) (21134/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 180 |  Loss: (0.1035) | Acc: (96.54%) (22367/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 190 |  Loss: (0.1035) | Acc: (96.53%) (23600/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 200 |  Loss: (0.1033) | Acc: (96.53%) (24836/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 210 |  Loss: (0.1037) | Acc: (96.53%) (26070/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 220 |  Loss: (0.1032) | Acc: (96.57%) (27319/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 230 |  Loss: (0.1031) | Acc: (96.57%) (28553/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 240 |  Loss: (0.1028) | Acc: (96.59%) (29795/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 250 |  Loss: (0.1023) | Acc: (96.59%) (31034/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 260 |  Loss: (0.1028) | Acc: (96.58%) (32267/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 270 |  Loss: (0.1024) | Acc: (96.60%) (33507/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 280 |  Loss: (0.1027) | Acc: (96.58%) (34738/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 290 |  Loss: (0.1028) | Acc: (96.57%) (35972/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 300 |  Loss: (0.1028) | Acc: (96.58%) (37210/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 310 |  Loss: (0.1037) | Acc: (96.54%) (38432/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 320 |  Loss: (0.1032) | Acc: (96.56%) (39673/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 330 |  Loss: (0.1026) | Acc: (96.60%) (40926/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 340 |  Loss: (0.1021) | Acc: (96.60%) (42166/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 350 |  Loss: (0.1020) | Acc: (96.61%) (43403/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 360 |  Loss: (0.1023) | Acc: (96.59%) (44634/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 370 |  Loss: (0.1025) | Acc: (96.58%) (45866/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 380 |  Loss: (0.1031) | Acc: (96.55%) (47087/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 101 | Batch_idx: 390 |  Loss: (0.1029) | Acc: (96.56%) (48278/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4158) | Acc: (40.44%) (4044/10000)\n",
      "Epoch: 102 | Batch_idx: 0 |  Loss: (0.0648) | Acc: (97.66%) (125/128)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 10 |  Loss: (0.1058) | Acc: (95.81%) (1349/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 20 |  Loss: (0.1104) | Acc: (95.68%) (2572/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 30 |  Loss: (0.1196) | Acc: (95.77%) (3800/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 40 |  Loss: (0.1160) | Acc: (95.90%) (5033/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 50 |  Loss: (0.1141) | Acc: (95.89%) (6260/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 60 |  Loss: (0.1097) | Acc: (96.16%) (7508/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 70 |  Loss: (0.1099) | Acc: (96.17%) (8740/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 80 |  Loss: (0.1088) | Acc: (96.25%) (9979/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 90 |  Loss: (0.1113) | Acc: (96.16%) (11201/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 100 |  Loss: (0.1093) | Acc: (96.20%) (12437/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 110 |  Loss: (0.1086) | Acc: (96.19%) (13666/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 120 |  Loss: (0.1069) | Acc: (96.27%) (14911/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 130 |  Loss: (0.1069) | Acc: (96.24%) (16137/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 140 |  Loss: (0.1065) | Acc: (96.28%) (17376/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 150 |  Loss: (0.1056) | Acc: (96.32%) (18616/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 160 |  Loss: (0.1047) | Acc: (96.33%) (19852/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 170 |  Loss: (0.1039) | Acc: (96.35%) (21089/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 180 |  Loss: (0.1050) | Acc: (96.31%) (22312/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 190 |  Loss: (0.1047) | Acc: (96.33%) (23551/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 200 |  Loss: (0.1040) | Acc: (96.35%) (24789/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 210 |  Loss: (0.1048) | Acc: (96.29%) (26006/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 220 |  Loss: (0.1043) | Acc: (96.30%) (27241/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 230 |  Loss: (0.1050) | Acc: (96.27%) (28464/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 240 |  Loss: (0.1044) | Acc: (96.29%) (29702/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 250 |  Loss: (0.1041) | Acc: (96.30%) (30939/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 260 |  Loss: (0.1041) | Acc: (96.31%) (32174/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 270 |  Loss: (0.1038) | Acc: (96.31%) (33407/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 280 |  Loss: (0.1032) | Acc: (96.32%) (34643/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 290 |  Loss: (0.1027) | Acc: (96.33%) (35880/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 300 |  Loss: (0.1026) | Acc: (96.33%) (37115/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 310 |  Loss: (0.1032) | Acc: (96.29%) (38333/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 320 |  Loss: (0.1032) | Acc: (96.31%) (39572/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 330 |  Loss: (0.1034) | Acc: (96.32%) (40807/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 340 |  Loss: (0.1030) | Acc: (96.33%) (42048/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 350 |  Loss: (0.1032) | Acc: (96.33%) (43278/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 360 |  Loss: (0.1031) | Acc: (96.33%) (44510/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 370 |  Loss: (0.1034) | Acc: (96.32%) (45739/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 380 |  Loss: (0.1031) | Acc: (96.33%) (46978/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 102 | Batch_idx: 390 |  Loss: (0.1030) | Acc: (96.33%) (48166/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3591) | Acc: (40.54%) (4054/10000)\n",
      "Epoch: 103 | Batch_idx: 0 |  Loss: (0.0872) | Acc: (96.88%) (124/128)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 10 |  Loss: (0.0917) | Acc: (97.02%) (1366/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 20 |  Loss: (0.0921) | Acc: (97.06%) (2609/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 30 |  Loss: (0.0945) | Acc: (97.00%) (3849/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 40 |  Loss: (0.0954) | Acc: (96.99%) (5090/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 50 |  Loss: (0.0935) | Acc: (97.01%) (6333/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 60 |  Loss: (0.0979) | Acc: (96.77%) (7556/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 70 |  Loss: (0.0990) | Acc: (96.74%) (8792/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 80 |  Loss: (0.0987) | Acc: (96.73%) (10029/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 90 |  Loss: (0.1018) | Acc: (96.61%) (11253/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 100 |  Loss: (0.1016) | Acc: (96.60%) (12488/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 110 |  Loss: (0.1009) | Acc: (96.66%) (13733/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 120 |  Loss: (0.0999) | Acc: (96.67%) (14972/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 130 |  Loss: (0.0999) | Acc: (96.68%) (16212/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 140 |  Loss: (0.1004) | Acc: (96.70%) (17452/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 150 |  Loss: (0.1018) | Acc: (96.64%) (18679/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 160 |  Loss: (0.1016) | Acc: (96.61%) (19910/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 170 |  Loss: (0.1014) | Acc: (96.61%) (21147/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 180 |  Loss: (0.1011) | Acc: (96.62%) (22384/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 190 |  Loss: (0.1012) | Acc: (96.58%) (23612/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 200 |  Loss: (0.1005) | Acc: (96.62%) (24858/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 210 |  Loss: (0.1007) | Acc: (96.61%) (26092/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 220 |  Loss: (0.0997) | Acc: (96.67%) (27346/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 230 |  Loss: (0.0992) | Acc: (96.68%) (28586/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 240 |  Loss: (0.0986) | Acc: (96.70%) (29831/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 250 |  Loss: (0.0990) | Acc: (96.70%) (31068/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 260 |  Loss: (0.0994) | Acc: (96.67%) (32297/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 270 |  Loss: (0.0987) | Acc: (96.70%) (33545/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 280 |  Loss: (0.0982) | Acc: (96.71%) (34786/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 290 |  Loss: (0.0985) | Acc: (96.70%) (36018/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 300 |  Loss: (0.0978) | Acc: (96.71%) (37261/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 310 |  Loss: (0.0975) | Acc: (96.71%) (38499/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 320 |  Loss: (0.0972) | Acc: (96.72%) (39741/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 330 |  Loss: (0.0972) | Acc: (96.73%) (40983/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 340 |  Loss: (0.0970) | Acc: (96.72%) (42217/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 350 |  Loss: (0.0975) | Acc: (96.69%) (43442/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 360 |  Loss: (0.0974) | Acc: (96.70%) (44681/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 370 |  Loss: (0.0979) | Acc: (96.70%) (45919/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 380 |  Loss: (0.0981) | Acc: (96.69%) (47152/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 103 | Batch_idx: 390 |  Loss: (0.0981) | Acc: (96.69%) (48344/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4461) | Acc: (38.87%) (3887/10000)\n",
      "Epoch: 104 | Batch_idx: 0 |  Loss: (0.1416) | Acc: (95.31%) (122/128)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 10 |  Loss: (0.0971) | Acc: (96.88%) (1364/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 20 |  Loss: (0.0980) | Acc: (96.84%) (2603/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 30 |  Loss: (0.1045) | Acc: (96.62%) (3834/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 40 |  Loss: (0.1028) | Acc: (96.61%) (5070/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 50 |  Loss: (0.1024) | Acc: (96.66%) (6310/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 60 |  Loss: (0.1022) | Acc: (96.62%) (7544/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 70 |  Loss: (0.1025) | Acc: (96.57%) (8776/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 80 |  Loss: (0.1016) | Acc: (96.65%) (10021/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 90 |  Loss: (0.1004) | Acc: (96.65%) (11258/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 100 |  Loss: (0.1016) | Acc: (96.63%) (12492/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 110 |  Loss: (0.1004) | Acc: (96.64%) (13731/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 120 |  Loss: (0.0995) | Acc: (96.66%) (14970/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 130 |  Loss: (0.0996) | Acc: (96.65%) (16206/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 140 |  Loss: (0.0984) | Acc: (96.69%) (17451/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 150 |  Loss: (0.0998) | Acc: (96.67%) (18685/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 160 |  Loss: (0.0995) | Acc: (96.69%) (19926/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 170 |  Loss: (0.1004) | Acc: (96.68%) (21161/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 180 |  Loss: (0.1005) | Acc: (96.68%) (22398/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 190 |  Loss: (0.1017) | Acc: (96.65%) (23628/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 200 |  Loss: (0.1013) | Acc: (96.65%) (24867/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 210 |  Loss: (0.1010) | Acc: (96.66%) (26106/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 220 |  Loss: (0.1009) | Acc: (96.65%) (27340/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 230 |  Loss: (0.1008) | Acc: (96.64%) (28575/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 240 |  Loss: (0.1006) | Acc: (96.64%) (29812/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 250 |  Loss: (0.1005) | Acc: (96.64%) (31050/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 260 |  Loss: (0.1006) | Acc: (96.64%) (32284/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 270 |  Loss: (0.1004) | Acc: (96.64%) (33524/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 280 |  Loss: (0.1010) | Acc: (96.62%) (34752/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 290 |  Loss: (0.1010) | Acc: (96.62%) (35989/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 300 |  Loss: (0.1001) | Acc: (96.64%) (37235/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 310 |  Loss: (0.1001) | Acc: (96.65%) (38474/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 320 |  Loss: (0.0995) | Acc: (96.66%) (39715/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 330 |  Loss: (0.0997) | Acc: (96.66%) (40951/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 340 |  Loss: (0.0999) | Acc: (96.64%) (42183/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 350 |  Loss: (0.0999) | Acc: (96.65%) (43424/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 360 |  Loss: (0.1002) | Acc: (96.64%) (44656/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 370 |  Loss: (0.1009) | Acc: (96.62%) (45885/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 380 |  Loss: (0.1011) | Acc: (96.60%) (47112/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 104 | Batch_idx: 390 |  Loss: (0.1013) | Acc: (96.59%) (48297/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.5672) | Acc: (38.20%) (3820/10000)\n",
      "Epoch: 105 | Batch_idx: 0 |  Loss: (0.1147) | Acc: (96.09%) (123/128)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 10 |  Loss: (0.1157) | Acc: (96.16%) (1354/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 20 |  Loss: (0.1105) | Acc: (96.50%) (2594/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 30 |  Loss: (0.1091) | Acc: (96.40%) (3825/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 40 |  Loss: (0.1069) | Acc: (96.49%) (5064/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 50 |  Loss: (0.1052) | Acc: (96.58%) (6305/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 60 |  Loss: (0.1079) | Acc: (96.43%) (7529/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 70 |  Loss: (0.1062) | Acc: (96.52%) (8772/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 80 |  Loss: (0.1048) | Acc: (96.52%) (10007/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 90 |  Loss: (0.1017) | Acc: (96.69%) (11262/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 100 |  Loss: (0.1015) | Acc: (96.63%) (12492/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 110 |  Loss: (0.1012) | Acc: (96.68%) (13736/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 120 |  Loss: (0.1021) | Acc: (96.60%) (14961/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 130 |  Loss: (0.1027) | Acc: (96.58%) (16195/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 140 |  Loss: (0.1022) | Acc: (96.61%) (17436/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 150 |  Loss: (0.1029) | Acc: (96.58%) (18667/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 160 |  Loss: (0.1030) | Acc: (96.60%) (19907/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 170 |  Loss: (0.1031) | Acc: (96.58%) (21140/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 180 |  Loss: (0.1030) | Acc: (96.59%) (22377/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 190 |  Loss: (0.1026) | Acc: (96.57%) (23610/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 200 |  Loss: (0.1035) | Acc: (96.54%) (24839/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 210 |  Loss: (0.1020) | Acc: (96.57%) (26082/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 220 |  Loss: (0.1021) | Acc: (96.57%) (27319/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 230 |  Loss: (0.1020) | Acc: (96.57%) (28554/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 240 |  Loss: (0.1019) | Acc: (96.57%) (29790/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 250 |  Loss: (0.1020) | Acc: (96.56%) (31023/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 260 |  Loss: (0.1028) | Acc: (96.52%) (32244/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 270 |  Loss: (0.1032) | Acc: (96.51%) (33476/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 280 |  Loss: (0.1029) | Acc: (96.52%) (34716/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 290 |  Loss: (0.1026) | Acc: (96.52%) (35953/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 300 |  Loss: (0.1023) | Acc: (96.53%) (37192/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 310 |  Loss: (0.1028) | Acc: (96.52%) (38423/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 320 |  Loss: (0.1025) | Acc: (96.52%) (39658/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 330 |  Loss: (0.1030) | Acc: (96.51%) (40888/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 340 |  Loss: (0.1031) | Acc: (96.50%) (42119/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 350 |  Loss: (0.1033) | Acc: (96.48%) (43348/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 360 |  Loss: (0.1032) | Acc: (96.48%) (44581/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 370 |  Loss: (0.1034) | Acc: (96.48%) (45817/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 380 |  Loss: (0.1031) | Acc: (96.48%) (47051/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 105 | Batch_idx: 390 |  Loss: (0.1029) | Acc: (96.49%) (48244/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4591) | Acc: (39.19%) (3919/10000)\n",
      "Epoch: 106 | Batch_idx: 0 |  Loss: (0.0740) | Acc: (96.88%) (124/128)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 10 |  Loss: (0.1234) | Acc: (95.81%) (1349/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 20 |  Loss: (0.1146) | Acc: (96.13%) (2584/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 30 |  Loss: (0.0986) | Acc: (96.65%) (3835/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 40 |  Loss: (0.1007) | Acc: (96.68%) (5074/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 50 |  Loss: (0.0999) | Acc: (96.69%) (6312/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 60 |  Loss: (0.1054) | Acc: (96.48%) (7533/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 70 |  Loss: (0.1064) | Acc: (96.43%) (8764/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 80 |  Loss: (0.1062) | Acc: (96.43%) (9998/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 90 |  Loss: (0.1068) | Acc: (96.33%) (11221/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 100 |  Loss: (0.1069) | Acc: (96.37%) (12459/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 110 |  Loss: (0.1084) | Acc: (96.35%) (13689/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 120 |  Loss: (0.1094) | Acc: (96.32%) (14918/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 130 |  Loss: (0.1096) | Acc: (96.28%) (16145/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 140 |  Loss: (0.1077) | Acc: (96.35%) (17390/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 150 |  Loss: (0.1073) | Acc: (96.37%) (18627/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 160 |  Loss: (0.1069) | Acc: (96.38%) (19861/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 170 |  Loss: (0.1051) | Acc: (96.43%) (21106/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 180 |  Loss: (0.1040) | Acc: (96.46%) (22349/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 190 |  Loss: (0.1045) | Acc: (96.47%) (23585/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 200 |  Loss: (0.1037) | Acc: (96.49%) (24824/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 210 |  Loss: (0.1034) | Acc: (96.49%) (26059/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 220 |  Loss: (0.1031) | Acc: (96.51%) (27302/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 230 |  Loss: (0.1030) | Acc: (96.51%) (28536/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 240 |  Loss: (0.1031) | Acc: (96.51%) (29771/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 250 |  Loss: (0.1025) | Acc: (96.52%) (31009/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 260 |  Loss: (0.1025) | Acc: (96.51%) (32243/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 270 |  Loss: (0.1029) | Acc: (96.51%) (33478/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 280 |  Loss: (0.1028) | Acc: (96.50%) (34708/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 290 |  Loss: (0.1023) | Acc: (96.53%) (35955/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 300 |  Loss: (0.1022) | Acc: (96.56%) (37203/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 310 |  Loss: (0.1018) | Acc: (96.58%) (38447/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 320 |  Loss: (0.1026) | Acc: (96.56%) (39673/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 330 |  Loss: (0.1022) | Acc: (96.58%) (40917/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 340 |  Loss: (0.1018) | Acc: (96.60%) (42165/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 350 |  Loss: (0.1016) | Acc: (96.61%) (43406/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 360 |  Loss: (0.1012) | Acc: (96.62%) (44647/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 370 |  Loss: (0.1008) | Acc: (96.63%) (45886/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 380 |  Loss: (0.1007) | Acc: (96.64%) (47129/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 106 | Batch_idx: 390 |  Loss: (0.1006) | Acc: (96.64%) (48318/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4719) | Acc: (38.96%) (3896/10000)\n",
      "Epoch: 107 | Batch_idx: 0 |  Loss: (0.0786) | Acc: (96.88%) (124/128)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 10 |  Loss: (0.1098) | Acc: (96.16%) (1354/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 20 |  Loss: (0.1077) | Acc: (96.35%) (2590/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 30 |  Loss: (0.1011) | Acc: (96.72%) (3838/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 40 |  Loss: (0.1012) | Acc: (96.67%) (5073/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 50 |  Loss: (0.0996) | Acc: (96.74%) (6315/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 60 |  Loss: (0.0990) | Acc: (96.59%) (7542/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 70 |  Loss: (0.0991) | Acc: (96.53%) (8773/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 80 |  Loss: (0.1010) | Acc: (96.50%) (10005/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 90 |  Loss: (0.1014) | Acc: (96.51%) (11242/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 100 |  Loss: (0.1022) | Acc: (96.47%) (12472/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 110 |  Loss: (0.1012) | Acc: (96.50%) (13711/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 120 |  Loss: (0.1011) | Acc: (96.49%) (14944/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 130 |  Loss: (0.1013) | Acc: (96.48%) (16178/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 140 |  Loss: (0.1005) | Acc: (96.54%) (17424/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 150 |  Loss: (0.1004) | Acc: (96.54%) (18660/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 160 |  Loss: (0.0988) | Acc: (96.59%) (19905/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 170 |  Loss: (0.0988) | Acc: (96.58%) (21140/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 180 |  Loss: (0.0987) | Acc: (96.58%) (22376/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 190 |  Loss: (0.0991) | Acc: (96.56%) (23608/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 200 |  Loss: (0.0989) | Acc: (96.56%) (24844/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 210 |  Loss: (0.0989) | Acc: (96.57%) (26081/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 220 |  Loss: (0.0985) | Acc: (96.59%) (27322/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 230 |  Loss: (0.0987) | Acc: (96.59%) (28559/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 240 |  Loss: (0.0986) | Acc: (96.58%) (29792/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 250 |  Loss: (0.0990) | Acc: (96.56%) (31022/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 260 |  Loss: (0.0994) | Acc: (96.54%) (32253/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 270 |  Loss: (0.0998) | Acc: (96.52%) (33482/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 280 |  Loss: (0.0999) | Acc: (96.54%) (34724/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 290 |  Loss: (0.0988) | Acc: (96.58%) (35973/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 300 |  Loss: (0.0992) | Acc: (96.58%) (37209/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 310 |  Loss: (0.0990) | Acc: (96.58%) (38447/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 320 |  Loss: (0.0994) | Acc: (96.59%) (39685/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 330 |  Loss: (0.0998) | Acc: (96.56%) (40912/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 340 |  Loss: (0.0993) | Acc: (96.58%) (42156/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 350 |  Loss: (0.0997) | Acc: (96.58%) (43390/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 360 |  Loss: (0.0995) | Acc: (96.59%) (44632/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 370 |  Loss: (0.0998) | Acc: (96.57%) (45861/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 380 |  Loss: (0.1000) | Acc: (96.58%) (47100/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 107 | Batch_idx: 390 |  Loss: (0.1000) | Acc: (96.58%) (48288/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4545) | Acc: (39.15%) (3915/10000)\n",
      "Epoch: 108 | Batch_idx: 0 |  Loss: (0.1063) | Acc: (96.88%) (124/128)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 10 |  Loss: (0.0842) | Acc: (97.09%) (1367/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 20 |  Loss: (0.1026) | Acc: (96.54%) (2595/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 30 |  Loss: (0.0980) | Acc: (96.67%) (3836/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 40 |  Loss: (0.0989) | Acc: (96.53%) (5066/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 50 |  Loss: (0.0962) | Acc: (96.66%) (6310/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 60 |  Loss: (0.0955) | Acc: (96.68%) (7549/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 70 |  Loss: (0.0959) | Acc: (96.71%) (8789/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 80 |  Loss: (0.0966) | Acc: (96.72%) (10028/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 90 |  Loss: (0.0947) | Acc: (96.81%) (11277/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 100 |  Loss: (0.0926) | Acc: (96.84%) (12519/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 110 |  Loss: (0.0922) | Acc: (96.90%) (13768/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 120 |  Loss: (0.0927) | Acc: (96.88%) (15005/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 130 |  Loss: (0.0939) | Acc: (96.86%) (16241/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 140 |  Loss: (0.0941) | Acc: (96.85%) (17479/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 150 |  Loss: (0.0941) | Acc: (96.83%) (18715/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 160 |  Loss: (0.0949) | Acc: (96.81%) (19951/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 170 |  Loss: (0.0954) | Acc: (96.81%) (21190/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 180 |  Loss: (0.0957) | Acc: (96.80%) (22426/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 190 |  Loss: (0.0961) | Acc: (96.77%) (23658/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 200 |  Loss: (0.0964) | Acc: (96.75%) (24892/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 210 |  Loss: (0.0964) | Acc: (96.75%) (26130/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 220 |  Loss: (0.0960) | Acc: (96.75%) (27370/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 230 |  Loss: (0.0964) | Acc: (96.73%) (28602/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 240 |  Loss: (0.0963) | Acc: (96.73%) (29840/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 250 |  Loss: (0.0960) | Acc: (96.74%) (31082/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 260 |  Loss: (0.0968) | Acc: (96.74%) (32319/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 270 |  Loss: (0.0974) | Acc: (96.72%) (33551/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 280 |  Loss: (0.0974) | Acc: (96.72%) (34790/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 290 |  Loss: (0.0987) | Acc: (96.68%) (36011/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 300 |  Loss: (0.0983) | Acc: (96.69%) (37251/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 310 |  Loss: (0.0980) | Acc: (96.69%) (38490/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 320 |  Loss: (0.0980) | Acc: (96.69%) (39729/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 330 |  Loss: (0.0984) | Acc: (96.68%) (40962/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 340 |  Loss: (0.0984) | Acc: (96.67%) (42193/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 350 |  Loss: (0.0988) | Acc: (96.63%) (43415/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 360 |  Loss: (0.0985) | Acc: (96.66%) (44663/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 370 |  Loss: (0.0978) | Acc: (96.68%) (45912/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 380 |  Loss: (0.0977) | Acc: (96.68%) (47150/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 108 | Batch_idx: 390 |  Loss: (0.0983) | Acc: (96.66%) (48330/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.6538) | Acc: (36.57%) (3657/10000)\n",
      "Epoch: 109 | Batch_idx: 0 |  Loss: (0.0804) | Acc: (96.09%) (123/128)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 10 |  Loss: (0.1091) | Acc: (96.52%) (1359/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 20 |  Loss: (0.1051) | Acc: (96.39%) (2591/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 30 |  Loss: (0.1065) | Acc: (96.37%) (3824/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 40 |  Loss: (0.1033) | Acc: (96.46%) (5062/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 50 |  Loss: (0.1048) | Acc: (96.42%) (6294/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 60 |  Loss: (0.1002) | Acc: (96.57%) (7540/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 70 |  Loss: (0.0990) | Acc: (96.60%) (8779/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 80 |  Loss: (0.0980) | Acc: (96.65%) (10021/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 90 |  Loss: (0.0992) | Acc: (96.66%) (11259/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 100 |  Loss: (0.0967) | Acc: (96.79%) (12513/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 110 |  Loss: (0.0963) | Acc: (96.83%) (13758/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 120 |  Loss: (0.0971) | Acc: (96.78%) (14990/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 130 |  Loss: (0.0966) | Acc: (96.82%) (16234/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 140 |  Loss: (0.0969) | Acc: (96.81%) (17473/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 150 |  Loss: (0.0982) | Acc: (96.79%) (18708/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 160 |  Loss: (0.0989) | Acc: (96.74%) (19936/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 170 |  Loss: (0.0993) | Acc: (96.74%) (21174/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 180 |  Loss: (0.0990) | Acc: (96.75%) (22414/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 190 |  Loss: (0.0997) | Acc: (96.72%) (23645/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 200 |  Loss: (0.1004) | Acc: (96.69%) (24876/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 210 |  Loss: (0.0994) | Acc: (96.72%) (26122/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 220 |  Loss: (0.0992) | Acc: (96.75%) (27369/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 230 |  Loss: (0.0987) | Acc: (96.77%) (28613/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 240 |  Loss: (0.0984) | Acc: (96.76%) (29849/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 250 |  Loss: (0.0988) | Acc: (96.74%) (31080/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 260 |  Loss: (0.0995) | Acc: (96.71%) (32308/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 270 |  Loss: (0.1000) | Acc: (96.67%) (33533/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 280 |  Loss: (0.1001) | Acc: (96.66%) (34765/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 290 |  Loss: (0.1002) | Acc: (96.67%) (36007/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 300 |  Loss: (0.0999) | Acc: (96.66%) (37242/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 310 |  Loss: (0.0998) | Acc: (96.68%) (38486/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 320 |  Loss: (0.0995) | Acc: (96.69%) (39727/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 330 |  Loss: (0.0995) | Acc: (96.68%) (40960/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 340 |  Loss: (0.0992) | Acc: (96.68%) (42201/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 350 |  Loss: (0.0994) | Acc: (96.68%) (43438/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 360 |  Loss: (0.0994) | Acc: (96.67%) (44669/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 370 |  Loss: (0.0995) | Acc: (96.67%) (45908/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 380 |  Loss: (0.0996) | Acc: (96.67%) (47145/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 109 | Batch_idx: 390 |  Loss: (0.0995) | Acc: (96.68%) (48341/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.5432) | Acc: (38.71%) (3871/10000)\n",
      "Epoch: 110 | Batch_idx: 0 |  Loss: (0.1266) | Acc: (97.66%) (125/128)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 10 |  Loss: (0.1105) | Acc: (96.59%) (1360/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 20 |  Loss: (0.0970) | Acc: (96.99%) (2607/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 30 |  Loss: (0.0991) | Acc: (96.95%) (3847/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 40 |  Loss: (0.0971) | Acc: (96.93%) (5087/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 50 |  Loss: (0.0973) | Acc: (96.86%) (6323/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 60 |  Loss: (0.1003) | Acc: (96.68%) (7549/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 70 |  Loss: (0.1016) | Acc: (96.59%) (8778/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 80 |  Loss: (0.0999) | Acc: (96.65%) (10021/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 90 |  Loss: (0.1002) | Acc: (96.65%) (11258/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 100 |  Loss: (0.0995) | Acc: (96.66%) (12496/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 110 |  Loss: (0.1001) | Acc: (96.65%) (13732/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 120 |  Loss: (0.0983) | Acc: (96.68%) (14974/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 130 |  Loss: (0.0964) | Acc: (96.75%) (16223/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 140 |  Loss: (0.0942) | Acc: (96.82%) (17474/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 150 |  Loss: (0.0956) | Acc: (96.76%) (18701/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 160 |  Loss: (0.0948) | Acc: (96.77%) (19942/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 170 |  Loss: (0.0946) | Acc: (96.78%) (21184/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 180 |  Loss: (0.0953) | Acc: (96.76%) (22417/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 190 |  Loss: (0.0961) | Acc: (96.76%) (23656/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 200 |  Loss: (0.0963) | Acc: (96.73%) (24886/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 210 |  Loss: (0.0962) | Acc: (96.73%) (26124/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 220 |  Loss: (0.0967) | Acc: (96.69%) (27353/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 230 |  Loss: (0.0971) | Acc: (96.70%) (28593/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 240 |  Loss: (0.0971) | Acc: (96.71%) (29834/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 250 |  Loss: (0.0978) | Acc: (96.69%) (31063/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 260 |  Loss: (0.0969) | Acc: (96.73%) (32314/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 270 |  Loss: (0.0966) | Acc: (96.72%) (33550/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 280 |  Loss: (0.0964) | Acc: (96.73%) (34791/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 290 |  Loss: (0.0959) | Acc: (96.75%) (36036/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 300 |  Loss: (0.0957) | Acc: (96.75%) (37276/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 310 |  Loss: (0.0956) | Acc: (96.74%) (38510/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 320 |  Loss: (0.0954) | Acc: (96.75%) (39752/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 330 |  Loss: (0.0950) | Acc: (96.78%) (41003/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 340 |  Loss: (0.0948) | Acc: (96.77%) (42240/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 350 |  Loss: (0.0946) | Acc: (96.78%) (43483/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 360 |  Loss: (0.0948) | Acc: (96.77%) (44717/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 370 |  Loss: (0.0949) | Acc: (96.77%) (45954/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 380 |  Loss: (0.0950) | Acc: (96.76%) (47186/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 110 | Batch_idx: 390 |  Loss: (0.0942) | Acc: (96.79%) (48394/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.5633) | Acc: (38.44%) (3844/10000)\n",
      "Epoch: 111 | Batch_idx: 0 |  Loss: (0.0853) | Acc: (96.09%) (123/128)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 10 |  Loss: (0.0870) | Acc: (96.66%) (1361/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 20 |  Loss: (0.0867) | Acc: (96.76%) (2601/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 30 |  Loss: (0.0898) | Acc: (96.77%) (3840/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 40 |  Loss: (0.0851) | Acc: (96.97%) (5089/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 50 |  Loss: (0.0875) | Acc: (96.95%) (6329/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 60 |  Loss: (0.0893) | Acc: (96.84%) (7561/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 70 |  Loss: (0.0910) | Acc: (96.79%) (8796/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 80 |  Loss: (0.0914) | Acc: (96.81%) (10037/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 90 |  Loss: (0.0912) | Acc: (96.78%) (11273/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 100 |  Loss: (0.0905) | Acc: (96.77%) (12510/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 110 |  Loss: (0.0894) | Acc: (96.81%) (13755/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 120 |  Loss: (0.0900) | Acc: (96.82%) (14996/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 130 |  Loss: (0.0901) | Acc: (96.84%) (16238/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 140 |  Loss: (0.0910) | Acc: (96.82%) (17474/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 150 |  Loss: (0.0917) | Acc: (96.77%) (18704/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 160 |  Loss: (0.0935) | Acc: (96.70%) (19927/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 170 |  Loss: (0.0946) | Acc: (96.63%) (21150/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 180 |  Loss: (0.0953) | Acc: (96.62%) (22386/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 190 |  Loss: (0.0948) | Acc: (96.61%) (23618/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 200 |  Loss: (0.0957) | Acc: (96.56%) (24842/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 210 |  Loss: (0.0959) | Acc: (96.54%) (26074/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 220 |  Loss: (0.0964) | Acc: (96.54%) (27310/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 230 |  Loss: (0.0961) | Acc: (96.55%) (28547/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 240 |  Loss: (0.0964) | Acc: (96.56%) (29786/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 250 |  Loss: (0.0970) | Acc: (96.55%) (31019/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 260 |  Loss: (0.0961) | Acc: (96.59%) (32268/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 270 |  Loss: (0.0959) | Acc: (96.60%) (33509/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 280 |  Loss: (0.0958) | Acc: (96.62%) (34753/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 290 |  Loss: (0.0964) | Acc: (96.60%) (35982/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 300 |  Loss: (0.0964) | Acc: (96.61%) (37220/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 310 |  Loss: (0.0967) | Acc: (96.60%) (38456/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 320 |  Loss: (0.0969) | Acc: (96.61%) (39696/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 330 |  Loss: (0.0967) | Acc: (96.62%) (40934/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 340 |  Loss: (0.0967) | Acc: (96.61%) (42169/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 350 |  Loss: (0.0968) | Acc: (96.62%) (43408/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 360 |  Loss: (0.0963) | Acc: (96.63%) (44649/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 370 |  Loss: (0.0963) | Acc: (96.64%) (45894/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 380 |  Loss: (0.0970) | Acc: (96.62%) (47122/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 111 | Batch_idx: 390 |  Loss: (0.0969) | Acc: (96.64%) (48320/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4588) | Acc: (39.21%) (3921/10000)\n",
      "Epoch: 112 | Batch_idx: 0 |  Loss: (0.1035) | Acc: (96.09%) (123/128)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 10 |  Loss: (0.0934) | Acc: (96.66%) (1361/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 20 |  Loss: (0.1008) | Acc: (96.39%) (2591/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 30 |  Loss: (0.0931) | Acc: (96.80%) (3841/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 40 |  Loss: (0.0906) | Acc: (96.95%) (5088/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 50 |  Loss: (0.0916) | Acc: (96.84%) (6322/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 60 |  Loss: (0.0930) | Acc: (96.81%) (7559/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 70 |  Loss: (0.0953) | Acc: (96.69%) (8787/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 80 |  Loss: (0.0943) | Acc: (96.74%) (10030/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 90 |  Loss: (0.0939) | Acc: (96.76%) (11271/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 100 |  Loss: (0.0931) | Acc: (96.81%) (12515/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 110 |  Loss: (0.0922) | Acc: (96.82%) (13756/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 120 |  Loss: (0.0921) | Acc: (96.84%) (14998/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 130 |  Loss: (0.0926) | Acc: (96.83%) (16237/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 140 |  Loss: (0.0923) | Acc: (96.86%) (17482/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 150 |  Loss: (0.0924) | Acc: (96.86%) (18721/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 160 |  Loss: (0.0918) | Acc: (96.88%) (19966/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 170 |  Loss: (0.0931) | Acc: (96.84%) (21196/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 180 |  Loss: (0.0941) | Acc: (96.81%) (22428/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 190 |  Loss: (0.0935) | Acc: (96.84%) (23676/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 200 |  Loss: (0.0928) | Acc: (96.88%) (24925/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 210 |  Loss: (0.0935) | Acc: (96.86%) (26159/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 220 |  Loss: (0.0930) | Acc: (96.89%) (27407/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 230 |  Loss: (0.0929) | Acc: (96.88%) (28645/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 240 |  Loss: (0.0925) | Acc: (96.91%) (29894/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 250 |  Loss: (0.0924) | Acc: (96.92%) (31139/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 260 |  Loss: (0.0924) | Acc: (96.93%) (32383/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 270 |  Loss: (0.0925) | Acc: (96.92%) (33619/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 280 |  Loss: (0.0929) | Acc: (96.90%) (34853/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 290 |  Loss: (0.0928) | Acc: (96.91%) (36097/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 300 |  Loss: (0.0929) | Acc: (96.90%) (37332/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 310 |  Loss: (0.0932) | Acc: (96.88%) (38564/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 320 |  Loss: (0.0936) | Acc: (96.86%) (39798/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 330 |  Loss: (0.0935) | Acc: (96.86%) (41038/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 340 |  Loss: (0.0938) | Acc: (96.85%) (42272/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 350 |  Loss: (0.0939) | Acc: (96.84%) (43510/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 360 |  Loss: (0.0942) | Acc: (96.84%) (44748/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 370 |  Loss: (0.0946) | Acc: (96.81%) (45975/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 380 |  Loss: (0.0947) | Acc: (96.82%) (47215/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 112 | Batch_idx: 390 |  Loss: (0.0947) | Acc: (96.81%) (48407/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4461) | Acc: (38.86%) (3886/10000)\n",
      "Epoch: 113 | Batch_idx: 0 |  Loss: (0.0718) | Acc: (97.66%) (125/128)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 10 |  Loss: (0.1000) | Acc: (96.88%) (1364/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 20 |  Loss: (0.0917) | Acc: (97.14%) (2611/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 30 |  Loss: (0.0968) | Acc: (97.00%) (3849/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 40 |  Loss: (0.0937) | Acc: (97.03%) (5092/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 50 |  Loss: (0.0949) | Acc: (96.92%) (6327/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 60 |  Loss: (0.0940) | Acc: (96.89%) (7565/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 70 |  Loss: (0.0935) | Acc: (96.85%) (8802/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 80 |  Loss: (0.0955) | Acc: (96.79%) (10035/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 90 |  Loss: (0.0966) | Acc: (96.82%) (11278/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 100 |  Loss: (0.0960) | Acc: (96.82%) (12517/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 110 |  Loss: (0.0971) | Acc: (96.77%) (13749/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 120 |  Loss: (0.0985) | Acc: (96.79%) (14991/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 130 |  Loss: (0.0989) | Acc: (96.77%) (16226/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 140 |  Loss: (0.0996) | Acc: (96.71%) (17454/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 150 |  Loss: (0.0990) | Acc: (96.75%) (18700/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 160 |  Loss: (0.0982) | Acc: (96.80%) (19949/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 170 |  Loss: (0.0983) | Acc: (96.79%) (21186/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 180 |  Loss: (0.0990) | Acc: (96.78%) (22421/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 190 |  Loss: (0.0986) | Acc: (96.79%) (23664/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 200 |  Loss: (0.0976) | Acc: (96.83%) (24913/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 210 |  Loss: (0.0973) | Acc: (96.85%) (26157/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 220 |  Loss: (0.0983) | Acc: (96.81%) (27386/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 230 |  Loss: (0.0979) | Acc: (96.82%) (28629/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 240 |  Loss: (0.0979) | Acc: (96.83%) (29869/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 250 |  Loss: (0.0976) | Acc: (96.83%) (31110/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 260 |  Loss: (0.0975) | Acc: (96.84%) (32351/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 270 |  Loss: (0.0975) | Acc: (96.83%) (33588/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 280 |  Loss: (0.0970) | Acc: (96.84%) (34830/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 290 |  Loss: (0.0971) | Acc: (96.83%) (36067/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 300 |  Loss: (0.0971) | Acc: (96.83%) (37305/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 310 |  Loss: (0.0974) | Acc: (96.82%) (38544/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 320 |  Loss: (0.0968) | Acc: (96.85%) (39792/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 330 |  Loss: (0.0965) | Acc: (96.84%) (41030/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 340 |  Loss: (0.0962) | Acc: (96.85%) (42271/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 350 |  Loss: (0.0966) | Acc: (96.83%) (43502/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 360 |  Loss: (0.0961) | Acc: (96.85%) (44753/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 370 |  Loss: (0.0959) | Acc: (96.86%) (45998/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 380 |  Loss: (0.0956) | Acc: (96.86%) (47238/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 113 | Batch_idx: 390 |  Loss: (0.0954) | Acc: (96.87%) (48436/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3794) | Acc: (39.70%) (3970/10000)\n",
      "Epoch: 114 | Batch_idx: 0 |  Loss: (0.1211) | Acc: (96.88%) (124/128)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 10 |  Loss: (0.0964) | Acc: (96.59%) (1360/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 20 |  Loss: (0.0967) | Acc: (96.65%) (2598/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 30 |  Loss: (0.0965) | Acc: (96.65%) (3835/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 40 |  Loss: (0.0921) | Acc: (96.93%) (5087/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 50 |  Loss: (0.0913) | Acc: (96.89%) (6325/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 60 |  Loss: (0.0945) | Acc: (96.71%) (7551/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 70 |  Loss: (0.0937) | Acc: (96.79%) (8796/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 80 |  Loss: (0.0953) | Acc: (96.76%) (10032/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 90 |  Loss: (0.0953) | Acc: (96.73%) (11267/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 100 |  Loss: (0.0948) | Acc: (96.72%) (12504/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 110 |  Loss: (0.0936) | Acc: (96.75%) (13746/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 120 |  Loss: (0.0943) | Acc: (96.74%) (14983/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 130 |  Loss: (0.0941) | Acc: (96.72%) (16218/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 140 |  Loss: (0.0953) | Acc: (96.67%) (17447/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 150 |  Loss: (0.0950) | Acc: (96.69%) (18688/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 160 |  Loss: (0.0962) | Acc: (96.64%) (19916/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 170 |  Loss: (0.0961) | Acc: (96.67%) (21159/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 180 |  Loss: (0.0970) | Acc: (96.64%) (22390/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 190 |  Loss: (0.0975) | Acc: (96.63%) (23624/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 200 |  Loss: (0.0971) | Acc: (96.63%) (24862/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 210 |  Loss: (0.0972) | Acc: (96.62%) (26095/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 220 |  Loss: (0.0974) | Acc: (96.64%) (27338/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 230 |  Loss: (0.0968) | Acc: (96.65%) (28577/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 240 |  Loss: (0.0964) | Acc: (96.66%) (29817/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 250 |  Loss: (0.0974) | Acc: (96.60%) (31037/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 260 |  Loss: (0.0967) | Acc: (96.65%) (32289/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 270 |  Loss: (0.0967) | Acc: (96.64%) (33523/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 280 |  Loss: (0.0968) | Acc: (96.64%) (34761/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 290 |  Loss: (0.0968) | Acc: (96.65%) (36002/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 300 |  Loss: (0.0965) | Acc: (96.68%) (37249/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 310 |  Loss: (0.0967) | Acc: (96.69%) (38490/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 320 |  Loss: (0.0964) | Acc: (96.71%) (39735/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 330 |  Loss: (0.0964) | Acc: (96.71%) (40973/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 340 |  Loss: (0.0962) | Acc: (96.72%) (42217/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 350 |  Loss: (0.0968) | Acc: (96.70%) (43446/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 360 |  Loss: (0.0968) | Acc: (96.70%) (44685/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 370 |  Loss: (0.0964) | Acc: (96.72%) (45931/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 380 |  Loss: (0.0958) | Acc: (96.76%) (47187/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 114 | Batch_idx: 390 |  Loss: (0.0957) | Acc: (96.77%) (48385/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.2980) | Acc: (40.22%) (4022/10000)\n",
      "Epoch: 115 | Batch_idx: 0 |  Loss: (0.1178) | Acc: (95.31%) (122/128)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 10 |  Loss: (0.0931) | Acc: (96.80%) (1363/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 20 |  Loss: (0.0879) | Acc: (96.99%) (2607/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 30 |  Loss: (0.0906) | Acc: (96.77%) (3840/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 40 |  Loss: (0.0935) | Acc: (96.57%) (5068/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 50 |  Loss: (0.0909) | Acc: (96.74%) (6315/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 60 |  Loss: (0.0917) | Acc: (96.73%) (7553/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 70 |  Loss: (0.0921) | Acc: (96.71%) (8789/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 80 |  Loss: (0.0937) | Acc: (96.74%) (10030/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 90 |  Loss: (0.0938) | Acc: (96.72%) (11266/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 100 |  Loss: (0.0944) | Acc: (96.74%) (12507/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 110 |  Loss: (0.0942) | Acc: (96.75%) (13746/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 120 |  Loss: (0.0943) | Acc: (96.75%) (14984/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 130 |  Loss: (0.0954) | Acc: (96.70%) (16214/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 140 |  Loss: (0.0965) | Acc: (96.69%) (17450/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 150 |  Loss: (0.0968) | Acc: (96.69%) (18689/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 160 |  Loss: (0.0960) | Acc: (96.72%) (19932/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 170 |  Loss: (0.0961) | Acc: (96.71%) (21168/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 180 |  Loss: (0.0958) | Acc: (96.72%) (22409/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 190 |  Loss: (0.0955) | Acc: (96.74%) (23650/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 200 |  Loss: (0.0957) | Acc: (96.70%) (24880/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 210 |  Loss: (0.0957) | Acc: (96.70%) (26116/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 220 |  Loss: (0.0949) | Acc: (96.73%) (27363/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 230 |  Loss: (0.0950) | Acc: (96.72%) (28599/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 240 |  Loss: (0.0949) | Acc: (96.71%) (29834/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 250 |  Loss: (0.0950) | Acc: (96.71%) (31072/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 260 |  Loss: (0.0964) | Acc: (96.67%) (32295/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 270 |  Loss: (0.0964) | Acc: (96.67%) (33532/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 280 |  Loss: (0.0972) | Acc: (96.65%) (34763/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 290 |  Loss: (0.0981) | Acc: (96.61%) (35986/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 300 |  Loss: (0.0979) | Acc: (96.61%) (37221/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 310 |  Loss: (0.0983) | Acc: (96.59%) (38452/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 320 |  Loss: (0.0984) | Acc: (96.59%) (39687/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 330 |  Loss: (0.0978) | Acc: (96.61%) (40931/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 340 |  Loss: (0.0974) | Acc: (96.63%) (42177/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 350 |  Loss: (0.0969) | Acc: (96.64%) (43418/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 360 |  Loss: (0.0973) | Acc: (96.63%) (44651/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 370 |  Loss: (0.0975) | Acc: (96.62%) (45881/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 380 |  Loss: (0.0974) | Acc: (96.62%) (47121/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 115 | Batch_idx: 390 |  Loss: (0.0978) | Acc: (96.62%) (48309/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.4769) | Acc: (38.69%) (3869/10000)\n",
      "Epoch: 116 | Batch_idx: 0 |  Loss: (0.1072) | Acc: (96.88%) (124/128)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 10 |  Loss: (0.1079) | Acc: (96.24%) (1355/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 20 |  Loss: (0.0963) | Acc: (96.61%) (2597/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 30 |  Loss: (0.1001) | Acc: (96.52%) (3830/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 40 |  Loss: (0.0946) | Acc: (96.65%) (5072/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 50 |  Loss: (0.0938) | Acc: (96.81%) (6320/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 60 |  Loss: (0.0926) | Acc: (96.84%) (7561/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 70 |  Loss: (0.0927) | Acc: (96.83%) (8800/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 80 |  Loss: (0.0928) | Acc: (96.79%) (10035/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 90 |  Loss: (0.0918) | Acc: (96.83%) (11279/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 100 |  Loss: (0.0925) | Acc: (96.81%) (12515/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 110 |  Loss: (0.0928) | Acc: (96.80%) (13753/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 120 |  Loss: (0.0929) | Acc: (96.85%) (15000/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 130 |  Loss: (0.0933) | Acc: (96.87%) (16243/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 140 |  Loss: (0.0938) | Acc: (96.88%) (17484/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 150 |  Loss: (0.0939) | Acc: (96.84%) (18718/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 160 |  Loss: (0.0940) | Acc: (96.85%) (19958/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 170 |  Loss: (0.0942) | Acc: (96.83%) (21194/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 180 |  Loss: (0.0956) | Acc: (96.78%) (22423/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 190 |  Loss: (0.0956) | Acc: (96.79%) (23664/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 200 |  Loss: (0.0957) | Acc: (96.81%) (24908/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 210 |  Loss: (0.0952) | Acc: (96.82%) (26148/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 220 |  Loss: (0.0953) | Acc: (96.80%) (27384/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 230 |  Loss: (0.0949) | Acc: (96.82%) (28628/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 240 |  Loss: (0.0952) | Acc: (96.82%) (29866/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 250 |  Loss: (0.0954) | Acc: (96.80%) (31101/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 260 |  Loss: (0.0953) | Acc: (96.79%) (32336/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 270 |  Loss: (0.0953) | Acc: (96.80%) (33577/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 280 |  Loss: (0.0952) | Acc: (96.82%) (34824/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 290 |  Loss: (0.0955) | Acc: (96.81%) (36059/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 300 |  Loss: (0.0951) | Acc: (96.82%) (37301/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 310 |  Loss: (0.0945) | Acc: (96.83%) (38548/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 320 |  Loss: (0.0947) | Acc: (96.81%) (39777/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 330 |  Loss: (0.0943) | Acc: (96.83%) (41025/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 340 |  Loss: (0.0945) | Acc: (96.83%) (42263/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 350 |  Loss: (0.0943) | Acc: (96.84%) (43508/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 360 |  Loss: (0.0942) | Acc: (96.84%) (44749/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 370 |  Loss: (0.0937) | Acc: (96.86%) (45995/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 380 |  Loss: (0.0937) | Acc: (96.84%) (47228/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 116 | Batch_idx: 390 |  Loss: (0.0941) | Acc: (96.84%) (48418/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3204) | Acc: (41.21%) (4121/10000)\n",
      "Epoch: 117 | Batch_idx: 0 |  Loss: (0.2207) | Acc: (92.19%) (118/128)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 10 |  Loss: (0.0961) | Acc: (97.23%) (1369/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 20 |  Loss: (0.0982) | Acc: (96.76%) (2601/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 30 |  Loss: (0.0919) | Acc: (96.95%) (3847/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 40 |  Loss: (0.0966) | Acc: (96.72%) (5076/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 50 |  Loss: (0.1010) | Acc: (96.51%) (6300/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 60 |  Loss: (0.1016) | Acc: (96.48%) (7533/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 70 |  Loss: (0.1003) | Acc: (96.47%) (8767/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 80 |  Loss: (0.1002) | Acc: (96.48%) (10003/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 90 |  Loss: (0.0980) | Acc: (96.58%) (11250/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 100 |  Loss: (0.0984) | Acc: (96.57%) (12484/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 110 |  Loss: (0.0996) | Acc: (96.52%) (13714/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 120 |  Loss: (0.0996) | Acc: (96.49%) (14945/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 130 |  Loss: (0.0973) | Acc: (96.60%) (16198/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 140 |  Loss: (0.0963) | Acc: (96.68%) (17449/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 150 |  Loss: (0.0967) | Acc: (96.67%) (18685/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 160 |  Loss: (0.0980) | Acc: (96.66%) (19920/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 170 |  Loss: (0.0978) | Acc: (96.65%) (21154/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 180 |  Loss: (0.0987) | Acc: (96.64%) (22389/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 190 |  Loss: (0.0978) | Acc: (96.67%) (23635/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 200 |  Loss: (0.0973) | Acc: (96.70%) (24878/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 210 |  Loss: (0.0961) | Acc: (96.73%) (26124/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 220 |  Loss: (0.0957) | Acc: (96.74%) (27367/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 230 |  Loss: (0.0970) | Acc: (96.70%) (28592/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 240 |  Loss: (0.0970) | Acc: (96.70%) (29829/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 250 |  Loss: (0.0973) | Acc: (96.69%) (31065/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 260 |  Loss: (0.0968) | Acc: (96.70%) (32307/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 270 |  Loss: (0.0973) | Acc: (96.68%) (33536/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 280 |  Loss: (0.0968) | Acc: (96.71%) (34785/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 290 |  Loss: (0.0972) | Acc: (96.70%) (36019/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 300 |  Loss: (0.0968) | Acc: (96.70%) (37258/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 310 |  Loss: (0.0969) | Acc: (96.69%) (38492/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 320 |  Loss: (0.0963) | Acc: (96.72%) (39741/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 330 |  Loss: (0.0964) | Acc: (96.73%) (40981/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 340 |  Loss: (0.0960) | Acc: (96.75%) (42231/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 350 |  Loss: (0.0957) | Acc: (96.77%) (43476/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 360 |  Loss: (0.0961) | Acc: (96.76%) (44709/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 370 |  Loss: (0.0963) | Acc: (96.73%) (45934/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 380 |  Loss: (0.0964) | Acc: (96.73%) (47173/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 117 | Batch_idx: 390 |  Loss: (0.0965) | Acc: (96.73%) (48363/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3721) | Acc: (39.52%) (3952/10000)\n",
      "Epoch: 118 | Batch_idx: 0 |  Loss: (0.0327) | Acc: (100.00%) (128/128)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 10 |  Loss: (0.0880) | Acc: (96.95%) (1365/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 20 |  Loss: (0.1065) | Acc: (96.35%) (2590/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 30 |  Loss: (0.1088) | Acc: (96.30%) (3821/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 40 |  Loss: (0.1080) | Acc: (96.36%) (5057/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 50 |  Loss: (0.1069) | Acc: (96.37%) (6291/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 60 |  Loss: (0.1045) | Acc: (96.50%) (7535/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 70 |  Loss: (0.1031) | Acc: (96.52%) (8772/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 80 |  Loss: (0.1004) | Acc: (96.61%) (10017/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 90 |  Loss: (0.1002) | Acc: (96.66%) (11259/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 100 |  Loss: (0.1012) | Acc: (96.67%) (12498/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 110 |  Loss: (0.1016) | Acc: (96.66%) (13734/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 120 |  Loss: (0.0982) | Acc: (96.75%) (14984/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 130 |  Loss: (0.0977) | Acc: (96.76%) (16224/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 140 |  Loss: (0.0988) | Acc: (96.73%) (17457/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 150 |  Loss: (0.0987) | Acc: (96.76%) (18701/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 160 |  Loss: (0.0975) | Acc: (96.80%) (19948/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 170 |  Loss: (0.0972) | Acc: (96.82%) (21191/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 180 |  Loss: (0.0969) | Acc: (96.80%) (22427/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 190 |  Loss: (0.0963) | Acc: (96.81%) (23668/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 200 |  Loss: (0.0959) | Acc: (96.82%) (24909/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 210 |  Loss: (0.0959) | Acc: (96.83%) (26151/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 220 |  Loss: (0.0958) | Acc: (96.83%) (27390/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 230 |  Loss: (0.0950) | Acc: (96.85%) (28636/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 240 |  Loss: (0.0946) | Acc: (96.87%) (29882/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 250 |  Loss: (0.0940) | Acc: (96.88%) (31126/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 260 |  Loss: (0.0937) | Acc: (96.90%) (32371/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 270 |  Loss: (0.0936) | Acc: (96.89%) (33609/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 280 |  Loss: (0.0933) | Acc: (96.89%) (34851/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 290 |  Loss: (0.0936) | Acc: (96.88%) (36085/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 300 |  Loss: (0.0939) | Acc: (96.87%) (37321/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 310 |  Loss: (0.0933) | Acc: (96.89%) (38569/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 320 |  Loss: (0.0923) | Acc: (96.94%) (39829/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 330 |  Loss: (0.0933) | Acc: (96.90%) (41055/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 340 |  Loss: (0.0928) | Acc: (96.90%) (42296/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 350 |  Loss: (0.0927) | Acc: (96.90%) (43536/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 360 |  Loss: (0.0922) | Acc: (96.92%) (44784/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 370 |  Loss: (0.0924) | Acc: (96.92%) (46027/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 380 |  Loss: (0.0924) | Acc: (96.90%) (47258/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 118 | Batch_idx: 390 |  Loss: (0.0923) | Acc: (96.90%) (48452/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3183) | Acc: (39.69%) (3969/10000)\n",
      "Epoch: 119 | Batch_idx: 0 |  Loss: (0.1044) | Acc: (97.66%) (125/128)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 10 |  Loss: (0.1065) | Acc: (96.88%) (1364/1408)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 20 |  Loss: (0.1051) | Acc: (96.65%) (2598/2688)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 30 |  Loss: (0.1114) | Acc: (96.42%) (3826/3968)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 40 |  Loss: (0.1136) | Acc: (96.46%) (5062/5248)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 50 |  Loss: (0.1098) | Acc: (96.43%) (6295/6528)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 60 |  Loss: (0.1077) | Acc: (96.54%) (7538/7808)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 70 |  Loss: (0.1046) | Acc: (96.65%) (8784/9088)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 80 |  Loss: (0.1028) | Acc: (96.74%) (10030/10368)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 90 |  Loss: (0.1027) | Acc: (96.71%) (11265/11648)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 100 |  Loss: (0.1060) | Acc: (96.60%) (12489/12928)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 110 |  Loss: (0.1039) | Acc: (96.64%) (13730/14208)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 120 |  Loss: (0.1023) | Acc: (96.65%) (14969/15488)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 130 |  Loss: (0.1013) | Acc: (96.65%) (16206/16768)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 140 |  Loss: (0.1005) | Acc: (96.66%) (17446/18048)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 150 |  Loss: (0.0998) | Acc: (96.69%) (18689/19328)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 160 |  Loss: (0.0991) | Acc: (96.72%) (19932/20608)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 170 |  Loss: (0.0979) | Acc: (96.74%) (21175/21888)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 180 |  Loss: (0.0979) | Acc: (96.73%) (22411/23168)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 190 |  Loss: (0.0987) | Acc: (96.73%) (23649/24448)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 200 |  Loss: (0.0985) | Acc: (96.76%) (24895/25728)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 210 |  Loss: (0.0982) | Acc: (96.77%) (26136/27008)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 220 |  Loss: (0.0974) | Acc: (96.80%) (27383/28288)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 230 |  Loss: (0.0979) | Acc: (96.79%) (28618/29568)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 240 |  Loss: (0.0981) | Acc: (96.79%) (29857/30848)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 250 |  Loss: (0.0981) | Acc: (96.79%) (31097/32128)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 260 |  Loss: (0.0981) | Acc: (96.78%) (32333/33408)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 270 |  Loss: (0.0978) | Acc: (96.79%) (33576/34688)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 280 |  Loss: (0.0977) | Acc: (96.79%) (34814/35968)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 290 |  Loss: (0.0975) | Acc: (96.80%) (36057/37248)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 300 |  Loss: (0.0976) | Acc: (96.81%) (37298/38528)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 310 |  Loss: (0.0985) | Acc: (96.76%) (38518/39808)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 320 |  Loss: (0.0981) | Acc: (96.78%) (39764/41088)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 330 |  Loss: (0.0981) | Acc: (96.77%) (41001/42368)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 340 |  Loss: (0.0982) | Acc: (96.77%) (42237/43648)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 350 |  Loss: (0.0978) | Acc: (96.79%) (43485/44928)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 360 |  Loss: (0.0976) | Acc: (96.77%) (44717/46208)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 370 |  Loss: (0.0967) | Acc: (96.81%) (45973/47488)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 380 |  Loss: (0.0965) | Acc: (96.82%) (47217/48768)\n",
      "lr: 0.0001\n",
      "Epoch: 119 | Batch_idx: 390 |  Loss: (0.0966) | Acc: (96.81%) (48405/50000)\n",
      "lr: 0.0001\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3112) | Acc: (39.96%) (3996/10000)\n",
      "Epoch: 120 | Batch_idx: 0 |  Loss: (0.1419) | Acc: (95.31%) (122/128)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 10 |  Loss: (0.0903) | Acc: (97.16%) (1368/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 20 |  Loss: (0.0896) | Acc: (96.99%) (2607/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 30 |  Loss: (0.0935) | Acc: (96.75%) (3839/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 40 |  Loss: (0.1007) | Acc: (96.49%) (5064/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 50 |  Loss: (0.0970) | Acc: (96.58%) (6305/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 60 |  Loss: (0.0958) | Acc: (96.59%) (7542/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 70 |  Loss: (0.0947) | Acc: (96.69%) (8787/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 80 |  Loss: (0.0936) | Acc: (96.74%) (10030/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 90 |  Loss: (0.0930) | Acc: (96.80%) (11275/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 100 |  Loss: (0.0932) | Acc: (96.74%) (12507/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 110 |  Loss: (0.0933) | Acc: (96.76%) (13747/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 120 |  Loss: (0.0923) | Acc: (96.80%) (14993/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 130 |  Loss: (0.0914) | Acc: (96.85%) (16240/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 140 |  Loss: (0.0917) | Acc: (96.85%) (17480/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 150 |  Loss: (0.0912) | Acc: (96.87%) (18723/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 160 |  Loss: (0.0921) | Acc: (96.81%) (19950/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 170 |  Loss: (0.0917) | Acc: (96.82%) (21192/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 180 |  Loss: (0.0915) | Acc: (96.84%) (22437/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 190 |  Loss: (0.0918) | Acc: (96.82%) (23670/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 200 |  Loss: (0.0923) | Acc: (96.80%) (24905/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 210 |  Loss: (0.0909) | Acc: (96.87%) (26162/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 220 |  Loss: (0.0903) | Acc: (96.89%) (27409/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 230 |  Loss: (0.0906) | Acc: (96.89%) (28648/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 240 |  Loss: (0.0907) | Acc: (96.89%) (29889/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 250 |  Loss: (0.0912) | Acc: (96.87%) (31121/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 260 |  Loss: (0.0915) | Acc: (96.86%) (32360/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 270 |  Loss: (0.0915) | Acc: (96.88%) (33605/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 280 |  Loss: (0.0914) | Acc: (96.88%) (34845/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 290 |  Loss: (0.0914) | Acc: (96.86%) (36080/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 300 |  Loss: (0.0907) | Acc: (96.89%) (37330/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 310 |  Loss: (0.0903) | Acc: (96.91%) (38576/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 320 |  Loss: (0.0903) | Acc: (96.89%) (39812/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 330 |  Loss: (0.0907) | Acc: (96.90%) (41055/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 340 |  Loss: (0.0905) | Acc: (96.92%) (42303/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 350 |  Loss: (0.0907) | Acc: (96.89%) (43532/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 360 |  Loss: (0.0912) | Acc: (96.87%) (44763/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 370 |  Loss: (0.0915) | Acc: (96.87%) (46000/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 380 |  Loss: (0.0918) | Acc: (96.86%) (47235/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 120 | Batch_idx: 390 |  Loss: (0.0918) | Acc: (96.86%) (48431/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3803) | Acc: (39.24%) (3924/10000)\n",
      "Epoch: 121 | Batch_idx: 0 |  Loss: (0.0388) | Acc: (98.44%) (126/128)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 10 |  Loss: (0.0783) | Acc: (97.51%) (1373/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 20 |  Loss: (0.0836) | Acc: (97.28%) (2615/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 30 |  Loss: (0.0884) | Acc: (97.15%) (3855/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 40 |  Loss: (0.0915) | Acc: (97.03%) (5092/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 50 |  Loss: (0.0904) | Acc: (97.06%) (6336/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 60 |  Loss: (0.0907) | Acc: (97.11%) (7582/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 70 |  Loss: (0.0925) | Acc: (97.03%) (8818/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 80 |  Loss: (0.0918) | Acc: (97.03%) (10060/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 90 |  Loss: (0.0889) | Acc: (97.12%) (11312/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 100 |  Loss: (0.0903) | Acc: (97.01%) (12542/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 110 |  Loss: (0.0916) | Acc: (96.93%) (13772/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 120 |  Loss: (0.0910) | Acc: (96.93%) (15013/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 130 |  Loss: (0.0904) | Acc: (96.97%) (16260/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 140 |  Loss: (0.0909) | Acc: (96.97%) (17501/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 150 |  Loss: (0.0905) | Acc: (96.98%) (18744/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 160 |  Loss: (0.0913) | Acc: (96.94%) (19977/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 170 |  Loss: (0.0911) | Acc: (96.93%) (21217/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 180 |  Loss: (0.0897) | Acc: (96.98%) (22468/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 190 |  Loss: (0.0894) | Acc: (97.00%) (23714/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 200 |  Loss: (0.0889) | Acc: (97.00%) (24957/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 210 |  Loss: (0.0889) | Acc: (97.00%) (26197/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 220 |  Loss: (0.0887) | Acc: (97.00%) (27438/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 230 |  Loss: (0.0889) | Acc: (96.97%) (28673/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 240 |  Loss: (0.0892) | Acc: (96.97%) (29914/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 250 |  Loss: (0.0893) | Acc: (96.96%) (31150/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 260 |  Loss: (0.0896) | Acc: (96.96%) (32391/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 270 |  Loss: (0.0896) | Acc: (96.94%) (33628/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 280 |  Loss: (0.0903) | Acc: (96.94%) (34867/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 290 |  Loss: (0.0897) | Acc: (96.97%) (36118/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 300 |  Loss: (0.0889) | Acc: (96.98%) (37364/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 310 |  Loss: (0.0886) | Acc: (97.00%) (38615/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 320 |  Loss: (0.0887) | Acc: (97.00%) (39856/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 330 |  Loss: (0.0891) | Acc: (97.00%) (41096/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 340 |  Loss: (0.0885) | Acc: (97.02%) (42346/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 350 |  Loss: (0.0886) | Acc: (97.02%) (43589/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 360 |  Loss: (0.0894) | Acc: (96.97%) (44808/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 370 |  Loss: (0.0895) | Acc: (96.98%) (46055/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 380 |  Loss: (0.0893) | Acc: (96.98%) (47297/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 121 | Batch_idx: 390 |  Loss: (0.0894) | Acc: (96.97%) (48483/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3019) | Acc: (40.25%) (4025/10000)\n",
      "Epoch: 122 | Batch_idx: 0 |  Loss: (0.1188) | Acc: (96.09%) (123/128)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 10 |  Loss: (0.0882) | Acc: (97.09%) (1367/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 20 |  Loss: (0.0788) | Acc: (97.58%) (2623/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 30 |  Loss: (0.0820) | Acc: (97.15%) (3855/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 40 |  Loss: (0.0863) | Acc: (97.05%) (5093/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 50 |  Loss: (0.0895) | Acc: (96.92%) (6327/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 60 |  Loss: (0.0895) | Acc: (96.91%) (7567/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 70 |  Loss: (0.0897) | Acc: (96.84%) (8801/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 80 |  Loss: (0.0913) | Acc: (96.86%) (10042/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 90 |  Loss: (0.0940) | Acc: (96.73%) (11267/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 100 |  Loss: (0.0966) | Acc: (96.67%) (12497/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 110 |  Loss: (0.0981) | Acc: (96.57%) (13720/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 120 |  Loss: (0.0992) | Acc: (96.52%) (14949/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 130 |  Loss: (0.0983) | Acc: (96.55%) (16189/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 140 |  Loss: (0.0985) | Acc: (96.55%) (17425/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 150 |  Loss: (0.0992) | Acc: (96.55%) (18661/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 160 |  Loss: (0.0981) | Acc: (96.58%) (19903/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 170 |  Loss: (0.0990) | Acc: (96.55%) (21132/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 180 |  Loss: (0.0985) | Acc: (96.55%) (22369/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 190 |  Loss: (0.0978) | Acc: (96.55%) (23605/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 200 |  Loss: (0.0975) | Acc: (96.58%) (24849/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 210 |  Loss: (0.0965) | Acc: (96.62%) (26095/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 220 |  Loss: (0.0958) | Acc: (96.66%) (27344/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 230 |  Loss: (0.0951) | Acc: (96.68%) (28587/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 240 |  Loss: (0.0950) | Acc: (96.69%) (29828/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 250 |  Loss: (0.0946) | Acc: (96.72%) (31073/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 260 |  Loss: (0.0942) | Acc: (96.73%) (32314/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 270 |  Loss: (0.0939) | Acc: (96.74%) (33558/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 280 |  Loss: (0.0937) | Acc: (96.76%) (34801/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 290 |  Loss: (0.0937) | Acc: (96.75%) (36036/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 300 |  Loss: (0.0934) | Acc: (96.76%) (37281/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 310 |  Loss: (0.0939) | Acc: (96.75%) (38515/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 320 |  Loss: (0.0944) | Acc: (96.75%) (39752/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 330 |  Loss: (0.0938) | Acc: (96.78%) (41005/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 340 |  Loss: (0.0940) | Acc: (96.80%) (42250/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 350 |  Loss: (0.0936) | Acc: (96.82%) (43500/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 360 |  Loss: (0.0938) | Acc: (96.81%) (44733/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 370 |  Loss: (0.0938) | Acc: (96.80%) (45970/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 380 |  Loss: (0.0935) | Acc: (96.82%) (47216/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 122 | Batch_idx: 390 |  Loss: (0.0936) | Acc: (96.81%) (48406/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3338) | Acc: (40.11%) (4011/10000)\n",
      "Epoch: 123 | Batch_idx: 0 |  Loss: (0.0742) | Acc: (97.66%) (125/128)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 10 |  Loss: (0.0804) | Acc: (97.37%) (1371/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 20 |  Loss: (0.0867) | Acc: (97.10%) (2610/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 30 |  Loss: (0.0860) | Acc: (97.10%) (3853/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 40 |  Loss: (0.0882) | Acc: (96.93%) (5087/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 50 |  Loss: (0.0918) | Acc: (96.84%) (6322/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 60 |  Loss: (0.0914) | Acc: (96.82%) (7560/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 70 |  Loss: (0.0921) | Acc: (96.83%) (8800/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 80 |  Loss: (0.0912) | Acc: (96.81%) (10037/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 90 |  Loss: (0.0915) | Acc: (96.81%) (11277/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 100 |  Loss: (0.0914) | Acc: (96.85%) (12521/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 110 |  Loss: (0.0925) | Acc: (96.85%) (13760/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 120 |  Loss: (0.0924) | Acc: (96.86%) (15001/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 130 |  Loss: (0.0928) | Acc: (96.82%) (16234/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 140 |  Loss: (0.0926) | Acc: (96.83%) (17475/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 150 |  Loss: (0.0927) | Acc: (96.82%) (18713/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 160 |  Loss: (0.0943) | Acc: (96.76%) (19940/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 170 |  Loss: (0.0940) | Acc: (96.74%) (21175/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 180 |  Loss: (0.0952) | Acc: (96.70%) (22403/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 190 |  Loss: (0.0953) | Acc: (96.67%) (23634/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 200 |  Loss: (0.0960) | Acc: (96.67%) (24870/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 210 |  Loss: (0.0958) | Acc: (96.66%) (26107/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 220 |  Loss: (0.0956) | Acc: (96.67%) (27346/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 230 |  Loss: (0.0948) | Acc: (96.70%) (28591/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 240 |  Loss: (0.0943) | Acc: (96.73%) (29838/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 250 |  Loss: (0.0946) | Acc: (96.68%) (31062/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 260 |  Loss: (0.0946) | Acc: (96.69%) (32303/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 270 |  Loss: (0.0943) | Acc: (96.72%) (33549/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 280 |  Loss: (0.0941) | Acc: (96.72%) (34789/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 290 |  Loss: (0.0939) | Acc: (96.72%) (36025/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 300 |  Loss: (0.0937) | Acc: (96.73%) (37270/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 310 |  Loss: (0.0937) | Acc: (96.72%) (38504/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 320 |  Loss: (0.0945) | Acc: (96.71%) (39735/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 330 |  Loss: (0.0936) | Acc: (96.75%) (40990/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 340 |  Loss: (0.0939) | Acc: (96.74%) (42224/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 350 |  Loss: (0.0939) | Acc: (96.74%) (43465/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 360 |  Loss: (0.0943) | Acc: (96.73%) (44699/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 370 |  Loss: (0.0943) | Acc: (96.74%) (45941/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 380 |  Loss: (0.0938) | Acc: (96.77%) (47191/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 123 | Batch_idx: 390 |  Loss: (0.0931) | Acc: (96.79%) (48393/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3699) | Acc: (39.40%) (3940/10000)\n",
      "Epoch: 124 | Batch_idx: 0 |  Loss: (0.0558) | Acc: (99.22%) (127/128)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 10 |  Loss: (0.0999) | Acc: (96.73%) (1362/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 20 |  Loss: (0.0944) | Acc: (96.95%) (2606/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 30 |  Loss: (0.0950) | Acc: (96.88%) (3844/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 40 |  Loss: (0.0908) | Acc: (97.03%) (5092/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 50 |  Loss: (0.0916) | Acc: (96.98%) (6331/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 60 |  Loss: (0.0919) | Acc: (96.95%) (7570/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 70 |  Loss: (0.0905) | Acc: (97.00%) (8815/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 80 |  Loss: (0.0925) | Acc: (96.96%) (10053/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 90 |  Loss: (0.0936) | Acc: (96.94%) (11291/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 100 |  Loss: (0.0939) | Acc: (96.92%) (12530/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 110 |  Loss: (0.0921) | Acc: (96.95%) (13774/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 120 |  Loss: (0.0911) | Acc: (96.99%) (15022/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 130 |  Loss: (0.0901) | Acc: (97.02%) (16268/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 140 |  Loss: (0.0910) | Acc: (96.99%) (17504/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 150 |  Loss: (0.0898) | Acc: (97.02%) (18752/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 160 |  Loss: (0.0890) | Acc: (97.04%) (19997/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 170 |  Loss: (0.0889) | Acc: (97.04%) (21240/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 180 |  Loss: (0.0890) | Acc: (97.04%) (22482/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 190 |  Loss: (0.0883) | Acc: (97.07%) (23732/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 200 |  Loss: (0.0906) | Acc: (97.01%) (24959/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 210 |  Loss: (0.0900) | Acc: (97.03%) (26205/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 220 |  Loss: (0.0911) | Acc: (96.99%) (27436/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 230 |  Loss: (0.0902) | Acc: (97.01%) (28684/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 240 |  Loss: (0.0899) | Acc: (97.05%) (29937/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 250 |  Loss: (0.0899) | Acc: (97.05%) (31180/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 260 |  Loss: (0.0901) | Acc: (97.03%) (32417/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 270 |  Loss: (0.0908) | Acc: (97.00%) (33647/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 280 |  Loss: (0.0911) | Acc: (97.00%) (34888/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 290 |  Loss: (0.0907) | Acc: (97.01%) (36133/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 300 |  Loss: (0.0897) | Acc: (97.04%) (37387/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 310 |  Loss: (0.0894) | Acc: (97.05%) (38634/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 320 |  Loss: (0.0891) | Acc: (97.06%) (39881/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 330 |  Loss: (0.0889) | Acc: (97.07%) (41126/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 340 |  Loss: (0.0888) | Acc: (97.07%) (42370/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 350 |  Loss: (0.0895) | Acc: (97.06%) (43606/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 360 |  Loss: (0.0892) | Acc: (97.07%) (44853/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 370 |  Loss: (0.0898) | Acc: (97.06%) (46093/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 380 |  Loss: (0.0899) | Acc: (97.06%) (47332/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 124 | Batch_idx: 390 |  Loss: (0.0899) | Acc: (97.05%) (48526/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3158) | Acc: (39.98%) (3998/10000)\n",
      "Epoch: 125 | Batch_idx: 0 |  Loss: (0.1044) | Acc: (95.31%) (122/128)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 10 |  Loss: (0.1139) | Acc: (96.16%) (1354/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 20 |  Loss: (0.0997) | Acc: (96.58%) (2596/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 30 |  Loss: (0.0959) | Acc: (96.70%) (3837/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 40 |  Loss: (0.0952) | Acc: (96.61%) (5070/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 50 |  Loss: (0.1004) | Acc: (96.51%) (6300/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 60 |  Loss: (0.0985) | Acc: (96.54%) (7538/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 70 |  Loss: (0.0974) | Acc: (96.53%) (8773/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 80 |  Loss: (0.0950) | Acc: (96.62%) (10018/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 90 |  Loss: (0.0945) | Acc: (96.63%) (11256/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 100 |  Loss: (0.0952) | Acc: (96.57%) (12484/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 110 |  Loss: (0.0967) | Acc: (96.52%) (13713/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 120 |  Loss: (0.0964) | Acc: (96.53%) (14951/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 130 |  Loss: (0.0961) | Acc: (96.60%) (16198/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 140 |  Loss: (0.0955) | Acc: (96.62%) (17438/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 150 |  Loss: (0.0961) | Acc: (96.62%) (18675/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 160 |  Loss: (0.0947) | Acc: (96.70%) (19927/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 170 |  Loss: (0.0941) | Acc: (96.74%) (21175/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 180 |  Loss: (0.0935) | Acc: (96.77%) (22419/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 190 |  Loss: (0.0933) | Acc: (96.80%) (23665/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 200 |  Loss: (0.0935) | Acc: (96.80%) (24904/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 210 |  Loss: (0.0936) | Acc: (96.79%) (26142/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 220 |  Loss: (0.0932) | Acc: (96.80%) (27384/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 230 |  Loss: (0.0928) | Acc: (96.81%) (28625/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 240 |  Loss: (0.0934) | Acc: (96.79%) (29858/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 250 |  Loss: (0.0933) | Acc: (96.78%) (31093/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 260 |  Loss: (0.0923) | Acc: (96.83%) (32348/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 270 |  Loss: (0.0924) | Acc: (96.84%) (33592/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 280 |  Loss: (0.0919) | Acc: (96.86%) (34838/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 290 |  Loss: (0.0922) | Acc: (96.85%) (36076/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 300 |  Loss: (0.0921) | Acc: (96.87%) (37321/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 310 |  Loss: (0.0916) | Acc: (96.88%) (38564/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 320 |  Loss: (0.0916) | Acc: (96.87%) (39803/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 330 |  Loss: (0.0914) | Acc: (96.88%) (41044/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 340 |  Loss: (0.0913) | Acc: (96.88%) (42285/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 350 |  Loss: (0.0912) | Acc: (96.88%) (43527/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 360 |  Loss: (0.0919) | Acc: (96.85%) (44753/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 370 |  Loss: (0.0918) | Acc: (96.86%) (45997/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 380 |  Loss: (0.0924) | Acc: (96.85%) (47233/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 125 | Batch_idx: 390 |  Loss: (0.0925) | Acc: (96.86%) (48431/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3274) | Acc: (40.00%) (4000/10000)\n",
      "Epoch: 126 | Batch_idx: 0 |  Loss: (0.0673) | Acc: (98.44%) (126/128)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 10 |  Loss: (0.0856) | Acc: (97.30%) (1370/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 20 |  Loss: (0.0852) | Acc: (97.14%) (2611/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 30 |  Loss: (0.0900) | Acc: (97.05%) (3851/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 40 |  Loss: (0.0848) | Acc: (97.24%) (5103/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 50 |  Loss: (0.0865) | Acc: (97.29%) (6351/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 60 |  Loss: (0.0879) | Acc: (97.26%) (7594/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 70 |  Loss: (0.0882) | Acc: (97.16%) (8830/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 80 |  Loss: (0.0919) | Acc: (97.09%) (10066/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 90 |  Loss: (0.0924) | Acc: (97.13%) (11314/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 100 |  Loss: (0.0907) | Acc: (97.12%) (12556/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 110 |  Loss: (0.0917) | Acc: (97.05%) (13789/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 120 |  Loss: (0.0926) | Acc: (97.03%) (15028/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 130 |  Loss: (0.0927) | Acc: (97.03%) (16270/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 140 |  Loss: (0.0930) | Acc: (97.01%) (17509/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 150 |  Loss: (0.0929) | Acc: (97.01%) (18751/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 160 |  Loss: (0.0925) | Acc: (97.01%) (19991/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 170 |  Loss: (0.0932) | Acc: (96.94%) (21218/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 180 |  Loss: (0.0928) | Acc: (96.93%) (22457/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 190 |  Loss: (0.0933) | Acc: (96.93%) (23697/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 200 |  Loss: (0.0933) | Acc: (96.93%) (24939/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 210 |  Loss: (0.0931) | Acc: (96.94%) (26181/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 220 |  Loss: (0.0929) | Acc: (96.96%) (27429/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 230 |  Loss: (0.0936) | Acc: (96.93%) (28661/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 240 |  Loss: (0.0942) | Acc: (96.91%) (29894/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 250 |  Loss: (0.0937) | Acc: (96.92%) (31137/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 260 |  Loss: (0.0938) | Acc: (96.91%) (32377/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 270 |  Loss: (0.0946) | Acc: (96.89%) (33610/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 280 |  Loss: (0.0945) | Acc: (96.89%) (34849/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 290 |  Loss: (0.0947) | Acc: (96.89%) (36090/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 300 |  Loss: (0.0947) | Acc: (96.90%) (37333/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 310 |  Loss: (0.0947) | Acc: (96.88%) (38566/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 320 |  Loss: (0.0954) | Acc: (96.87%) (39801/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 330 |  Loss: (0.0953) | Acc: (96.87%) (41040/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 340 |  Loss: (0.0951) | Acc: (96.88%) (42284/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 350 |  Loss: (0.0950) | Acc: (96.88%) (43524/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 360 |  Loss: (0.0948) | Acc: (96.87%) (44763/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 370 |  Loss: (0.0950) | Acc: (96.86%) (45996/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 380 |  Loss: (0.0950) | Acc: (96.85%) (47234/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 126 | Batch_idx: 390 |  Loss: (0.0948) | Acc: (96.85%) (48426/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.2810) | Acc: (40.65%) (4065/10000)\n",
      "Epoch: 127 | Batch_idx: 0 |  Loss: (0.0842) | Acc: (97.66%) (125/128)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 10 |  Loss: (0.1110) | Acc: (96.45%) (1358/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 20 |  Loss: (0.1025) | Acc: (96.54%) (2595/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 30 |  Loss: (0.0952) | Acc: (96.67%) (3836/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 40 |  Loss: (0.0956) | Acc: (96.74%) (5077/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 50 |  Loss: (0.0931) | Acc: (96.83%) (6321/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 60 |  Loss: (0.0934) | Acc: (96.82%) (7560/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 70 |  Loss: (0.0931) | Acc: (96.83%) (8800/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 80 |  Loss: (0.0934) | Acc: (96.84%) (10040/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 90 |  Loss: (0.0935) | Acc: (96.84%) (11280/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 100 |  Loss: (0.0926) | Acc: (96.90%) (12527/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 110 |  Loss: (0.0933) | Acc: (96.88%) (13764/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 120 |  Loss: (0.0911) | Acc: (96.95%) (15016/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 130 |  Loss: (0.0911) | Acc: (96.96%) (16259/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 140 |  Loss: (0.0929) | Acc: (96.89%) (17486/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 150 |  Loss: (0.0920) | Acc: (96.92%) (18732/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 160 |  Loss: (0.0909) | Acc: (96.96%) (19982/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 170 |  Loss: (0.0907) | Acc: (96.97%) (21224/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 180 |  Loss: (0.0904) | Acc: (96.97%) (22467/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 190 |  Loss: (0.0898) | Acc: (97.00%) (23714/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 200 |  Loss: (0.0896) | Acc: (97.00%) (24957/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 210 |  Loss: (0.0899) | Acc: (97.00%) (26197/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 220 |  Loss: (0.0898) | Acc: (97.00%) (27439/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 230 |  Loss: (0.0899) | Acc: (97.00%) (28682/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 240 |  Loss: (0.0897) | Acc: (97.01%) (29926/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 250 |  Loss: (0.0889) | Acc: (97.04%) (31178/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 260 |  Loss: (0.0888) | Acc: (97.02%) (32412/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 270 |  Loss: (0.0892) | Acc: (96.98%) (33640/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 280 |  Loss: (0.0891) | Acc: (96.98%) (34881/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 290 |  Loss: (0.0890) | Acc: (96.99%) (36125/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 300 |  Loss: (0.0898) | Acc: (96.97%) (37360/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 310 |  Loss: (0.0895) | Acc: (96.98%) (38605/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 320 |  Loss: (0.0900) | Acc: (96.94%) (39829/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 330 |  Loss: (0.0900) | Acc: (96.94%) (41070/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 340 |  Loss: (0.0900) | Acc: (96.94%) (42314/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 350 |  Loss: (0.0902) | Acc: (96.94%) (43551/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 360 |  Loss: (0.0905) | Acc: (96.92%) (44787/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 370 |  Loss: (0.0912) | Acc: (96.91%) (46019/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 380 |  Loss: (0.0911) | Acc: (96.90%) (47255/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 127 | Batch_idx: 390 |  Loss: (0.0914) | Acc: (96.88%) (48442/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3467) | Acc: (40.13%) (4013/10000)\n",
      "Epoch: 128 | Batch_idx: 0 |  Loss: (0.2199) | Acc: (93.75%) (120/128)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 10 |  Loss: (0.0946) | Acc: (96.80%) (1363/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 20 |  Loss: (0.0936) | Acc: (96.80%) (2602/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 30 |  Loss: (0.0890) | Acc: (97.00%) (3849/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 40 |  Loss: (0.0894) | Acc: (97.08%) (5095/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 50 |  Loss: (0.0871) | Acc: (97.12%) (6340/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 60 |  Loss: (0.0892) | Acc: (97.08%) (7580/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 70 |  Loss: (0.0911) | Acc: (97.05%) (8820/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 80 |  Loss: (0.0941) | Acc: (96.87%) (10043/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 90 |  Loss: (0.0949) | Acc: (96.82%) (11278/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 100 |  Loss: (0.0933) | Acc: (96.86%) (12522/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 110 |  Loss: (0.0939) | Acc: (96.88%) (13765/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 120 |  Loss: (0.0935) | Acc: (96.88%) (15004/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 130 |  Loss: (0.0916) | Acc: (96.90%) (16249/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 140 |  Loss: (0.0920) | Acc: (96.88%) (17484/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 150 |  Loss: (0.0920) | Acc: (96.90%) (18728/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 160 |  Loss: (0.0922) | Acc: (96.92%) (19973/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 170 |  Loss: (0.0941) | Acc: (96.86%) (21201/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 180 |  Loss: (0.0931) | Acc: (96.89%) (22448/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 190 |  Loss: (0.0930) | Acc: (96.89%) (23687/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 200 |  Loss: (0.0930) | Acc: (96.91%) (24932/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 210 |  Loss: (0.0921) | Acc: (96.94%) (26182/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 220 |  Loss: (0.0921) | Acc: (96.93%) (27420/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 230 |  Loss: (0.0926) | Acc: (96.90%) (28650/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 240 |  Loss: (0.0929) | Acc: (96.89%) (29890/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 250 |  Loss: (0.0921) | Acc: (96.93%) (31141/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 260 |  Loss: (0.0924) | Acc: (96.91%) (32377/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 270 |  Loss: (0.0919) | Acc: (96.92%) (33620/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 280 |  Loss: (0.0924) | Acc: (96.89%) (34849/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 290 |  Loss: (0.0931) | Acc: (96.87%) (36082/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 300 |  Loss: (0.0929) | Acc: (96.87%) (37322/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 310 |  Loss: (0.0928) | Acc: (96.86%) (38559/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 320 |  Loss: (0.0927) | Acc: (96.87%) (39803/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 330 |  Loss: (0.0925) | Acc: (96.89%) (41049/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 340 |  Loss: (0.0929) | Acc: (96.88%) (42288/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 350 |  Loss: (0.0932) | Acc: (96.87%) (43523/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 360 |  Loss: (0.0931) | Acc: (96.87%) (44762/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 370 |  Loss: (0.0932) | Acc: (96.86%) (45998/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 380 |  Loss: (0.0937) | Acc: (96.84%) (47227/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 128 | Batch_idx: 390 |  Loss: (0.0937) | Acc: (96.84%) (48418/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3716) | Acc: (39.93%) (3993/10000)\n",
      "Epoch: 129 | Batch_idx: 0 |  Loss: (0.0604) | Acc: (99.22%) (127/128)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 10 |  Loss: (0.0904) | Acc: (97.23%) (1369/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 20 |  Loss: (0.0842) | Acc: (97.14%) (2611/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 30 |  Loss: (0.0845) | Acc: (97.08%) (3852/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 40 |  Loss: (0.0825) | Acc: (97.16%) (5099/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 50 |  Loss: (0.0815) | Acc: (97.14%) (6341/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 60 |  Loss: (0.0820) | Acc: (97.16%) (7586/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 70 |  Loss: (0.0835) | Acc: (97.08%) (8823/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 80 |  Loss: (0.0840) | Acc: (97.11%) (10068/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 90 |  Loss: (0.0839) | Acc: (97.12%) (11312/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 100 |  Loss: (0.0833) | Acc: (97.14%) (12558/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 110 |  Loss: (0.0840) | Acc: (97.13%) (13800/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 120 |  Loss: (0.0837) | Acc: (97.14%) (15045/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 130 |  Loss: (0.0835) | Acc: (97.16%) (16291/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 140 |  Loss: (0.0840) | Acc: (97.14%) (17532/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 150 |  Loss: (0.0842) | Acc: (97.14%) (18775/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 160 |  Loss: (0.0836) | Acc: (97.16%) (20023/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 170 |  Loss: (0.0846) | Acc: (97.12%) (21258/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 180 |  Loss: (0.0852) | Acc: (97.10%) (22496/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 190 |  Loss: (0.0854) | Acc: (97.08%) (23735/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 200 |  Loss: (0.0855) | Acc: (97.08%) (24977/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 210 |  Loss: (0.0868) | Acc: (97.04%) (26208/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 220 |  Loss: (0.0869) | Acc: (97.04%) (27452/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 230 |  Loss: (0.0878) | Acc: (97.05%) (28696/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 240 |  Loss: (0.0871) | Acc: (97.08%) (29947/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 250 |  Loss: (0.0877) | Acc: (97.05%) (31181/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 260 |  Loss: (0.0872) | Acc: (97.06%) (32426/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 270 |  Loss: (0.0870) | Acc: (97.07%) (33672/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 280 |  Loss: (0.0877) | Acc: (97.04%) (34905/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 290 |  Loss: (0.0872) | Acc: (97.07%) (36155/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 300 |  Loss: (0.0866) | Acc: (97.10%) (37410/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 310 |  Loss: (0.0868) | Acc: (97.07%) (38642/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 320 |  Loss: (0.0870) | Acc: (97.05%) (39875/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 330 |  Loss: (0.0872) | Acc: (97.03%) (41111/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 340 |  Loss: (0.0870) | Acc: (97.04%) (42354/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 350 |  Loss: (0.0877) | Acc: (97.02%) (43590/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 360 |  Loss: (0.0875) | Acc: (97.02%) (44833/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 370 |  Loss: (0.0880) | Acc: (97.02%) (46073/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 380 |  Loss: (0.0883) | Acc: (97.01%) (47309/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 129 | Batch_idx: 390 |  Loss: (0.0881) | Acc: (97.01%) (48503/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3661) | Acc: (39.82%) (3982/10000)\n",
      "Epoch: 130 | Batch_idx: 0 |  Loss: (0.0985) | Acc: (96.88%) (124/128)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 10 |  Loss: (0.0780) | Acc: (97.30%) (1370/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 20 |  Loss: (0.0885) | Acc: (96.88%) (2604/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 30 |  Loss: (0.0918) | Acc: (96.98%) (3848/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 40 |  Loss: (0.0944) | Acc: (96.88%) (5084/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 50 |  Loss: (0.0932) | Acc: (96.88%) (6324/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 60 |  Loss: (0.0935) | Acc: (96.90%) (7566/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 70 |  Loss: (0.0927) | Acc: (96.94%) (8810/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 80 |  Loss: (0.0934) | Acc: (96.90%) (10047/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 90 |  Loss: (0.0913) | Acc: (96.94%) (11291/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 100 |  Loss: (0.0897) | Acc: (97.00%) (12540/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 110 |  Loss: (0.0902) | Acc: (96.97%) (13777/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 120 |  Loss: (0.0902) | Acc: (96.94%) (15014/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 130 |  Loss: (0.0911) | Acc: (96.94%) (16255/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 140 |  Loss: (0.0900) | Acc: (97.00%) (17507/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 150 |  Loss: (0.0896) | Acc: (96.98%) (18745/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 160 |  Loss: (0.0892) | Acc: (96.98%) (19986/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 170 |  Loss: (0.0886) | Acc: (96.98%) (21228/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 180 |  Loss: (0.0886) | Acc: (96.97%) (22466/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 190 |  Loss: (0.0875) | Acc: (97.01%) (23717/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 200 |  Loss: (0.0888) | Acc: (96.97%) (24948/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 210 |  Loss: (0.0880) | Acc: (96.98%) (26192/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 220 |  Loss: (0.0884) | Acc: (96.97%) (27431/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 230 |  Loss: (0.0882) | Acc: (96.99%) (28679/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 240 |  Loss: (0.0873) | Acc: (97.00%) (29922/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 250 |  Loss: (0.0883) | Acc: (96.97%) (31153/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 260 |  Loss: (0.0885) | Acc: (96.95%) (32389/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 270 |  Loss: (0.0889) | Acc: (96.95%) (33629/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 280 |  Loss: (0.0890) | Acc: (96.92%) (34861/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 290 |  Loss: (0.0887) | Acc: (96.94%) (36109/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 300 |  Loss: (0.0887) | Acc: (96.95%) (37351/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 310 |  Loss: (0.0889) | Acc: (96.94%) (38588/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 320 |  Loss: (0.0898) | Acc: (96.89%) (39811/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 330 |  Loss: (0.0898) | Acc: (96.89%) (41051/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 340 |  Loss: (0.0895) | Acc: (96.90%) (42293/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 350 |  Loss: (0.0898) | Acc: (96.90%) (43534/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 360 |  Loss: (0.0908) | Acc: (96.88%) (44768/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 370 |  Loss: (0.0907) | Acc: (96.89%) (46012/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 380 |  Loss: (0.0908) | Acc: (96.90%) (47257/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 130 | Batch_idx: 390 |  Loss: (0.0911) | Acc: (96.89%) (48447/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3382) | Acc: (40.02%) (4002/10000)\n",
      "Epoch: 131 | Batch_idx: 0 |  Loss: (0.0289) | Acc: (100.00%) (128/128)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 10 |  Loss: (0.1002) | Acc: (96.09%) (1353/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 20 |  Loss: (0.1039) | Acc: (96.32%) (2589/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 30 |  Loss: (0.0998) | Acc: (96.40%) (3825/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 40 |  Loss: (0.0976) | Acc: (96.57%) (5068/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 50 |  Loss: (0.0962) | Acc: (96.63%) (6308/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 60 |  Loss: (0.0981) | Acc: (96.50%) (7535/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 70 |  Loss: (0.0949) | Acc: (96.63%) (8782/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 80 |  Loss: (0.0970) | Acc: (96.60%) (10015/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 90 |  Loss: (0.0968) | Acc: (96.66%) (11259/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 100 |  Loss: (0.0936) | Acc: (96.79%) (12513/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 110 |  Loss: (0.0933) | Acc: (96.80%) (13753/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 120 |  Loss: (0.0930) | Acc: (96.81%) (14994/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 130 |  Loss: (0.0926) | Acc: (96.83%) (16236/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 140 |  Loss: (0.0927) | Acc: (96.83%) (17476/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 150 |  Loss: (0.0932) | Acc: (96.80%) (18709/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 160 |  Loss: (0.0923) | Acc: (96.83%) (19955/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 170 |  Loss: (0.0922) | Acc: (96.87%) (21202/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 180 |  Loss: (0.0927) | Acc: (96.86%) (22441/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 190 |  Loss: (0.0922) | Acc: (96.86%) (23680/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 200 |  Loss: (0.0916) | Acc: (96.88%) (24926/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 210 |  Loss: (0.0921) | Acc: (96.86%) (26161/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 220 |  Loss: (0.0931) | Acc: (96.81%) (27387/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 230 |  Loss: (0.0933) | Acc: (96.82%) (28629/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 240 |  Loss: (0.0932) | Acc: (96.82%) (29868/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 250 |  Loss: (0.0932) | Acc: (96.82%) (31105/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 260 |  Loss: (0.0930) | Acc: (96.84%) (32351/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 270 |  Loss: (0.0934) | Acc: (96.83%) (33587/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 280 |  Loss: (0.0934) | Acc: (96.83%) (34829/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 290 |  Loss: (0.0933) | Acc: (96.85%) (36073/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 300 |  Loss: (0.0925) | Acc: (96.87%) (37323/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 310 |  Loss: (0.0925) | Acc: (96.87%) (38562/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 320 |  Loss: (0.0919) | Acc: (96.90%) (39814/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 330 |  Loss: (0.0921) | Acc: (96.90%) (41054/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 340 |  Loss: (0.0916) | Acc: (96.90%) (42295/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 350 |  Loss: (0.0914) | Acc: (96.90%) (43536/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 360 |  Loss: (0.0912) | Acc: (96.92%) (44784/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 370 |  Loss: (0.0907) | Acc: (96.94%) (46035/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 380 |  Loss: (0.0912) | Acc: (96.94%) (47274/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 131 | Batch_idx: 390 |  Loss: (0.0908) | Acc: (96.94%) (48472/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.2861) | Acc: (40.80%) (4080/10000)\n",
      "Epoch: 132 | Batch_idx: 0 |  Loss: (0.0950) | Acc: (96.88%) (124/128)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 10 |  Loss: (0.1071) | Acc: (96.38%) (1357/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 20 |  Loss: (0.0998) | Acc: (96.28%) (2588/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 30 |  Loss: (0.0980) | Acc: (96.50%) (3829/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 40 |  Loss: (0.0969) | Acc: (96.51%) (5065/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 50 |  Loss: (0.0934) | Acc: (96.65%) (6309/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 60 |  Loss: (0.0925) | Acc: (96.71%) (7551/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 70 |  Loss: (0.0921) | Acc: (96.81%) (8798/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 80 |  Loss: (0.0915) | Acc: (96.82%) (10038/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 90 |  Loss: (0.0893) | Acc: (96.90%) (11287/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 100 |  Loss: (0.0885) | Acc: (96.96%) (12535/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 110 |  Loss: (0.0900) | Acc: (96.92%) (13770/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 120 |  Loss: (0.0889) | Acc: (96.97%) (15019/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 130 |  Loss: (0.0883) | Acc: (96.99%) (16263/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 140 |  Loss: (0.0877) | Acc: (97.01%) (17508/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 150 |  Loss: (0.0863) | Acc: (97.04%) (18755/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 160 |  Loss: (0.0861) | Acc: (97.04%) (19997/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 170 |  Loss: (0.0867) | Acc: (97.02%) (21236/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 180 |  Loss: (0.0861) | Acc: (97.05%) (22484/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 190 |  Loss: (0.0862) | Acc: (97.05%) (23727/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 200 |  Loss: (0.0858) | Acc: (97.07%) (24973/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 210 |  Loss: (0.0856) | Acc: (97.07%) (26217/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 220 |  Loss: (0.0860) | Acc: (97.07%) (27460/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 230 |  Loss: (0.0866) | Acc: (97.05%) (28695/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 240 |  Loss: (0.0867) | Acc: (97.03%) (29933/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 250 |  Loss: (0.0865) | Acc: (97.04%) (31176/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 260 |  Loss: (0.0862) | Acc: (97.04%) (32420/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 270 |  Loss: (0.0865) | Acc: (97.03%) (33659/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 280 |  Loss: (0.0866) | Acc: (97.02%) (34897/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 290 |  Loss: (0.0860) | Acc: (97.04%) (36144/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 300 |  Loss: (0.0860) | Acc: (97.05%) (37390/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 310 |  Loss: (0.0863) | Acc: (97.04%) (38631/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 320 |  Loss: (0.0866) | Acc: (97.04%) (39872/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 330 |  Loss: (0.0871) | Acc: (97.03%) (41109/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 340 |  Loss: (0.0872) | Acc: (97.01%) (42343/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 350 |  Loss: (0.0881) | Acc: (96.98%) (43570/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 360 |  Loss: (0.0879) | Acc: (96.97%) (44808/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 370 |  Loss: (0.0884) | Acc: (96.94%) (46037/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 380 |  Loss: (0.0888) | Acc: (96.92%) (47265/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 132 | Batch_idx: 390 |  Loss: (0.0892) | Acc: (96.91%) (48456/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.2930) | Acc: (40.94%) (4094/10000)\n",
      "Epoch: 133 | Batch_idx: 0 |  Loss: (0.1493) | Acc: (97.66%) (125/128)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 10 |  Loss: (0.0974) | Acc: (97.09%) (1367/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 20 |  Loss: (0.0862) | Acc: (97.40%) (2618/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 30 |  Loss: (0.0856) | Acc: (97.25%) (3859/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 40 |  Loss: (0.0899) | Acc: (97.10%) (5096/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 50 |  Loss: (0.0856) | Acc: (97.30%) (6352/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 60 |  Loss: (0.0884) | Acc: (97.20%) (7589/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 70 |  Loss: (0.0896) | Acc: (97.12%) (8826/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 80 |  Loss: (0.0893) | Acc: (97.09%) (10066/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 90 |  Loss: (0.0891) | Acc: (97.11%) (11311/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 100 |  Loss: (0.0912) | Acc: (97.08%) (12551/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 110 |  Loss: (0.0907) | Acc: (97.09%) (13795/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 120 |  Loss: (0.0891) | Acc: (97.13%) (15043/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 130 |  Loss: (0.0902) | Acc: (97.10%) (16282/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 140 |  Loss: (0.0915) | Acc: (97.05%) (17515/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 150 |  Loss: (0.0929) | Acc: (96.99%) (18747/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 160 |  Loss: (0.0920) | Acc: (97.02%) (19993/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 170 |  Loss: (0.0918) | Acc: (97.02%) (21235/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 180 |  Loss: (0.0923) | Acc: (96.98%) (22468/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 190 |  Loss: (0.0916) | Acc: (96.98%) (23710/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 200 |  Loss: (0.0921) | Acc: (96.98%) (24950/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 210 |  Loss: (0.0922) | Acc: (96.97%) (26190/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 220 |  Loss: (0.0920) | Acc: (96.96%) (27429/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 230 |  Loss: (0.0917) | Acc: (96.98%) (28676/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 240 |  Loss: (0.0916) | Acc: (96.98%) (29916/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 250 |  Loss: (0.0917) | Acc: (96.99%) (31162/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 260 |  Loss: (0.0914) | Acc: (97.00%) (32406/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 270 |  Loss: (0.0915) | Acc: (96.99%) (33643/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 280 |  Loss: (0.0916) | Acc: (96.99%) (34884/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 290 |  Loss: (0.0912) | Acc: (96.99%) (36128/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 300 |  Loss: (0.0908) | Acc: (97.02%) (37379/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 310 |  Loss: (0.0908) | Acc: (97.00%) (38612/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 320 |  Loss: (0.0909) | Acc: (96.98%) (39848/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 330 |  Loss: (0.0913) | Acc: (96.99%) (41093/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 340 |  Loss: (0.0912) | Acc: (96.99%) (42336/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 350 |  Loss: (0.0906) | Acc: (97.02%) (43587/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 360 |  Loss: (0.0904) | Acc: (97.02%) (44832/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 370 |  Loss: (0.0905) | Acc: (97.01%) (46070/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 380 |  Loss: (0.0906) | Acc: (97.00%) (47305/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 133 | Batch_idx: 390 |  Loss: (0.0906) | Acc: (97.00%) (48502/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3576) | Acc: (40.28%) (4028/10000)\n",
      "Epoch: 134 | Batch_idx: 0 |  Loss: (0.0766) | Acc: (97.66%) (125/128)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 10 |  Loss: (0.0831) | Acc: (97.51%) (1373/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 20 |  Loss: (0.0889) | Acc: (97.06%) (2609/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 30 |  Loss: (0.0880) | Acc: (96.95%) (3847/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 40 |  Loss: (0.0863) | Acc: (96.95%) (5088/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 50 |  Loss: (0.0884) | Acc: (96.86%) (6323/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 60 |  Loss: (0.0878) | Acc: (96.91%) (7567/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 70 |  Loss: (0.0918) | Acc: (96.73%) (8791/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 80 |  Loss: (0.0925) | Acc: (96.75%) (10031/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 90 |  Loss: (0.0912) | Acc: (96.82%) (11278/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 100 |  Loss: (0.0898) | Acc: (96.85%) (12521/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 110 |  Loss: (0.0904) | Acc: (96.86%) (13762/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 120 |  Loss: (0.0909) | Acc: (96.86%) (15002/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 130 |  Loss: (0.0909) | Acc: (96.88%) (16245/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 140 |  Loss: (0.0910) | Acc: (96.91%) (17490/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 150 |  Loss: (0.0902) | Acc: (96.91%) (18730/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 160 |  Loss: (0.0900) | Acc: (96.89%) (19968/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 170 |  Loss: (0.0906) | Acc: (96.86%) (21200/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 180 |  Loss: (0.0917) | Acc: (96.86%) (22441/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 190 |  Loss: (0.0917) | Acc: (96.85%) (23679/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 200 |  Loss: (0.0910) | Acc: (96.89%) (24928/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 210 |  Loss: (0.0907) | Acc: (96.90%) (26172/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 220 |  Loss: (0.0911) | Acc: (96.88%) (27405/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 230 |  Loss: (0.0913) | Acc: (96.88%) (28644/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 240 |  Loss: (0.0907) | Acc: (96.89%) (29890/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 250 |  Loss: (0.0905) | Acc: (96.92%) (31137/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 260 |  Loss: (0.0903) | Acc: (96.92%) (32379/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 270 |  Loss: (0.0895) | Acc: (96.92%) (33621/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 280 |  Loss: (0.0895) | Acc: (96.93%) (34864/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 290 |  Loss: (0.0894) | Acc: (96.94%) (36109/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 300 |  Loss: (0.0887) | Acc: (96.96%) (37357/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 310 |  Loss: (0.0880) | Acc: (97.00%) (38613/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 320 |  Loss: (0.0881) | Acc: (97.01%) (39858/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 330 |  Loss: (0.0880) | Acc: (97.00%) (41098/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 340 |  Loss: (0.0882) | Acc: (96.98%) (42330/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 350 |  Loss: (0.0886) | Acc: (96.97%) (43568/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 360 |  Loss: (0.0885) | Acc: (96.98%) (44813/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 370 |  Loss: (0.0885) | Acc: (96.99%) (46058/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 380 |  Loss: (0.0887) | Acc: (96.99%) (47298/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 134 | Batch_idx: 390 |  Loss: (0.0891) | Acc: (96.97%) (48483/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3831) | Acc: (39.84%) (3984/10000)\n",
      "Epoch: 135 | Batch_idx: 0 |  Loss: (0.0781) | Acc: (96.09%) (123/128)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 10 |  Loss: (0.0822) | Acc: (97.09%) (1367/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 20 |  Loss: (0.0862) | Acc: (96.84%) (2603/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 30 |  Loss: (0.0872) | Acc: (96.82%) (3842/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 40 |  Loss: (0.0884) | Acc: (96.89%) (5085/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 50 |  Loss: (0.0866) | Acc: (96.95%) (6329/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 60 |  Loss: (0.0844) | Acc: (97.11%) (7582/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 70 |  Loss: (0.0859) | Acc: (96.97%) (8813/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 80 |  Loss: (0.0857) | Acc: (96.96%) (10053/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 90 |  Loss: (0.0867) | Acc: (96.94%) (11291/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 100 |  Loss: (0.0853) | Acc: (97.01%) (12541/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 110 |  Loss: (0.0846) | Acc: (97.02%) (13784/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 120 |  Loss: (0.0832) | Acc: (97.09%) (15038/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 130 |  Loss: (0.0819) | Acc: (97.13%) (16287/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 140 |  Loss: (0.0836) | Acc: (97.10%) (17524/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 150 |  Loss: (0.0840) | Acc: (97.07%) (18762/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 160 |  Loss: (0.0841) | Acc: (97.09%) (20008/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 170 |  Loss: (0.0833) | Acc: (97.12%) (21258/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 180 |  Loss: (0.0834) | Acc: (97.12%) (22500/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 190 |  Loss: (0.0833) | Acc: (97.09%) (23736/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 200 |  Loss: (0.0834) | Acc: (97.10%) (24982/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 210 |  Loss: (0.0832) | Acc: (97.09%) (26223/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 220 |  Loss: (0.0830) | Acc: (97.13%) (27476/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 230 |  Loss: (0.0833) | Acc: (97.12%) (28716/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 240 |  Loss: (0.0846) | Acc: (97.05%) (29939/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 250 |  Loss: (0.0846) | Acc: (97.05%) (31181/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 260 |  Loss: (0.0843) | Acc: (97.06%) (32427/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 270 |  Loss: (0.0854) | Acc: (97.04%) (33660/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 280 |  Loss: (0.0852) | Acc: (97.05%) (34908/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 290 |  Loss: (0.0854) | Acc: (97.03%) (36143/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 300 |  Loss: (0.0854) | Acc: (97.02%) (37378/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 310 |  Loss: (0.0858) | Acc: (97.04%) (38628/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 320 |  Loss: (0.0855) | Acc: (97.04%) (39873/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 330 |  Loss: (0.0865) | Acc: (97.00%) (41098/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 340 |  Loss: (0.0867) | Acc: (96.99%) (42336/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 350 |  Loss: (0.0872) | Acc: (96.98%) (43570/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 360 |  Loss: (0.0879) | Acc: (96.94%) (44795/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 370 |  Loss: (0.0880) | Acc: (96.95%) (46038/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 380 |  Loss: (0.0878) | Acc: (96.95%) (47282/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 135 | Batch_idx: 390 |  Loss: (0.0878) | Acc: (96.96%) (48482/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3489) | Acc: (40.04%) (4004/10000)\n",
      "Epoch: 136 | Batch_idx: 0 |  Loss: (0.1440) | Acc: (95.31%) (122/128)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 10 |  Loss: (0.0892) | Acc: (96.66%) (1361/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 20 |  Loss: (0.0967) | Acc: (96.65%) (2598/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 30 |  Loss: (0.0929) | Acc: (96.77%) (3840/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 40 |  Loss: (0.0887) | Acc: (96.88%) (5084/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 50 |  Loss: (0.0883) | Acc: (96.84%) (6322/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 60 |  Loss: (0.0876) | Acc: (96.81%) (7559/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 70 |  Loss: (0.0871) | Acc: (96.82%) (8799/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 80 |  Loss: (0.0879) | Acc: (96.86%) (10042/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 90 |  Loss: (0.0881) | Acc: (96.85%) (11281/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 100 |  Loss: (0.0871) | Acc: (96.91%) (12529/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 110 |  Loss: (0.0882) | Acc: (96.93%) (13772/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 120 |  Loss: (0.0881) | Acc: (96.93%) (15013/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 130 |  Loss: (0.0876) | Acc: (96.96%) (16259/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 140 |  Loss: (0.0878) | Acc: (96.99%) (17504/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 150 |  Loss: (0.0882) | Acc: (96.98%) (18745/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 160 |  Loss: (0.0879) | Acc: (97.00%) (19990/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 170 |  Loss: (0.0885) | Acc: (96.98%) (21228/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 180 |  Loss: (0.0883) | Acc: (97.00%) (22472/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 190 |  Loss: (0.0896) | Acc: (96.96%) (23705/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 200 |  Loss: (0.0897) | Acc: (96.96%) (24946/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 210 |  Loss: (0.0895) | Acc: (96.96%) (26187/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 220 |  Loss: (0.0896) | Acc: (96.97%) (27430/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 230 |  Loss: (0.0896) | Acc: (96.96%) (28670/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 240 |  Loss: (0.0891) | Acc: (96.99%) (29918/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 250 |  Loss: (0.0889) | Acc: (97.00%) (31163/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 260 |  Loss: (0.0888) | Acc: (97.01%) (32409/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 270 |  Loss: (0.0888) | Acc: (97.01%) (33651/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 280 |  Loss: (0.0886) | Acc: (97.03%) (34899/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 290 |  Loss: (0.0901) | Acc: (97.00%) (36131/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 300 |  Loss: (0.0896) | Acc: (97.01%) (37376/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 310 |  Loss: (0.0896) | Acc: (97.00%) (38615/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 320 |  Loss: (0.0903) | Acc: (96.98%) (39849/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 330 |  Loss: (0.0905) | Acc: (96.98%) (41089/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 340 |  Loss: (0.0904) | Acc: (96.98%) (42329/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 350 |  Loss: (0.0904) | Acc: (96.97%) (43568/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 360 |  Loss: (0.0905) | Acc: (96.97%) (44808/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 370 |  Loss: (0.0908) | Acc: (96.96%) (46042/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 380 |  Loss: (0.0913) | Acc: (96.94%) (47275/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 136 | Batch_idx: 390 |  Loss: (0.0911) | Acc: (96.93%) (48467/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3726) | Acc: (39.53%) (3953/10000)\n",
      "Epoch: 137 | Batch_idx: 0 |  Loss: (0.0772) | Acc: (97.66%) (125/128)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 10 |  Loss: (0.0886) | Acc: (96.31%) (1356/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 20 |  Loss: (0.0826) | Acc: (97.02%) (2608/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 30 |  Loss: (0.0946) | Acc: (96.82%) (3842/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 40 |  Loss: (0.0893) | Acc: (97.01%) (5091/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 50 |  Loss: (0.0915) | Acc: (97.03%) (6334/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 60 |  Loss: (0.0912) | Acc: (97.00%) (7574/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 70 |  Loss: (0.0924) | Acc: (96.95%) (8811/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 80 |  Loss: (0.0915) | Acc: (96.99%) (10056/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 90 |  Loss: (0.0935) | Acc: (96.94%) (11291/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 100 |  Loss: (0.0921) | Acc: (96.95%) (12534/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 110 |  Loss: (0.0923) | Acc: (96.94%) (13773/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 120 |  Loss: (0.0912) | Acc: (96.99%) (15022/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 130 |  Loss: (0.0916) | Acc: (96.95%) (16257/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 140 |  Loss: (0.0914) | Acc: (96.94%) (17495/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 150 |  Loss: (0.0915) | Acc: (96.97%) (18742/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 160 |  Loss: (0.0911) | Acc: (96.95%) (19980/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 170 |  Loss: (0.0909) | Acc: (96.98%) (21226/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 180 |  Loss: (0.0911) | Acc: (96.95%) (22462/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 190 |  Loss: (0.0911) | Acc: (96.94%) (23699/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 200 |  Loss: (0.0922) | Acc: (96.91%) (24934/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 210 |  Loss: (0.0922) | Acc: (96.91%) (26173/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 220 |  Loss: (0.0917) | Acc: (96.91%) (27413/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 230 |  Loss: (0.0913) | Acc: (96.93%) (28659/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 240 |  Loss: (0.0913) | Acc: (96.91%) (29896/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 250 |  Loss: (0.0919) | Acc: (96.91%) (31134/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 260 |  Loss: (0.0922) | Acc: (96.90%) (32371/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 270 |  Loss: (0.0918) | Acc: (96.92%) (33619/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 280 |  Loss: (0.0916) | Acc: (96.93%) (34864/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 290 |  Loss: (0.0915) | Acc: (96.94%) (36110/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 300 |  Loss: (0.0917) | Acc: (96.92%) (37341/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 310 |  Loss: (0.0914) | Acc: (96.93%) (38586/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 320 |  Loss: (0.0917) | Acc: (96.91%) (39820/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 330 |  Loss: (0.0910) | Acc: (96.93%) (41066/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 340 |  Loss: (0.0910) | Acc: (96.93%) (42307/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 350 |  Loss: (0.0911) | Acc: (96.91%) (43540/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 360 |  Loss: (0.0911) | Acc: (96.92%) (44783/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 370 |  Loss: (0.0917) | Acc: (96.88%) (46004/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 380 |  Loss: (0.0912) | Acc: (96.89%) (47252/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 137 | Batch_idx: 390 |  Loss: (0.0914) | Acc: (96.88%) (48441/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3421) | Acc: (39.88%) (3988/10000)\n",
      "Epoch: 138 | Batch_idx: 0 |  Loss: (0.0844) | Acc: (96.88%) (124/128)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 10 |  Loss: (0.0841) | Acc: (97.09%) (1367/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 20 |  Loss: (0.0931) | Acc: (96.76%) (2601/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 30 |  Loss: (0.0944) | Acc: (96.85%) (3843/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 40 |  Loss: (0.0891) | Acc: (97.01%) (5091/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 50 |  Loss: (0.0881) | Acc: (96.98%) (6331/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 60 |  Loss: (0.0892) | Acc: (97.02%) (7575/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 70 |  Loss: (0.0864) | Acc: (97.07%) (8822/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 80 |  Loss: (0.0878) | Acc: (97.05%) (10062/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 90 |  Loss: (0.0889) | Acc: (97.03%) (11302/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 100 |  Loss: (0.0885) | Acc: (97.05%) (12547/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 110 |  Loss: (0.0899) | Acc: (96.96%) (13776/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 120 |  Loss: (0.0919) | Acc: (96.86%) (15002/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 130 |  Loss: (0.0942) | Acc: (96.81%) (16233/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 140 |  Loss: (0.0952) | Acc: (96.74%) (17460/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 150 |  Loss: (0.0939) | Acc: (96.79%) (18708/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 160 |  Loss: (0.0937) | Acc: (96.81%) (19951/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 170 |  Loss: (0.0933) | Acc: (96.84%) (21196/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 180 |  Loss: (0.0922) | Acc: (96.86%) (22441/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 190 |  Loss: (0.0923) | Acc: (96.87%) (23682/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 200 |  Loss: (0.0925) | Acc: (96.88%) (24926/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 210 |  Loss: (0.0927) | Acc: (96.85%) (26156/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 220 |  Loss: (0.0936) | Acc: (96.83%) (27392/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 230 |  Loss: (0.0931) | Acc: (96.85%) (28638/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 240 |  Loss: (0.0922) | Acc: (96.87%) (29881/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 250 |  Loss: (0.0921) | Acc: (96.88%) (31127/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 260 |  Loss: (0.0924) | Acc: (96.87%) (32361/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 270 |  Loss: (0.0925) | Acc: (96.85%) (33597/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 280 |  Loss: (0.0921) | Acc: (96.87%) (34843/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 290 |  Loss: (0.0920) | Acc: (96.87%) (36082/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 300 |  Loss: (0.0918) | Acc: (96.88%) (37325/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 310 |  Loss: (0.0915) | Acc: (96.88%) (38567/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 320 |  Loss: (0.0917) | Acc: (96.86%) (39798/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 330 |  Loss: (0.0915) | Acc: (96.88%) (41046/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 340 |  Loss: (0.0913) | Acc: (96.88%) (42286/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 350 |  Loss: (0.0909) | Acc: (96.89%) (43530/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 360 |  Loss: (0.0911) | Acc: (96.88%) (44765/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 370 |  Loss: (0.0906) | Acc: (96.89%) (46011/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 380 |  Loss: (0.0906) | Acc: (96.89%) (47253/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 138 | Batch_idx: 390 |  Loss: (0.0903) | Acc: (96.90%) (48448/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.2749) | Acc: (40.78%) (4078/10000)\n",
      "Epoch: 139 | Batch_idx: 0 |  Loss: (0.0859) | Acc: (99.22%) (127/128)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 10 |  Loss: (0.0895) | Acc: (96.80%) (1363/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 20 |  Loss: (0.0862) | Acc: (97.02%) (2608/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 30 |  Loss: (0.0839) | Acc: (96.90%) (3845/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 40 |  Loss: (0.0841) | Acc: (97.03%) (5092/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 50 |  Loss: (0.0841) | Acc: (97.03%) (6334/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 60 |  Loss: (0.0863) | Acc: (96.90%) (7566/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 70 |  Loss: (0.0870) | Acc: (96.91%) (8807/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 80 |  Loss: (0.0886) | Acc: (96.86%) (10042/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 90 |  Loss: (0.0896) | Acc: (96.82%) (11278/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 100 |  Loss: (0.0922) | Acc: (96.74%) (12507/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 110 |  Loss: (0.0920) | Acc: (96.76%) (13747/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 120 |  Loss: (0.0908) | Acc: (96.82%) (14995/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 130 |  Loss: (0.0901) | Acc: (96.86%) (16241/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 140 |  Loss: (0.0897) | Acc: (96.88%) (17485/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 150 |  Loss: (0.0901) | Acc: (96.84%) (18718/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 160 |  Loss: (0.0895) | Acc: (96.89%) (19968/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 170 |  Loss: (0.0903) | Acc: (96.89%) (21207/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 180 |  Loss: (0.0899) | Acc: (96.89%) (22448/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 190 |  Loss: (0.0900) | Acc: (96.89%) (23688/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 200 |  Loss: (0.0899) | Acc: (96.89%) (24928/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 210 |  Loss: (0.0906) | Acc: (96.85%) (26157/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 220 |  Loss: (0.0910) | Acc: (96.85%) (27397/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 230 |  Loss: (0.0906) | Acc: (96.87%) (28642/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 240 |  Loss: (0.0904) | Acc: (96.89%) (29888/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 250 |  Loss: (0.0907) | Acc: (96.88%) (31127/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 260 |  Loss: (0.0907) | Acc: (96.89%) (32370/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 270 |  Loss: (0.0912) | Acc: (96.86%) (33599/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 280 |  Loss: (0.0915) | Acc: (96.84%) (34833/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 290 |  Loss: (0.0913) | Acc: (96.86%) (36080/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 300 |  Loss: (0.0918) | Acc: (96.84%) (37312/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 310 |  Loss: (0.0917) | Acc: (96.85%) (38556/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 320 |  Loss: (0.0920) | Acc: (96.84%) (39791/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 330 |  Loss: (0.0919) | Acc: (96.85%) (41034/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 340 |  Loss: (0.0916) | Acc: (96.88%) (42287/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 350 |  Loss: (0.0915) | Acc: (96.90%) (43533/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 360 |  Loss: (0.0910) | Acc: (96.91%) (44781/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 370 |  Loss: (0.0909) | Acc: (96.91%) (46022/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 380 |  Loss: (0.0908) | Acc: (96.93%) (47270/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 139 | Batch_idx: 390 |  Loss: (0.0903) | Acc: (96.96%) (48478/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3153) | Acc: (40.73%) (4073/10000)\n",
      "Epoch: 140 | Batch_idx: 0 |  Loss: (0.0563) | Acc: (97.66%) (125/128)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 10 |  Loss: (0.0862) | Acc: (97.16%) (1368/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 20 |  Loss: (0.0930) | Acc: (97.02%) (2608/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 30 |  Loss: (0.0868) | Acc: (97.23%) (3858/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 40 |  Loss: (0.0869) | Acc: (97.16%) (5099/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 50 |  Loss: (0.0909) | Acc: (96.97%) (6330/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 60 |  Loss: (0.0907) | Acc: (96.91%) (7567/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 70 |  Loss: (0.0895) | Acc: (97.00%) (8815/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 80 |  Loss: (0.0893) | Acc: (97.03%) (10060/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 90 |  Loss: (0.0885) | Acc: (97.00%) (11298/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 100 |  Loss: (0.0879) | Acc: (97.01%) (12541/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 110 |  Loss: (0.0875) | Acc: (97.02%) (13784/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 120 |  Loss: (0.0888) | Acc: (96.97%) (15018/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 130 |  Loss: (0.0903) | Acc: (96.90%) (16249/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 140 |  Loss: (0.0911) | Acc: (96.89%) (17486/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 150 |  Loss: (0.0928) | Acc: (96.81%) (18712/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 160 |  Loss: (0.0923) | Acc: (96.82%) (19953/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 170 |  Loss: (0.0925) | Acc: (96.83%) (21194/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 180 |  Loss: (0.0911) | Acc: (96.88%) (22446/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 190 |  Loss: (0.0920) | Acc: (96.86%) (23680/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 200 |  Loss: (0.0924) | Acc: (96.83%) (24913/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 210 |  Loss: (0.0923) | Acc: (96.82%) (26150/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 220 |  Loss: (0.0918) | Acc: (96.84%) (27394/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 230 |  Loss: (0.0919) | Acc: (96.82%) (28628/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 240 |  Loss: (0.0919) | Acc: (96.83%) (29869/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 250 |  Loss: (0.0916) | Acc: (96.86%) (31120/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 260 |  Loss: (0.0920) | Acc: (96.85%) (32354/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 270 |  Loss: (0.0921) | Acc: (96.81%) (33582/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 280 |  Loss: (0.0925) | Acc: (96.81%) (34820/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 290 |  Loss: (0.0924) | Acc: (96.81%) (36060/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 300 |  Loss: (0.0924) | Acc: (96.80%) (37296/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 310 |  Loss: (0.0928) | Acc: (96.78%) (38527/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 320 |  Loss: (0.0931) | Acc: (96.78%) (39765/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 330 |  Loss: (0.0932) | Acc: (96.77%) (41001/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 340 |  Loss: (0.0934) | Acc: (96.78%) (42241/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 350 |  Loss: (0.0930) | Acc: (96.80%) (43490/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 360 |  Loss: (0.0928) | Acc: (96.81%) (44734/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 370 |  Loss: (0.0929) | Acc: (96.81%) (45975/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 380 |  Loss: (0.0927) | Acc: (96.82%) (47217/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 140 | Batch_idx: 390 |  Loss: (0.0925) | Acc: (96.83%) (48416/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3226) | Acc: (40.58%) (4058/10000)\n",
      "Epoch: 141 | Batch_idx: 0 |  Loss: (0.0546) | Acc: (99.22%) (127/128)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 10 |  Loss: (0.1031) | Acc: (96.02%) (1352/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 20 |  Loss: (0.0914) | Acc: (96.58%) (2596/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 30 |  Loss: (0.0832) | Acc: (96.98%) (3848/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 40 |  Loss: (0.0798) | Acc: (97.22%) (5102/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 50 |  Loss: (0.0793) | Acc: (97.30%) (6352/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 60 |  Loss: (0.0794) | Acc: (97.26%) (7594/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 70 |  Loss: (0.0813) | Acc: (97.22%) (8835/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 80 |  Loss: (0.0841) | Acc: (97.16%) (10074/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 90 |  Loss: (0.0838) | Acc: (97.24%) (11326/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 100 |  Loss: (0.0827) | Acc: (97.27%) (12575/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 110 |  Loss: (0.0854) | Acc: (97.21%) (13811/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 120 |  Loss: (0.0856) | Acc: (97.23%) (15059/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 130 |  Loss: (0.0853) | Acc: (97.24%) (16305/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 140 |  Loss: (0.0868) | Acc: (97.19%) (17540/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 150 |  Loss: (0.0889) | Acc: (97.11%) (18770/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 160 |  Loss: (0.0899) | Acc: (97.08%) (20006/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 170 |  Loss: (0.0899) | Acc: (97.08%) (21248/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 180 |  Loss: (0.0898) | Acc: (97.07%) (22489/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 190 |  Loss: (0.0902) | Acc: (97.05%) (23728/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 200 |  Loss: (0.0905) | Acc: (97.03%) (24965/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 210 |  Loss: (0.0905) | Acc: (97.03%) (26206/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 220 |  Loss: (0.0905) | Acc: (97.02%) (27445/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 230 |  Loss: (0.0901) | Acc: (97.02%) (28687/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 240 |  Loss: (0.0895) | Acc: (97.05%) (29939/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 250 |  Loss: (0.0893) | Acc: (97.06%) (31182/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 260 |  Loss: (0.0891) | Acc: (97.08%) (32434/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 270 |  Loss: (0.0893) | Acc: (97.07%) (33671/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 280 |  Loss: (0.0883) | Acc: (97.11%) (34927/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 290 |  Loss: (0.0885) | Acc: (97.11%) (36170/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 300 |  Loss: (0.0881) | Acc: (97.11%) (37413/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 310 |  Loss: (0.0883) | Acc: (97.10%) (38655/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 320 |  Loss: (0.0887) | Acc: (97.09%) (39892/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 330 |  Loss: (0.0889) | Acc: (97.08%) (41131/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 340 |  Loss: (0.0889) | Acc: (97.08%) (42373/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 350 |  Loss: (0.0891) | Acc: (97.09%) (43619/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 360 |  Loss: (0.0895) | Acc: (97.06%) (44851/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 370 |  Loss: (0.0896) | Acc: (97.05%) (46087/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 380 |  Loss: (0.0897) | Acc: (97.04%) (47324/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 141 | Batch_idx: 390 |  Loss: (0.0898) | Acc: (97.05%) (48525/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3668) | Acc: (39.82%) (3982/10000)\n",
      "Epoch: 142 | Batch_idx: 0 |  Loss: (0.0252) | Acc: (99.22%) (127/128)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 10 |  Loss: (0.0945) | Acc: (96.59%) (1360/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 20 |  Loss: (0.0863) | Acc: (97.10%) (2610/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 30 |  Loss: (0.0917) | Acc: (96.93%) (3846/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 40 |  Loss: (0.0924) | Acc: (97.01%) (5091/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 50 |  Loss: (0.0939) | Acc: (96.92%) (6327/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 60 |  Loss: (0.0917) | Acc: (97.02%) (7575/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 70 |  Loss: (0.0916) | Acc: (97.02%) (8817/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 80 |  Loss: (0.0892) | Acc: (97.07%) (10064/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 90 |  Loss: (0.0891) | Acc: (97.00%) (11298/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 100 |  Loss: (0.0887) | Acc: (97.04%) (12545/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 110 |  Loss: (0.0882) | Acc: (97.06%) (13790/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 120 |  Loss: (0.0891) | Acc: (97.03%) (15028/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 130 |  Loss: (0.0895) | Acc: (97.02%) (16268/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 140 |  Loss: (0.0899) | Acc: (96.98%) (17503/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 150 |  Loss: (0.0901) | Acc: (96.98%) (18745/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 160 |  Loss: (0.0916) | Acc: (96.95%) (19979/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 170 |  Loss: (0.0924) | Acc: (96.91%) (21212/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 180 |  Loss: (0.0921) | Acc: (96.90%) (22450/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 190 |  Loss: (0.0927) | Acc: (96.88%) (23684/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 200 |  Loss: (0.0933) | Acc: (96.88%) (24925/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 210 |  Loss: (0.0920) | Acc: (96.91%) (26174/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 220 |  Loss: (0.0920) | Acc: (96.92%) (27418/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 230 |  Loss: (0.0922) | Acc: (96.91%) (28655/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 240 |  Loss: (0.0928) | Acc: (96.89%) (29888/30848)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 250 |  Loss: (0.0928) | Acc: (96.89%) (31128/32128)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 260 |  Loss: (0.0931) | Acc: (96.88%) (32366/33408)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 270 |  Loss: (0.0928) | Acc: (96.89%) (33609/34688)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 280 |  Loss: (0.0934) | Acc: (96.86%) (34837/35968)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 290 |  Loss: (0.0938) | Acc: (96.83%) (36069/37248)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 300 |  Loss: (0.0933) | Acc: (96.86%) (37317/38528)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 310 |  Loss: (0.0935) | Acc: (96.85%) (38554/39808)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 320 |  Loss: (0.0927) | Acc: (96.88%) (39807/41088)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 330 |  Loss: (0.0922) | Acc: (96.90%) (41053/42368)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 340 |  Loss: (0.0921) | Acc: (96.90%) (42293/43648)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 350 |  Loss: (0.0925) | Acc: (96.88%) (43524/44928)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 360 |  Loss: (0.0930) | Acc: (96.86%) (44757/46208)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 370 |  Loss: (0.0931) | Acc: (96.86%) (45995/47488)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 380 |  Loss: (0.0930) | Acc: (96.86%) (47238/48768)\n",
      "lr: 1e-05\n",
      "Epoch: 142 | Batch_idx: 390 |  Loss: (0.0926) | Acc: (96.88%) (48438/50000)\n",
      "lr: 1e-05\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.3205) | Acc: (40.26%) (4026/10000)\n",
      "Epoch: 143 | Batch_idx: 0 |  Loss: (0.0763) | Acc: (95.31%) (122/128)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 10 |  Loss: (0.0865) | Acc: (97.02%) (1366/1408)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 20 |  Loss: (0.0860) | Acc: (96.91%) (2605/2688)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 30 |  Loss: (0.0881) | Acc: (96.90%) (3845/3968)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 40 |  Loss: (0.0837) | Acc: (97.08%) (5095/5248)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 50 |  Loss: (0.0841) | Acc: (97.18%) (6344/6528)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 60 |  Loss: (0.0854) | Acc: (97.13%) (7584/7808)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 70 |  Loss: (0.0848) | Acc: (97.23%) (8836/9088)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 80 |  Loss: (0.0849) | Acc: (97.24%) (10082/10368)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 90 |  Loss: (0.0850) | Acc: (97.21%) (11323/11648)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 100 |  Loss: (0.0857) | Acc: (97.18%) (12564/12928)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 110 |  Loss: (0.0853) | Acc: (97.19%) (13809/14208)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 120 |  Loss: (0.0846) | Acc: (97.22%) (15057/15488)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 130 |  Loss: (0.0842) | Acc: (97.20%) (16299/16768)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 140 |  Loss: (0.0857) | Acc: (97.14%) (17532/18048)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 150 |  Loss: (0.0859) | Acc: (97.11%) (18769/19328)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 160 |  Loss: (0.0868) | Acc: (97.10%) (20010/20608)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 170 |  Loss: (0.0869) | Acc: (97.09%) (21251/21888)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 180 |  Loss: (0.0869) | Acc: (97.10%) (22495/23168)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 190 |  Loss: (0.0877) | Acc: (97.08%) (23734/24448)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 200 |  Loss: (0.0872) | Acc: (97.09%) (24980/25728)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 210 |  Loss: (0.0870) | Acc: (97.07%) (26218/27008)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 220 |  Loss: (0.0871) | Acc: (97.07%) (27460/28288)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 230 |  Loss: (0.0870) | Acc: (97.06%) (28698/29568)\n",
      "lr: 1e-05\n",
      "Epoch: 143 | Batch_idx: 240 |  Loss: (0.0876) | Acc: (97.03%) (29932/30848)\n",
      "lr: 1e-05\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0 \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.data).cpu().sum()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "                  .format(epoch, batch_idx, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "            print(\"lr:\", optimizer.param_groups[0]['lr']) #!#\n",
    "\n",
    "            writer.add_scalar('training loss', (train_loss/(batch_idx + 1)), epoch * len(train_loader) + batch_idx) #!#\n",
    "            writer.add_scalar('training accuracy', (100. * correct / total), epoch * len(train_loader) + batch_idx) #!#\n",
    "            writer.add_scalar('lr', optimizer.param_groups[0]['lr'], epoch * len(train_loader) + batch_idx) #!#\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.data).cpu().sum()\n",
    "        \n",
    "        writer.add_scalar('test loss', test_loss / (batch_idx + 1), epoch * len(test_loader) + batch_idx) #!#\n",
    "        writer.add_scalar('test accuracy', 100. * correct / total, epoch * len(test_loader) + batch_idx) #!#        \n",
    "        \n",
    "        \n",
    "    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "          .format(test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "def save_checkpoint(directory, state, filename='latest.tar.gz'):\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    model_filename = os.path.join(directory, filename)\n",
    "    torch.save(state, model_filename)\n",
    "    print(\"=> saving checkpoint\")\n",
    "\n",
    "def load_checkpoint(directory, filename='latest.tar.gz'):\n",
    "\n",
    "    model_filename = os.path.join(directory, filename)\n",
    "    if os.path.exists(model_filename):\n",
    "        print(\"=> loading checkpoint\")\n",
    "        state = torch.load(model_filename)\n",
    "        return state\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "start_epoch = 0\n",
    "\n",
    "checkpoint = load_checkpoint(default_directory)\n",
    "if not checkpoint:\n",
    "    pass\n",
    "else:\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "for epoch in range(start_epoch, 165):\n",
    "\n",
    "    if epoch < 80:\n",
    "        lr = learning_rate\n",
    "    elif epoch < 120:\n",
    "        lr = learning_rate * 0.1\n",
    "    else:\n",
    "        lr = learning_rate * 0.01\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    train(epoch)\n",
    "    save_checkpoint(default_directory, {\n",
    "        'epoch': epoch,\n",
    "        'model': model,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    })\n",
    "    test()  \n",
    "\n",
    "now = time.gmtime(time.time() - start_time)\n",
    "print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0496c03db4b9cf5b7334b0627171684ca29346468b7a3d114e1af4dcf199d1e0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('DL_basic': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
